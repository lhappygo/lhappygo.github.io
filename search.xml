<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AQS独占模式解析</title>
    <url>/2019/09/07/AbstractQueuedSynchronized(%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<p><strong>AbstractQueuedSynchronized独占模式</strong></p>
<p>概述：独占模式下节点怎样进入同步队列排队，离开同步队列前会进行哪些操作。AQS在独占模式和共享模式下获取锁分别提供了三种方式<br>不响应线程中断获取，响应县城中断获取，设置超时时间获取。三种方式整体步骤大致相同，只少部分不同，重在理解一种方式，后类比。</p>
<ul>
<li>不响应线程中断获取锁</li>
</ul>
<p><img src="/images/AQS_002/0001.png" alt="Alt text"></p>
<p>按照顺序执行下图4步骤</p>
<p><img src="/images/AQS_002/0002.png" alt="Alt text"></p>
<ol>
<li><strong>!tryAcquire(arg)</strong></li>
</ol>
<p><img src="/images/AQS_002/0003.png" alt="Alt text"></p>
<p>tryAcquire()此方法是由子类去覆盖，重写里面判断逻辑。如果获取锁失败，则返回false，进行下一步判断。否则直接进入。</p>
<ol>
<li><strong>addWaiter(Node.EXCLUSIVE)</strong></li>
</ol>
<p><img src="/images/AQS_002/0004.png" alt="Alt text"></p>
<p><img src="/images/AQS_002/0005.png" alt="Alt text"></p>
<p>执行到这一步表名第一次获取锁失败，这个线程就被包装成节点放进排队区排队了，包装过程中已声明以什么方式占有锁（独占式、共享模式）此时并未将自己挂起。</p>
<ol>
<li><strong>acquireQueued(addWaiter(Node.EXCLUSIVE),arg)</strong></li>
</ol>
<p><img src="/images/AQS_002/0006.png" alt="Alt text"></p>
<blockquote>
<p><strong>包装成节点进入排队区后会立即执行此方法。</strong></p>
</blockquote>
<ul>
<li>当一个节点首次进入排队区后有两种情况，<ul>
<li>一种是前节点已经获取锁，此节点直接尝试获取锁，看是否前节点释放锁。如果前节点正好释放锁，正好此节点可以直接获取锁。否则要在队列中进行挂起等待，此时会给前继结点标识为signal，表明前继结点释放锁后，会唤醒当前结点。</li>
</ul>
</li>
</ul>
<p>另一种情况，节点进入排队区发现前边有多个节点在排队区排队，那它可安心挂起，挂起之前会将前继结点标识为signal，好让前继结点释放锁之后，唤醒当前节点。注意，我们看到整个for循环就只有一个出口，那就是等线程成功的获取到锁之后才能出去，在没有获取到锁之前就一直是挂在for循环的parkAndCheckInterrupt()方法里头。线程被唤醒后也是从这个地方继续执行for循环。</p>
<ol>
<li><strong>selfInterrupt()</strong></li>
</ol>
<p><img src="/images/AQS_002/0007.png" alt="Alt text"></p>
<p>由于上面整个线程一直是挂在for循环的parkAndCheckInterrupt()方法里头，没有成功获取到锁之前不响应任何形式的线程中断，只有当线程成功获取到锁并从for循环出来后，他才会查看在这期间是否有人要求中断线程，如果是的话再去调用selfInterrupt()方法将自己挂起</p>
<p><strong>2.以可中断模式获取锁（独占式）</strong></p>
<p><img src="/images/AQS_002/0008.png" alt="Alt text"></p>
<p>响应线程中断方式和不响应线程中断方式获取流程大致相同。区别只是线程从parkAndCheckInterrupt方法中醒来后会检查线程是否中断，如果中断就抛出InterruptedException异常,而不响应线程中断获取锁是在收到中断请求后只设置一下中断状态，并不会立马结束当前获取锁的方法，一直到节点成功获取锁之后才会根据中断状态决定是否将自己挂起。</p>
<p><strong>3.设置超时时间获取锁</strong></p>
<p><img src="/images/AQS_002/0009.png" alt="Alt text"></p>
<p>设置超时时间获取，首先会先尝试获取锁，第一次获取锁失败后根据情况，如传入的超时时间大于自旋时间，那么就会将线程挂起一段时间，否则会进行自旋，每次获取锁之后都会讲超时时间减去获取一次锁所用的时间。一直到超时时间小于0，也就说明超时时间用完了，此时会结束获取锁的操作，然后返回获取失败标识。在以超时获取锁的过程中，能用以响应线程中断请求的。</p>
<p><strong>4.线程释放锁并离开同步队列操作情况</strong></p>
<p><img src="/images/AQS_002/0010.png" alt="Alt text"></p>
<p>线程持有锁进行同步操作，操作后会释放锁。通过tryRelease方法可解锁，tryRelease方法是要让子类覆盖的，不同子类实现规则不一，如ReentrantLock，每调用一次tryRelease方法一次，state减一（同步状态减一）直到state减到0时进行锁释放。</p>
]]></content>
      <categories>
        <category>AQS</category>
      </categories>
      <tags>
        <tag>AQS</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Java中AQS</title>
    <url>/2019/08/10/AbstractQueuedSynchronized/</url>
    <content><![CDATA[<p>1.AbstractQueuedSynchronized</p>
<p>ReentrantLock实现了一个内部类Sync,该内部类继承了AQS，所有锁机制的实现都依赖于Sync这个内部类，ReentrantLock的实现依赖于AQS类。类似的还有CountDownLatch，CyclicBarrier，Semaphore这些类也是采用同样的方式来实现对锁的控制。AQS为这些类提供了基础，提供了一个密码锁，拥有了这个密码锁之后可以自己来设置密码。</p>
<p>AQS有一个排队区，提供了一个线程调度，告诉线程什么时候去排队，去哪里排队，排队前做什么，排队后做些什么。</p>
<p><strong>2.AQS提供了一把密码锁</strong></p>
<p><img src="/images/AQS_001/AQS_001.png" alt="Alt text"></p>
<ul>
<li>列出了AQS的三个成员变量</li>
<li>同步队列头结点引用</li>
<li>同步队列尾结点引用</li>
<li>同步状态</li>
</ul>
<p>这三个成员变量都是使用vovatile关键字修饰的，确保了在多线程对它的修改都是内存可见的。整个类的核心是这个同步状态，是个int类型的变量，可将同步状态比喻为密码锁，state的值相当于密码控制着锁。锁的密码由子类来实现。如：ReentrantLock中，state=0表示锁是开的，state&gt;0表示锁是锁着的，而Semphore中，state&gt;0表示锁是开的，state=0表示锁的锁着的。</p>
<p><strong>3.AbstractQueuedSynchronized的排队区实现</strong></p>
<p><img src="/images/AQS_001/AQS_002.png" alt="Alt text"></p>
<p>AQS内部有两种排队区，一条是同步队列(双向链表)，多个是条件队列。同步队列只有一条，条件队列可以有多条。同步队列的结点分别持有前后结点引用，而条件队列的结点只有一个指向后继结点的引用。</p>
<p><strong>AQS内部两个排队区</strong></p>
<ul>
<li>同步队列<ul>
<li>只有一条</li>
<li>结点，分别持有前后结点引用</li>
</ul>
</li>
<li>条件队列<ul>
<li>可有多条</li>
<li>结点，只有一个指向后继结点的引用</li>
</ul>
</li>
</ul>
<p>图中T代表线程，每个结点包含一个线程，线程在获取锁失败后先进入同步队列排队，想要进入条件队列该线程必须持有锁才行。</p>
<p>注：</p>
<ul>
<li><p>同步队列节点来源</p>
<ul>
<li>同步队列依赖一个双向链表完成同步状态的管理，当前线程获取同步状态失败后，同步器会将线程构建成一个节点，并加入到同步队列中。</li>
<li>通过signal或signalAll将条件队列中的节点转移到同步队列。（条件队列转化为同步队列） </li>
</ul>
</li>
<li><p>条件队列节点来源</p>
<ul>
<li>调用await方法阻塞线程。</li>
<li>当前线程在同步队列头节点，调用await方法阻塞(从同步队列转化到条件队列）</li>
</ul>
</li>
</ul>
<p><strong>总结：</strong></p>
<ul>
<li>同步队列与条件队列节点可互相转化</li>
<li>一个线程只能存在于两个队列中的一个</li>
</ul>
<p>队列每个结点结构</p>
<p><img src="/images/AQS_001/AQS_003.jpg" alt="Alt text"></p>
<p>Node代表同步队列和条件队列中的一个结点，是AQS的内部类。Node有很多属性，如：持有模式、等待状态、同步队列中的前继和后继，以及条件队列中的后继引用等。</p>
<p><strong>Node:</strong></p>
<ul>
<li><p>Node SHARED=new Node()：当前线程以共享模式持有锁</p>
</li>
<li><p>Node EXCLUSIVE =null：当前线程以独占模式持有锁</p>
</li>
<li><p>int CANCELLED=1：当前结点已取消获取锁</p>
</li>
<li><p>int SIGNAL=-1：后继结点的线程需要运行</p>
</li>
<li><p>int CONDITION=-2：当前结点在条件队列中排队</p>
</li>
<li><p>int PROPAGATE=-3：后继结点可以直接获取锁</p>
</li>
<li><p>volatile int waitStatus：当前结点的等待状态</p>
</li>
<li><p>volatile Node pre：同步队列中的前继结点</p>
</li>
<li><p>volatile Node next：同步队列中的后继结点</p>
</li>
<li><p>volatile Thread thread：当前结点持有的线程引用</p>
</li>
<li><p>final boolean isShared()：当前结点是否为共享模式</p>
</li>
<li><p>final Node predecessor()：返回当前结点的前继结点</p>
</li>
<li><p>Node(){}：构造器1</p>
</li>
<li><p>Node(Thread thread,Node model){}：持有模式是赋值给nextWaiter,条件队列中的后继结点</p>
</li>
<li><p>Node(Thread thread,int waitStatus){}：只有条件队列中使用</p>
</li>
</ul>
<blockquote>
<p>可把同步队列、条件队列看成排队区，每个节点看成排队区的座位，线程看成是排队的客人，客人来时去看下所有没有开，如果没开他就会去排队区另一个号牌，声明自己已什么方式持有锁，最后再到队列的尾部排队。</p>
</blockquote>
<p><strong>4.理解结点锁等待状态</strong></p>
<p>每个节点都有一个等待状态，共四种等待状态。</p>
<ul>
<li>CANCELLED：当一个线程在排队过程中打算放弃了，会将自己位置设置为CANCELLED,这样别人看到了就可以把它清理出队列。</li>
</ul>
<ul>
<li><p>SIGNAL：当线程在结点上药睡着之前，会将前继结点标识为SIGNAL,因为每个线程离开队列前都会查看当前结点，如果当前结点标识为SIGNAL，它会唤醒后继结点中的线程。只有保证前继结点上状态为SIGNAL，当前线程才会安心睡去。</p>
</li>
<li><p>CONDITION：该线程在条件队列中排队。</p>
</li>
<li><p>PROPAGATE：提醒后面来的线程可以直接获取锁，这个状态只在共享模式用到。</p>
</li>
</ul>
<p><strong>5.结点进入同步队列时进行的操作</strong></p>
<p><img src="/images/AQS_001/AQS_004.png" alt="Alt text"></p>
<p>注意：入队操作使用死循环，只有成功将节点添加到同步队列尾部才会返回，返回结果是同步队列原先的尾结点。</p>
<p><img src="/images/AQS_001/AQS_005.png" alt="Alt text"></p>
<p>需要注意添加尾结点的顺序，分为三步：指向尾结点，CAS更改尾结点，将旧尾结点的后继指向当前结点。在并发环境中这三步操作不一定能保证完成，所以在清空同步队列所有已取消的结点这一操作中，为了寻找非取消状态的结点，不是从前向后遍历而是从后向前遍历的。还有就是每个结点进入队列中时它的等待状态是为0，只有后继结点的线程需要挂起时才会将前面结点的等待状态改为SIGNAL。</p>
]]></content>
      <categories>
        <category>AQS</category>
      </categories>
      <tags>
        <tag>AQS</tag>
      </tags>
  </entry>
  <entry>
    <title>CAS算法及ABA问题</title>
    <url>/2020/03/07/CAS%E7%AE%97%E6%B3%95%E5%8F%8A%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p><strong>CAS算法</strong></p>
<p>CAS（Compare And Swap)比较并交换，乐观锁的思想，认为总可成功完成操作，在多线程同时使用CAS操作一个变量时，只会有一个线程获得操作更新的权利，其他的都会失败，失败的线程不会被挂起，仅被告知失败，并且允许再次尝试。</p>
<p><strong>三个重要参数</strong></p>
<ul>
<li>V：当前内存中的值</li>
<li>A：旧的预期值</li>
<li>B：要更新的值</li>
</ul>
<p>当V==A（旧的预期值==当前内存中的值），通过原子操作将V修改为B,并返回true,否则什么都不做，返回false。</p>
<p>CAS算法必须和volatile一起使用，并且要在多核CPU下才可以使用。</p>
<p>使用CAS算法的类有JUC包下的AtomicInteger类，getAndSet()就是调用unsafe类的getAndAddInt()方法。</p>
<p><strong>AtomicInteger类部分源码</strong></p>
<p><img src="/images/CAS_001/000001.jpg" alt="Alt text"></p>
<p><strong>Unsafe类的部分源码：</strong></p>
<pre><code>public final class Unsafe {

private Unsafe() {}

private static final Unsafe theUnsafe = new Unsafe();

// 拿到调用它的那个Class的ClassLoader判断是否是SystemDomainLoader,如果不是则抛安全异常
// 就是判断是否可以信任调用者并返回他实例
@CallerSensitive
public static Unsafe getUnsafe() {
    Class&lt;?&gt; caller = Reflection.getCallerClass();
    if (!VM.isSystemDomainLoader(caller.getClassLoader()))
        throw new SecurityException(&quot;Unsafe&quot;);
    return theUnsafe;
}


/**
 *  Object obeject 指定要获取哪个对象中的属性
 *  long valueOffset 指定该属性在内存中的偏移值
 *  int i 加数
 *  知道 obeject 和 valueOffset 才能确定共享变量
 *  源码中的变量为var1 var2，不能闻其名知其义，所以我改了名字，方便阅读
 */
public final int getAndAddInt(Object obeject, long valueOffset, int i) {
    int A;
       do {
            // 获取当前内存中的值,即旧的预期值
            A = this.getIntVolatile(obeject,valueOffset);  
           // 这里的obeject, valueOffset传递给底层去确定 V（当前内存中的值）
        } while (!compareAndSwapInt(obeject, valueOffset, A, A + i));    
            return A;
}    
}
</code></pre><p><strong>ABA问题：</strong></p>
<ul>
<li><p>问题</p>
<p>   CAS算法的实现前提：需要取内存中某时刻的数据，然后在下一时刻进行比较和交换，在这个时间差内可能数据已发生了改变，就会生产ABA问题。</p>
<p>   ABA问题指第一个线程t1从内存的V位置取出A，这时第二个线程t2也从内存V位置取出A，并将V位置的数据修改为B，接着又将V位置的数据修改为A,然后t1线程操作成功。对于t1来说，CAS操作是成功的，但是该过程中V位置的数据发生了变化，t1感知不到，某些场景下会出现数据不一致的问题。</p>
</li>
</ul>
<ul>
<li><p>解决办法(添加版本号)：</p>
<p>  每次对共享变量修改操作时都会带上一个版本号，在预期的版本号和数据的版本号一致时才可才可执行修改操作，并对版本号执行加1操作，否则执行失败。每次操作都会让版本号加1，不会出现ABA问题，版本号只能增加不能减少。</p>
</li>
</ul>
<p>从JDK1.5Atomic包里提供了类AtomicStampedReference来解决ABA问题。</p>
<p><strong>AtomicStampedReference类源码</strong></p>
<pre><code>public class AtomicStampedReference&lt;V&gt; {

private static class Pair&lt;T&gt; {
    final T reference;
    final int stamp;
    private Pair(T reference, int stamp) {
        this.reference = reference;
        this.stamp = stamp;
    }
    static &lt;T&gt; Pair&lt;T&gt; of(T reference, int stamp) {
        return new Pair&lt;T&gt;(reference, stamp);
    }
}

private volatile Pair&lt;V&gt; pair;

/** 
 *  首先检查当前引用是否等于预期引用，
 *  并且当前标志是否等于预期标志
 *  如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。
 *  
 *  expectedReference：表示预期值
 *  newReference：表示要更新的值
 *  expectedStamp：表示预期的时间戳
 *  newStamp：表示要更新的时间戳
 */
public boolean compareAndSet(V   expectedReference,
                             V   newReference,
                             int expectedStamp,
                             int newStamp) {
    Pair&lt;V&gt; current = pair;
    return
        expectedReference == current.reference &amp;&amp;
        expectedStamp == current.stamp &amp;&amp;
        ((newReference == current.reference &amp;&amp;
          newStamp == current.stamp) ||
         casPair(current, Pair.of(newReference, newStamp)));
}

private boolean casPair(Pair&lt;V&gt; cmp, Pair&lt;V&gt; val) {
    return UNSAFE.compareAndSwapObject(this, pairOffset, cmp, val);
}
</code></pre><p>}</p>
<p><strong>CAS缺点</strong></p>
<ul>
<li>循环时间太长，消耗CPU资源</li>
<li>只能包证一个共享变量原子操作</li>
<li>会出现ABA问题</li>
</ul>
]]></content>
      <categories>
        <category>CAS</category>
      </categories>
      <tags>
        <tag>CAS</tag>
        <tag>乐观锁</tag>
      </tags>
  </entry>
  <entry>
    <title>Eureka的自我保护机制</title>
    <url>/2019/01/05/Eureka%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%9D%E6%8A%A4%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h1 id="Eureka的自我保护机制"><a href="#Eureka的自我保护机制" class="headerlink" title="Eureka的自我保护机制"></a>Eureka的自我保护机制</h1><ul>
<li>原理：<ul>
<li>a、默认情况下,EurekaClient会定时向EurekaServer端发送心跳，如果EurekaServer在一定时间内没有收到EurekaClient发送的心跳，便会把该实例从注册服务列表中剔除（默认是90秒）。</li>
<li>b、但是在短时间内丢失大量的实例心跳，这时候EurekaServer会开启自我保护机制，Eureka不会踢出该服务。</li>
</ul>
</li>
<li><p>产生原因</p>
<p>   为了防止EurekaClient正常运行，但是与EurekaServer网络不通的情况下，EurekaServer不会对EurekaClient服务进行剔除。</p>
</li>
<li><p>何时使用</p>
<p> 本地环境建议禁止自我保护，生产环境建议开启自我保护。</p>
</li>
<li><p>如何配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">服务端</span><br><span class="line">server:</span><br><span class="line">    # 测试时关闭自我保护机制，保证不可用服务及时踢出</span><br><span class="line">    enable-self-preservation: false</span><br><span class="line">    ##剔除失效服务间隔</span><br><span class="line">    eviction-interval-timer-in-ms: 2000</span><br><span class="line"></span><br><span class="line">客户端：</span><br><span class="line">eureka:</span><br><span class="line"># 心跳检测检测与续约时间</span><br><span class="line"># 测试时将值设置设置小些，保证服务关闭后注册中心能及时踢出服务</span><br><span class="line">	client:</span><br><span class="line">		service-url:</span><br><span class="line">			defaultZone: http://localhost:8081/eureka/</span><br><span class="line">	instance:</span><br><span class="line">###Eureka客户端向服务端发送心跳的时间间隔，单位为秒（客户端告诉服务端自己会按照该规则）  </span><br><span class="line">    	lease-renewal-interval-in-seconds: 1</span><br><span class="line">####Eureka服务端在收到最后一次心跳之后等待的时间上限，单位为秒，超过则剔除（客户端告诉服务端按照此规则等待自己）</span><br><span class="line">    	lease-expiration-duration-in-seconds: 2</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>eureka</category>
      </categories>
      <tags>
        <tag>eureka</tag>
      </tags>
  </entry>
  <entry>
    <title>Eureka工作流程小记</title>
    <url>/2018/12/30/Eureka%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E5%B0%8F%E8%AE%B0/</url>
    <content><![CDATA[<p>Eureka保证AP（可用性、分区容错性）</p>
<p>Eureka Server各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余节点依然可以提供注册和查询服务。而Eureka Client在向某个Eureka注册时，如果发现连接失败，则会自动切换至其他节点。只要有一台Eureka Server还在，就能保证注册服务可用(保证可用性）。</p>
<p><strong>Eureka工作流程</strong></p>
<p>关于Eureka核心概念，自我保护机制、集群内工作原理请查看之前文章。以下对Eureka的工作流程进行整体梳理以下：</p>
<ul>
<li><p>1.Eureka Server启动成功，等待服务端注册。在启动过程中如果配置了集群，集群之间定时通过Replicate同步注册表，每个Eureka Server都存在独立完整的服务注册表信息。</p>
</li>
<li><p>2.Eureka Client启动时根据配置的Eureka Server地址去注册中心注册服务。</p>
</li>
<li><p>3.Eureka Client会每30s向Eureka Server发送一次心跳请求，证明客户端服务正常。</p>
</li>
<li><p>4.当Eureka Server 90s内没收到Eureka Client的心跳，注册中心则认为该节点失效，会注销该实例。</p>
</li>
<li><p>5.单位时间内Eureka Server统计到大量Eureka Client没有上送心跳，则认为可能为网络异常，进入自我保护机制，不再剔除没有上送心跳的客户端。</p>
</li>
<li><p>6.当Eureka Client心跳请求恢复正常之后，Eureka Server自动退出自我保护模式。</p>
</li>
<li><p>7.Eureka Client定时全量或增量从注册中心获取服务注册表，并且将获取到的信息缓存到本地</p>
</li>
<li><p>8.服务调用时，Eureka Client会先从本地缓存找寻调取的服务。如获取不到，先从注册中心刷新注册表，再同步到本地缓存。</p>
</li>
<li><p>9.Eureka Client获取到目标服务器信息，发起服务调用</p>
</li>
<li><p>10.Eureka Client程序关闭时向Eureka Server发送取消请求，Eureka Server将实例从注册表中删除。</p>
</li>
</ul>
<p><strong>点滴：</strong></p>
<ul>
<li>客户端主动通知注册中心下线</li>
</ul>
<p>如果你的Eureka Client是一个spring boot应用，可通过调用以下代码通知注册中心下线。<br>DiscoveryManager.getInstance().shutdownComponent()。</p>
<ul>
<li>服务器端配置：</li>
</ul>
<p><img src="/images/eureka_work_process_01/000001.png" alt="服务器端配置："></p>
<p>客户端配置：</p>
<p><img src="/images/eureka_work_process_01/000002.png" alt="客户端配置"></p>
]]></content>
      <categories>
        <category>eureka</category>
      </categories>
      <tags>
        <tag>eureka</tag>
      </tags>
  </entry>
  <entry>
    <title>JMM中happen-before八大规则</title>
    <url>/2019/02/23/JMM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B-happen-before%E5%8E%9F%E5%88%99/</url>
    <content><![CDATA[<p><strong>JMM中happen-before八大规则</strong></p>
<blockquote>
<p>java内存模型具备”有序性”，不需要其他方式就能保证有序性，称为先发生于原则。如果两个操作的执行次序无法从先发生于原则推导出，那么不能保证其有序性，这时jvm可以随意对其进行重排序。</p>
</blockquote>
<ul>
<li><p>a.程序次序规则（pragram order rule):同一线程内，按程序代码先后顺序执行。（程序代码中控制流先后顺序执行,不特指程序代码顺序，如：分支、循环结构）</p>
</li>
<li><p>b.管道/监视器锁定规则（monitor lock rule):同一个锁的lock先发生于unlock。</p>
</li>
<li><p>c.volatile变量规则（volatile variable rule):对volatile变量写操作先发生与对这个变量的读操作。（volatile变量写先于读）</p>
</li>
<li><p>d.线程启动规则（thread start rule):一个线程内的任何操作都必须在这个线程的start()方法之后调用。</p>
</li>
<li><p>e.线程加入规则（Thread join Rule): Thread对象的结束先发生于join方法返回。</p>
</li>
<li><p>f.线程中断规则（Thread Interruption rule):一个线程的所有操作都会在线程终止之前。</p>
</li>
</ul>
<ul>
<li><p>g.对象终结规则（Finalizer rule)：一个对象的终结操作必须在这个对象构造完成之后。</p>
</li>
<li><p>h.传递性（Transitivity):操作A先发生于操作B,操作B先发生于操作C，那么操作A先发生于操作C。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>JMM</category>
      </categories>
      <tags>
        <tag>JMM</tag>
        <tag>happen-before</tag>
      </tags>
  </entry>
  <entry>
    <title>Eureka高可用及数据一致性</title>
    <url>/2018/12/29/Eureka%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p><strong>一致性问题：</strong></p>
<p>服务注册中心不可能是单点的，一定会有一个集群，集群中服务注册信息如何保持一致性呢。</p>
<p> <img src="/images/eureka_01/0001.jpg" alt="Alt text">    </p>
<p><strong>Eureka是弱数据一致性的</strong></p>
<p>两个方面：</p>
<ul>
<li><p>什么是弱一致性</p>
<p>zookeeper也可实现数据注册中心，zookeeper是强一致性的。</p>
<p>分布式系统中存在一个重要理论：CAP</p>
</li>
</ul>
<p><img src="/images/eureka_01/0002.jpg" alt="Alt text">    </p>
<p>该理论提到了三个分布式系统的3个特性：</p>
<ul>
<li><p>Consistency 数据一致性<br>分布式系统中，数据存在多个节点中，有一些问题会导致写入数据时，一部分节点成功、一部分节点失败，造成数据不一致。</p>
<p>满足一致性要求对数据的更新操作成功后，多节点数据必须保持一致性。</p>
</li>
<li><p>Availability 可用性</p>
<p>客户端任何时候对集群读写操作，请求都能正常响应。</p>
</li>
<li><p>Partition Tolerance 分区容错性</p>
<p>集群部分节点故障，其他节点仍可用</p>
</li>
</ul>
<blockquote>
<p>CAP理论指明：这3个特性不能同时满足，最多满足2个。</p>
</blockquote>
<p>P是客观存在的，不可绕过，只是选择C还是选择A的问题。</p>
<p>Zookeeper是尽可能的保证数据一致性，某些情况下可牺牲可用性。</p>
<p>Eureka选择了A，所以Eureka具有高可用性，任何时候，服务消费者都能正常获取服务列表，但不保证数据的强一致性，消费者可能会拿到过期的服务列表。</p>
<p><img src="/images/eureka_01/0003.jpg" alt="Alt text">    </p>
<p>Eureka设计理念：保留可用及过期的数据总比丢掉可用数据好。</p>
<p><strong>2.Eureka数据同步方式</strong></p>
<p><strong>2.1复制方式</strong><br>分布式系统的数据在多个节点之间的复制方式，有两种：</p>
<ul>
<li><strong>主从复制</strong></li>
</ul>
<p>就是Master-Slave模式，有一个主节点，其他都是从节点，所有写操作都提交到主节点，再由主节点更新到其他从节点。</p>
<p>写的压力都集中在主节点上，这是系统的瓶颈，从节点可以分担读请求。</p>
<ul>
<li><strong>对等复制</strong></li>
</ul>
<p>Peer to Peer模式 节点部分主从，任何节点都可以接收写操作，然后每个节点间互相进行数据更新。</p>
<p>不存在写压力瓶颈，但各个节点数据同步时可能会有数据冲突。</p>
<p>Eureka采用的是 Peer to Peer 模式，对等复制。</p>
<p><strong>2.2同步过程</strong></p>
<p>Eureka Server本身依赖了Eureka Client,每个Eureka Client是作为其他Eureka Server的client</p>
<p>Eureka Server 启动后，会通过Eureka Client 请求其他Eureka Server节点中的一个节点，获取注册服务信息，然后复制到其他peer节点。</p>
<p>Eureka Server 每当自己的信息变更后，如Client向自己发起注册、续约、注销请求时，就会把自己的最新信息通知给其他Eureka Server，保持数据同步。</p>
<p><img src="/images/eureka_01/0004.jpg" alt="Alt text">    </p>
<p>如果自己的信息变更时另一个Eureka Server同步过来，这样再同步过去的话就出现数据同步死循环。</p>
<p><img src="/images/eureka_01/0005.jpg" alt="Alt text">    </p>
<p>Eureka Server再执行复制操作时，使用HEADER_REPLICATION这个 http header 来区分普通应用实例的正常请求，说明这是一个复制请求，这样其他peer节点收到请求时，就不会再对其进行复制操作，避免出现死循环。</p>
<p>数据冲突问题，Server_A向Server_B发起同步请求，如果A的数据比B的数据还旧，B不能接收A的数据，那么B如何知道A的数据是旧的，这时A该怎么办。</p>
<p>Eureka的数据新旧一般是通过版本号定义的，Eureka通过lastDirtyTimestamp这个类似版本号的属性来实现的。</p>
<blockquote>
<p>lastDirtyTimestamp 是注册中心里服务实例的一个属性，此服务实例最近一次变更时间。</p>
</blockquote>
<p>如Eureka Server A向Eureka Server B复制数据，数据冲突有2种情况。</p>
<p>1.A的数据比B的新，B返回404，A重新把这个应用实例注册到B。</p>
<p>2.A的数据比B的就，B返回409,要求A同步B的数据。</p>
<p><img src="/images/eureka_01/0006.jpg" alt="Alt text">    </p>
<p>另一个重要机制，heartbeat 心跳，续约操作，进行数据的最终修复，因为节点间的复制可能会出错，通过心跳可发现错误，进行弥补。</p>
<p>如发现某个应用实例数据与某个Server不一致，则Server返回404，实例重新注册即可。</p>
<p><strong>汇总：</strong></p>
<ul>
<li>Eureka是弱数据一致性，选择了CAP中的AP。</li>
<li>Eureka采用Peer to Peer 模式进行数据复制。</li>
<li>Eureka通过lastDirtyTimestamp解决复制冲突问题。</li>
<li>Eureka通过心跳机制实现数据修复。</li>
</ul>
]]></content>
      <categories>
        <category>eureka</category>
      </categories>
      <tags>
        <tag>eureka</tag>
      </tags>
  </entry>
  <entry>
    <title>Feign和Dubbo组件分析</title>
    <url>/2022/03/22/Feign%E5%92%8CDubbo%E7%BB%84%E4%BB%B6%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>在 Spring Cloud Alibaba 中，<strong>Feign</strong> 和 <strong>Dubbo</strong> 都是实现微服务间通信的关键组件，但它们的设计目标、协议支持和使用场景有显著差异。以下是两者的对比及适用场景分析：</p>
<hr>
<h3 id="一、核心区别"><a href="#一、核心区别" class="headerlink" title="一、核心区别"></a><strong>一、核心区别</strong></h3><table>
<thead>
<tr>
<th><strong>特性</strong></th>
<th><strong>Feign</strong></th>
<th><strong>Dubbo</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>通信协议</strong></td>
<td>基于 HTTP（RESTful 风格）</td>
<td>基于 TCP 的 RPC 协议（默认 Dubbo 协议）</td>
</tr>
<tr>
<td><strong>序列化</strong></td>
<td>通常使用 JSON（HTTP Body）</td>
<td>支持多种序列化（Hessian、Kryo、Protobuf 等）</td>
</tr>
<tr>
<td><strong>性能</strong></td>
<td>较低（HTTP 协议开销较大）</td>
<td>高（二进制协议 + 长连接）</td>
</tr>
<tr>
<td><strong>服务治理</strong></td>
<td>依赖 Spring Cloud 生态（Ribbon、Sentinel 等）</td>
<td>内置负载均衡、熔断、容错等治理能力</td>
</tr>
<tr>
<td><strong>跨语言支持</strong></td>
<td>较好（基于 HTTP + JSON）</td>
<td>有限（需依赖 Dubbo 多语言 SDK，如 Dubbo-go）</td>
</tr>
<tr>
<td><strong>适用场景</strong></td>
<td>轻量级 RESTful 调用、多语言异构系统</td>
<td>高性能内部服务调用、复杂服务治理需求</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="二、使用场景分析"><a href="#二、使用场景分析" class="headerlink" title="二、使用场景分析"></a><strong>二、使用场景分析</strong></h3><h4 id="1-选择-Feign-的场景"><a href="#1-选择-Feign-的场景" class="headerlink" title="1. 选择 Feign 的场景"></a><strong>1. 选择 Feign 的场景</strong></h4><ul>
<li><p><strong>场景 1：RESTful 接口调用</strong><br>需要调用外部服务暴露的 HTTP API（如第三方服务或跨团队服务），且接口符合 RESTful 规范。</p>
</li>
<li><p><strong>场景 2：简单服务治理需求</strong><br>服务治理依赖 Spring Cloud 生态（如 Nacos 服务发现、Sentinel 熔断），无需复杂路由或分组策略。</p>
</li>
<li><p><strong>场景 3：跨语言协作</strong><br>系统需要与非 Java 服务（如 Node.js、Python）交互，基于 HTTP + JSON 协议更通用。</p>
</li>
<li><p><strong>示例代码</strong>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@FeignClient</span>(name = <span class="string">"order-service"</span>, fallback = OrderServiceFallback<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class"><span class="title">public</span> <span class="title">interface</span> <span class="title">OrderServiceClient</span> </span>&#123;</span><br><span class="line">    <span class="meta">@GetMapping</span>(<span class="string">"/orders/&#123;id&#125;"</span>)</span><br><span class="line">    <span class="function">Order <span class="title">getOrder</span><span class="params">(@PathVariable Long id)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="2-选择-Dubbo-的场景"><a href="#2-选择-Dubbo-的场景" class="headerlink" title="2. 选择 Dubbo 的场景"></a><strong>2. 选择 Dubbo 的场景</strong></h4><ul>
<li><p><strong>场景 1：高性能内部服务调用</strong><br>服务间调用频繁且对延迟敏感（如订单扣减库存、支付核心链路），需减少网络开销。</p>
</li>
<li><p><strong>场景 2：复杂服务治理需求</strong><br>需要细粒度控制（如方法级负载均衡、服务分组、版本控制、隐式参数传递）。</p>
</li>
<li><p><strong>场景 3：遗留系统迁移</strong><br>已有 Dubbo 体系的历史系统迁移到 Spring Cloud Alibaba，需保留原有 RPC 调用方式。</p>
</li>
<li><p><strong>示例代码</strong>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@DubboService</span>(version = <span class="string">"1.0.0"</span>, group = <span class="string">"order"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderServiceImpl</span> <span class="keyword">implements</span> <span class="title">OrderService</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Order <span class="title">getOrder</span><span class="params">(Long id)</span> </span>&#123; <span class="comment">/* ... */</span> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Reference</span>(version = <span class="string">"1.0.0"</span>, group = <span class="string">"order"</span>)</span><br><span class="line"><span class="keyword">private</span> OrderService orderService;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="三、混合使用-Feign-和-Dubbo-的场景"><a href="#三、混合使用-Feign-和-Dubbo-的场景" class="headerlink" title="三、混合使用 Feign 和 Dubbo 的场景"></a><strong>三、混合使用 Feign 和 Dubbo 的场景</strong></h3><ul>
<li><p><strong>场景 1：内外分离架构</strong>  </p>
<ul>
<li><strong>内部服务</strong>：使用 Dubbo 实现高性能 RPC 调用（如订单服务调用库存服务）。  </li>
<li><strong>外部 API</strong>：使用 Feign 暴露 RESTful 接口给前端或第三方调用。</li>
</ul>
</li>
<li><p><strong>场景 2：逐步迁移</strong>  </p>
<ul>
<li>旧 Dubbo 服务逐步迁移到 Spring Cloud Alibaba，新服务使用 Feign。  </li>
<li>通过 Nacos 统一管理两种服务的注册发现。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="四、配置差异与注意事项"><a href="#四、配置差异与注意事项" class="headerlink" title="四、配置差异与注意事项"></a><strong>四、配置差异与注意事项</strong></h3><h4 id="1-Feign-配置要点"><a href="#1-Feign-配置要点" class="headerlink" title="1. Feign 配置要点"></a><strong>1. Feign 配置要点</strong></h4><ul>
<li><p><strong>依赖</strong>：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-openfeign<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-alibaba-sentinel<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>关键配置</strong>：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">feign:</span></span><br><span class="line">  <span class="attr">sentinel:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span>  <span class="comment"># 启用 Sentinel 熔断</span></span><br><span class="line">  <span class="attr">client:</span></span><br><span class="line">    <span class="attr">config:</span></span><br><span class="line">      <span class="attr">default:</span></span><br><span class="line">        <span class="attr">connectTimeout:</span> <span class="number">3000</span>  <span class="comment"># 连接超时</span></span><br><span class="line">        <span class="attr">readTimeout:</span> <span class="number">5000</span>     <span class="comment"># 读取超时</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="2-Dubbo-配置要点"><a href="#2-Dubbo-配置要点" class="headerlink" title="2. Dubbo 配置要点"></a><strong>2. Dubbo 配置要点</strong></h4><ul>
<li><p><strong>依赖</strong>：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-dubbo<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>关键配置</strong>：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">dubbo:</span></span><br><span class="line">  <span class="attr">scan:</span></span><br><span class="line">    <span class="attr">base-packages:</span> <span class="string">com.example.service</span>  <span class="comment"># Dubbo 服务扫描包</span></span><br><span class="line">  <span class="attr">protocol:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">dubbo</span>  <span class="comment"># 使用 Dubbo 协议</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">20880</span>  <span class="comment"># 服务暴露端口</span></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">address:</span> <span class="string">nacos://localhost:8848</span>  <span class="comment"># 注册中心地址</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<h3 id="五、决策建议"><a href="#五、决策建议" class="headerlink" title="五、决策建议"></a><strong>五、决策建议</strong></h3><table>
<thead>
<tr>
<th><strong>维度</strong></th>
<th><strong>选择 Feign</strong></th>
<th><strong>选择 Dubbo</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>协议需求</strong></td>
<td>RESTful/HTTP，需跨语言调用</td>
<td>高性能 RPC，内部服务通信</td>
</tr>
<tr>
<td><strong>性能要求</strong></td>
<td>可接受 HTTP 开销（QPS &lt; 1k）</td>
<td>高并发、低延迟（QPS &gt; 1k）</td>
</tr>
<tr>
<td><strong>服务治理</strong></td>
<td>依赖 Spring Cloud 生态（Sentinel、Gateway）</td>
<td>需要内置高级治理（路由、分组、权重）</td>
</tr>
<tr>
<td><strong>开发成本</strong></td>
<td>低（注解驱动，与 Spring MVC 兼容）</td>
<td>中（需配置协议、序列化、服务暴露）</td>
</tr>
<tr>
<td><strong>团队经验</strong></td>
<td>熟悉 Spring Cloud 技术栈</td>
<td>熟悉 Dubbo 或历史系统迁移需求</td>
</tr>
</tbody>
</table>
<hr>
<h3 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a><strong>六、总结</strong></h3><ul>
<li><strong>Feign</strong>：适合轻量级 RESTful 调用、跨语言协作，与 Spring Cloud 生态无缝集成。  </li>
<li><strong>Dubbo</strong>：适合高性能内部服务、复杂治理场景，提供更细粒度的 RPC 控制。  </li>
<li><strong>混合架构</strong>：内外服务分离时，可组合使用 Feign（对外）和 Dubbo（对内），通过 Nacos 统一治理。  </li>
</ul>
<p>根据业务需求、性能指标和技术栈成熟度选择工具，避免过度设计。</p>
]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>GC收集器优劣势及适用场景</title>
    <url>/2020/08/29/GC%E4%BC%98%E5%8A%A3%E5%8A%BF%E5%8F%8A%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    <content><![CDATA[<p>JVM垃圾收集器特点、优劣势及使用场景</p>
<p><strong>一、常见垃圾收集器</strong></p>
<ul>
<li><p><strong>新生代收集器</strong></p>
<ul>
<li><p>Serial</p>
</li>
<li><p>ParNew</p>
</li>
<li><p>Parallel Scavenge</p>
</li>
</ul>
</li>
<li><p><strong>老年代收集器</strong></p>
<ul>
<li><p>Serial Old</p>
</li>
<li><p>CMS</p>
</li>
<li><p>Parallel Old</p>
</li>
</ul>
</li>
<li><p>堆内存垃圾收集器:G1</p>
</li>
</ul>
<p>垃圾收集器之间有连线，标识可搭配使用。</p>
<p><img src="/images/GC-INFO/000001.png" alt="Alt text"></p>
<p><strong>二、新生代垃圾收集器</strong></p>
<ul>
<li>Serial收集器 [‘sɪəriəl]、[‘sɪriəl] </li>
</ul>
<p>Serial是新生代的单线程收集器，采用复制算法进行垃圾收集，进行垃圾回收时，不仅只有一条线程执行垃圾收集，而且收集同时所有用户线程必须暂停(Stop The World).</p>
<p>例如：环卫工人打扫马路卫生，肯定不会让人往地上乱扔纸屑，否则一边制造垃圾、一边清理垃圾，这活啥时候也干不完。</p>
<p>Serial收集器和Serial Old收集器结合进行垃圾收集的示图，当用户线程都执行到安全点时，所有线程暂停执行，Serial收集器以单线程，采用复制算法进行收集工作，收集完之后，用户线程继续开始执行。</p>
<p><img src="/images/GC-INFO/000002.png" alt="Alt text"></p>
<p><strong>使用场景：</strong></p>
<p>Client模式（桌面应用）；单核服务器。可用-XX:+UserSerialGC来选择Serial作为新生代收集器。</p>
<ul>
<li><p>ParNew收集器</p>
<p>ParNew就是一个Serial的多线程版，其他与Serial并无区别。ParNew在单核CPU环境并不会比Serial收集器达到更好的效率。它默认开启的收集线程数和CPU数量一致，可通过-XX:ParallelGCThreads来设置垃圾收集的线程数。</p>
<p>如下ParNew收集器和Serial Old收集器结合进行垃圾收集的示图，当用户线程都执行到安全点时，所有线程暂停执行，ParNew收集器以多线程、复制算法进行垃圾收集工作，收集完之后，用户线程继续开始执行。</p>
</li>
</ul>
<p><img src="/images/GC-INFO/000003.png" alt="Alt text"></p>
<p><strong>适用场景</strong></p>
<p>多核服务器；与CMS收集器搭配使用。当时用-XX：+UserConcMarkSweepGC来选择CMS作为老年代收集器时，新生代收集器默认就是ParNew,也可以用-XX:+UserParNewGC来指定使用ParNew作为新生代收集器。</p>
<ul>
<li>Parallel Scavenge收集器</li>
</ul>
<p>Parallel Scavenge是一款新生代多线程，与ParNew的不同之处是，ParNew目标是尽可能缩短垃圾收集时用户线程的停顿时间，Parallel Scavenge的目标是达到一个可控制的吞吐量。</p>
<p>吞吐量就是CPU执行用户线程的时间与CPU执行总时间的比值【吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间）】，比如虚拟机一共运行了100分钟，其中垃圾收集花费1分钟，那吞吐量就是99%。比如下面两个场景，垃圾收集器每 100 秒收集一次，每次停顿 10 秒，和垃圾收集器每 50 秒收集一次，每次停顿时间 7 秒，虽然后者每次停顿时间变短了，但是总体吞吐量变低了，CPU 总体利用率变低了。</p>
<p><img src="/images/GC-INFO/000004.png" alt="Alt text"></p>
<p>可通过-XX:MaxGCPauseMillis来设置收集器尽可能在多长时间内完成内存回收，可通过-XX:GCTimeRatio来精确控制吞吐量。</p>
<p>如下是 Parallel 收集器和 Parallel Old 收集器结合进行垃圾收集的示意图，在新生代，当用户线程都执行到安全点时，所有线程暂停执行，ParNew 收集器以多线程，采用复制算法进行垃圾收集工作，收集完之后，用户线程继续开始执行；在老年代，当用户线程都执行到安全点时，所有线程暂停执行，Parallel Old 收集器以多线程，采用标记整理算法进行垃圾收集工作。</p>
<p><img src="/images/GC-INFO/000005.png" alt="Alt text"></p>
<p><strong>适用场景：</strong></p>
<p>注重吞吐量，高效利用 CPU，需要高效运算且不需要太多交互。</p>
<p>可以使用 -XX:+UseParallelGC 来选择 Parallel Scavenge 作为新生代收集器，jdk7、jdk8 默认使用 Parallel Scavenge 作为新生代收集器。</p>
<p><strong>老年代垃圾收集器</strong></p>
<ul>
<li>Serial Old收集器</li>
</ul>
<p>Serial Old收集器是Serial的老年代版本，同样是一个单线程收集器，采用标记-整理算法。</p>
<p>如图是Serial收集器和Serial Old收集器结合进行垃圾收集示意图</p>
<p><img src="/images/GC-INFO/000006.png" alt="Alt text"></p>
<p><strong>适用场景：</strong></p>
<p>Client 模式（桌面应用）；单核服务器；与 Parallel Scavenge 收集器搭配；作为 CMS 收集器的后备预案。</p>
<ul>
<li>CMS(Concurrent Mark Sweep) 收集器</li>
</ul>
<p>CMS 收集器是一种以最短回收停顿时间为目标的收集器，以 “ 最短用户线程停顿时间 ” 著称。整个垃圾收集过程分为 4 个步骤：</p>
<ul>
<li><p>① 初始标记：标记一下 GC Roots 能直接关联到的对象，速度较快。</p>
</li>
<li><p>② 并发标记：进行 GC Roots Tracing，标记出全部的垃圾对象，耗时较长。</p>
</li>
<li><p>③ 重新标记：修正并发标记阶段引用户程序继续运行而导致变化的对象的标记记录，耗时较短。</p>
</li>
<li><p>④ 并发清除：用标记-清除算法清除垃圾对象，耗时较长。</p>
</li>
</ul>
<p>整个过程耗时最长的并发标记和并发清除都是和用户线程一起工作，所以从总体上来说，CMS 收集器垃圾收集可以看做是和用户线程并发执行的。</p>
<p><img src="/images/GC-INFO/000007.png" alt="Alt text"></p>
<p><strong>CMS 收集器也存在一些缺点：</strong></p>
<p>对 CPU 资源敏感：默认分配的垃圾收集线程数为（CPU 数+3）/4，随着 CPU 数量下降，占用 CPU 资源越多，吞吐量越小</p>
<p>无法处理浮动垃圾：在并发清理阶段，由于用户线程还在运行，还会不断产生新的垃圾，CMS 收集器无法在当次收集中清除这部分垃圾。同时由于在垃圾收集阶段用户线程也在并发执行，CMS 收集器不能像其他收集器那样等老年代被填满时再进行收集，需要预留一部分空间提供用户线程运行使用。当 CMS 运行时，预留的内存空间无法满足用户线程的需要，就会出现 “ Concurrent Mode Failure ”的错误，这时将会启动后备预案，临时用 Serial Old 来重新进行老年代的垃圾收集。</p>
<p>因为 CMS 是基于标记-清除算法，所以垃圾回收后会产生空间碎片，可以通过 -XX:UserCMSCompactAtFullCollection 开启碎片整理（默认开启），在 CMS 进行 Full GC 之前，会进行内存碎片的整理。还可以用 -XX:CMSFullGCsBeforeCompaction 设置执行多少次不压缩（不进行碎片整理）的 Full GC 之后，跟着来一次带压缩（碎片整理）的 Full GC。</p>
<ul>
<li><p>适用场景：</p>
<p>  重视服务器响应速度，要求系统停顿时间最短。可以使用 -XX:+UserConMarkSweepGC 来选择 CMS 作为老年代收集器。</p>
</li>
<li><p>Parallel Old 收集器</p>
</li>
</ul>
<p>Parallel Old 收集器是 Parallel Scavenge 的老年代版本，是一个多线程收集器，采用标记-整理算法。可以与 Parallel Scavenge 收集器搭配，可以充分利用多核 CPU 的计算能力。</p>
<p><img src="/images/GC-INFO/000008.png" alt="Alt text"></p>
<p><strong>适用场景：</strong></p>
<p>与Parallel Scavenge 收集器搭配使用；注重吞吐量。jdk7、jdk8 默认使用该收集器作为老年代收集器，使用 -XX:+UseParallelOldGC 来指定使用 Paralle Old 收集器。</p>
<p> <strong>新生代和老年代垃圾收集器</strong></p>
<ul>
<li>G1收集器</li>
</ul>
<p>G1 收集器是 jdk1.7 才正式引用的商用收集器，现在已经成为 jdk9 默认的收集器。前面几款收集器收集的范围都是新生代或者老年代，G1 进行垃圾收集的范围是整个堆内存，它采用 “ 化整为零 ” 的思路，把整个堆内存划分为多个大小相等的独立区域（Region），在 G1 收集器中还保留着新生代和老年代的概念，它们分别都是一部分 Region，如下图：</p>
<p><img src="/images/GC-INFO/000009.png" alt="Alt text"></p>
<p>每一个方块就是一个区域，每个区域可能是 Eden、Survivor、老年代，每种区域的数量也不一定。JVM 启动时会自动设置每个区域的大小（1M ~ 32M，必须是 2 的次幂），最多可以设置 2048 个区域（即支持的最大堆内存为 32M*2048 = 64G），假如设置 -Xmx8g -Xms8g，则每个区域大小为 8g/2048=4M。</p>
<p>为了在 GC Roots Tracing 的时候避免扫描全堆，在每个 Region 中，都有一个 Remembered Set 来实时记录该区域内的引用类型数据与其他区域数据的引用关系（在前面的几款分代收集中，新生代、老年代中也有一个 Remembered Set 来实时记录与其他区域的引用关系），在标记时直接参考这些引用关系就可以知道这些对象是否应该被清除，而不用扫描全堆的数据。</p>
<p>G1 收集器可以 “ 建立可预测的停顿时间模型 ”，它维护了一个列表用于记录每个 Region 回收的价值大小（回收后获得的空间大小以及回收所需时间的经验值），这样可以保证 G1 收集器在有限的时间内可以获得最大的回收效率。</p>
<p><strong>如下图所示，G1 收集器收集器收集过程有初始标记、并发标记、最终标记、筛选回收，和 CMS 收集器前几步的收集过程很相似：</strong></p>
<p><img src="/images/GC-INFO/0000010.png" alt="Alt text"></p>
<ul>
<li><p>① 初始标记：标记出 GC Roots 直接关联的对象，这个阶段速度较快，需要停止用户线程，单线程执行。</p>
</li>
<li><p>② 并发标记：从 GC Root 开始对堆中的对象进行可达新分析，找出存活对象，这个阶段耗时较长，但可以和用户线程并发执行。</p>
</li>
<li><p>③ 最终标记：修正在并发标记阶段引用户程序执行而产生变动的标记记录。</p>
</li>
<li><p>④ 筛选回收：筛选回收阶段会对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来指定回收计划（用最少的时间来回收包含垃圾最多的区域，这就是 Garbage First 的由来——第一时间清理垃圾最多的区块），这里为了提高回收效率，并没有采用和用户线程并发执行的方式，而是停顿用户线程。</p>
</li>
</ul>
<p><strong>适用场景：</strong></p>
<p>要求尽可能可控 GC 停顿时间；内存占用较大的应用。可以用 -XX:+UseG1GC 使用 G1 收集器，jdk9 默认使用 G1 收集器。</p>
<p><strong>JVM垃圾收集器总结</strong></p>
<p>本文主要介绍了JVM中的垃圾回收器，主要包括串行回收器、并行回收器以及CMS回收器、G1回收器。他们各自都有优缺点，通常来说你需要根据你的业务，进行基于垃圾回收器的性能测试，然后再做选择。下面给出配置回收器时，经常使用的参数：</p>
<pre><code>-XX:+UseSerialGC：在新生代和老年代使用串行收集器

-XX:+UseParNewGC：在新生代使用并行收集器

-XX:+UseParallelGC ：新生代使用并行回收收集器，更加关注吞吐量

-XX:+UseParallelOldGC：老年代使用并行回收收集器

-XX:ParallelGCThreads：设置用于垃圾回收的线程数

-XX:+UseConcMarkSweepGC：新生代使用并行收集器，老年代使用CMS+串行收集器

-XX:ParallelCMSThreads：设定CMS的线程数量

-XX:+UseG1GC：启用G1垃圾回收器
</code></pre>]]></content>
      <categories>
        <category>GC</category>
      </categories>
      <tags>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK自带定时任务</title>
    <url>/2015/07/12/JDK%E8%87%AA%E5%B8%A6%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</url>
    <content><![CDATA[<p><strong>Java定时任务调度详解</strong></p>
<ul>
<li>Timer</li>
<li>ScheduleExecutorService</li>
<li>开源工具包 Quartz</li>
<li>Spring和Quartz结合</li>
</ul>
<p><strong>JDK原生定时工具：Timer</strong></p>
<p>   定时任务调度：基于给定的时间点、给定的时间间隔、给定的执行次数自动执行的任务。</p>
<p>   Timer位于java.util包下，内部包含且仅包含一个后台线程(TimeThread)对多个业务任务<br>   (TimeTask)进行定时定频率的调度。</p>
<p> Schedule的四种用法和ScheduleAtFixedRate的用法</p>
<pre><code>public void schedule(TimerTask task,long delay);
public void schedule(TimerTask task,Date time);
public void schedule(TimerTask task,long delay,long period);
public void schedule(TimerTask task,Date firstTime,long period);
public void scheduleAtFixedRate(TimerTask task,long delay,long period);
public void scheduleAtFixedRate(TimerTask task,Date
firstTime,long period);

参数说明：
task:所要执行的任务，需要extends TimeTask overried run()
time/firstTime:首次执行任务的时间
period:周期性执行task的时间间隔，单位为毫秒
delay:执行task任务前的延迟时间，单位为毫秒
通过上述描述可实现：

延迟多久后执行一次任务；
指定时间执行一次任务；
延迟一段时间，并周期性执行任务；
指定时间，并周期性执行任务；
</code></pre><p>  <strong>思考1：如果time/firstTime指定的时间，在当前时间之前，会发生什么？</strong></p>
<p>   在时间等于或者超过time/firstTime的时候，会执行task.即time/firstTime指定的时间在当前时间之前，就会立即执行。</p>
<p>  <strong>思考2：schedule和scheduleAtFixedRate有何区别？</strong></p>
<p>  <strong>scheduleAtFixedRate：</strong> 每次执行时间为上一次任务开始起向后推一个period间隔，也就是说下次执行时间相对于上一次任务开始的时间点，因此执行时间不会延后，但是存在任务并发执行的问题。</p>
<p> <strong>schedule:</strong> 每次执行时间为上一次任务结束后推一个period间隔，也就是说下次执行时间相对于上一次任务结束的时间点，因此执行时间会不断延后。</p>
<p><strong>思考3：如果执行task发生异常，是否会影响其他task的定时调度？</strong></p>
<p>  如果TimeTask抛出RuntimeException，那么Timer会停止所有任务的运行。</p>
<p><strong>思考4：Timer的一些缺陷？</strong></p>
<p>  Timer背后是一个单线程，因此Timer存在管理并发任务的缺陷；所有任务都是由同一个线程来调度，所有任务都是串行执行，同一时间只能有一个任务得到执行，而前一个任务的延迟或者异常会影响到之后的任务。<br>   其次，Timer的一些调度方式还算简单，无法适应实际项目中任务定时调度的复杂度。</p>
<p>  <strong>一个简单的Demo范例：</strong></p>
<pre><code>public class Timerdemo{

    public static void main(String[] args){
      Timer timer = new Timer();
      Calendar calendar = Calendar.getInstance();
      // timer.schedule(new MyTask(),calendar.getTime(),1000);
      timer.scheduleAtFixedRate(new MyTask(),calendar.getTime(),1000);    
   }
}

class MyTask extends TimerTask{

    @override
    public void run(){

        Sysout(&quot;executor time start is :&quot;+new Simple
        DateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;).format(this.scheduleExecutorTime()));
        try{
            Thread.sleep(2000);
        }catch(InterruptedException e){
            e.printStackTrace();
        }
    }
}
</code></pre><p><img src="/images/timer/outResult1.jpg" alt="Alt text"></p>
<p> <strong>Timer其他需要关注的方法</strong></p>
<p>  cancel():终止Timer计时器，丢弃所有当前已安排的任务（TimeTasky也存在cancel()方法，不过终止的是TimeTask);</p>
<p>  purge(): 从计时器的任务队列中移除已取消的任务，并返回个数。</p>
<p><strong>JDK对定时任务调度的线程池支持：ScheduleExecutorService</strong></p>
<p>  由于Timer存在的问题，JDK5之后便提供了基于线程池的定时任务调度：ScheduleExecutorService。</p>
<p>  设计理念： 每一个被调度的任务都会被线程池中的一个线程去执行，因此任务可以并发执行，而且相互之间不受影响。</p>
<p>  <strong>范例：</strong></p>
<pre><code>public class ScheduleExecutorServiceDemo implements Runnable{

    @override
    public void run(){
        Sysout(&quot;执行：&quot;+new Date());
    }

    public static void mian(String[] args){

        ScheduleExecutorService scheduleExecutorService  = Executors.newScheduleThreadPool(10);
        scheduleExecutorService.scheduleAtFixedRate(new ScheduleExecutorServiceDemo(),1000,2000,TimeUnit.MILLISECONDS);
    }
}
</code></pre><p><img src="/images/timer/outResult2.jpg" alt="Alt text"></p>
<p><strong>定时任务大哥：Quartz</strong></p>
<p>  虽然ScheduledExecutorService对Timer进行了线程池的改进，但依然无法满足复杂的定时任务调度场景。因此OpenSymphony提供了强大的开源任务调度框架Quartz。<br>  Quartz是纯java实现，而且作为spring的默认调度框架，由于Quartz的强大调度功能、灵活的使用方式、还具有分布式集群能力，可以说Quartz可以搞定一切的调度任务。</p>
<p> <strong>Quartz的体系结构：</strong></p>
<p><img src="/images/timer/quartz-01.jpg" alt="Alt text"></p>
<pre><code>public class MyJob implements Job{

    @overried
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException{
       Sysout(&quot;执行&quot;+ new Date()+&quot;,&quot;+jobExecutionContext.getJobDetail().getJobDataMap().get(&quot;name&quot;));    
    }
}

public class QuartzDemo{
    public static void main(String[] args){

        JobDetail jobDetail = JobBuilder.newJob(MyJob.class).withIdentity(&quot;myJob&quot;,&quot;myGroup&quot;)
                     .usingJobData(&quot;name&quot;,&quot;zhangfengzhe&quot;)
                     .build();
      //每两秒执行一次，直到永远
      Trigger trigger = TriggerBuilder.newTrigger()
                        .withIdentity(&quot;triggerName&quot;,&quot;triggerGroup&quot;).withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(2).repeatForever())
                        .startNow().build();

        ScheduleFactory scheduleFactory = new StdSchedulerFactory();
        Schedule schedule = scheduleFactory.getSchedule();
        schedule.scheduleJob(jobDetail,trigger);
        schedule.start();
    }
}
</code></pre><p> 说明：<br>    1.从代码看，有XxxBuilder、XxxFactory，说明Quartz用到了Builder、Factory模式，易懂的链式编码风格。</p>
<pre><code>2.Quartz有3个核心概念：调度器（Scheduler)、任务（Job&amp;&amp;JobDetail)、触发器（Trigger)。（一个任务可以被多个触发器触发，一个触发器只能触发一个任务）

3.当Schedule调度Job时，实际上会通过反射newInstance一个新的Job实例（待调度完毕后销毁），同事会把JobExecutionContext传递给Job的execute方法，Job实例通过JobExecutionContext访问到Quartz运行时环境和Job本省的明细数据。

4.JobDataMap可以装载任何可以序列化的数据，存取方便。要注意JobDetail和Trigger都可以各自关联上JobDataMap。JobDataMap除了可以通过上诉代码获取外，还可以在YourJob实现类中，添加相应setter方法获取。

5.Trigger用来告诉Quartz调度程序什么时候执行，常用的触发器有两种：SimpleTrigger（类似Timer）、CronTrigger（类似于linux的CronTab)。

6.Quartz在进行调度器初始化的时候，会加载quartz.properties文件进行一些属性的设置，比如Quartz后台线程池的属性（threadCount)、作业存储设置等。会先从项目中找，如找不到那么就是用quartz.jar中默认的quartz.properties文件。

7.Quartz存在监听器的概念，如任务执行前后，任务的添加等，方便实现任务的监控。
</code></pre><p> <strong>CronTrigger示例：</strong></p>
<p><img src="/images/timer/cronTrigger-01.jpg" alt="Alt text"></p>
<p><img src="/images/timer/cronTrigger-02.jpg" alt="Alt text"></p>
<p><img src="/images/timer/cronTrigger-03.jpg" alt="Alt text"></p>
<p>这里给出一些常用的示例：<br>    0 15 10 ? <em> 每天10点15分触发<br>    0 15 10 ? 2017 2017年每天10点15分触发<br>    0 14 </em> ? 每天下午的 2点到2点59分每分触发<br>    0 0/5 14 ? 每天下午的 2点到2点59分(整点开始，每隔5分触发)<br>    0 0/5 14,18 ? 每天下午的 2点到2点59分、18点到18点59分(整点开始，每隔5分触发)<br>    0 0-5 14 ? 每天下午的 2点到2点05分每分触发<br>    0 15 10 ? <em> 6L 每月最后一周的星期五的10点15分触发<br>    0 15 10 ? </em> 6#3 每月的第三周的星期五开始触发<br>我们可以通过一些Cron在线工具非常方便的生成，比如<a href="http://www.pppet.net/等。" target="_blank" rel="noopener">http://www.pppet.net/等。</a></p>
<p><strong>Spring和Quartz的整合</strong></p>
<p>实际上，Quartz和Spring结合是很方便的，无非就是进行一些配置。大概基于2种方式：<br>第一，普通的类，普通的方法，直接在配置中指定（MethodInvokingJobDetailFactoryBean）。<br>第二，需要继承QuartzJobBean，复写指定方法（executeInternal）即可。<br>然后，就是一些触发器、调度器的配置了，这里不再展开介绍了，只要弄懂了原生的Quartz的使用，那么和Spring的结合使用就会很简单。</p>
]]></content>
      <categories>
        <category>定时任务</category>
      </categories>
      <tags>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM简略汇总</title>
    <url>/2018/04/21/JVM%E7%AE%80%E7%95%A5%E6%B1%87%E6%80%BB_01/</url>
    <content><![CDATA[<p><strong>jvm</strong></p>
<p><strong>java代码的执行</strong></p>
<ul>
<li><p>代码编译为class  javac</p>
</li>
<li><p>装载class  classloader</p>
</li>
<li><p>执行class  </p>
<ul>
<li><p>解释执行 client complier</p>
</li>
<li><p>编译执行 client complier</p>
</li>
</ul>
</li>
</ul>
<p><strong>JVM内存区域</strong></p>
<ul>
<li><p>程序计数器（线程私有)</p>
<ul>
<li>指向虚拟机字节码的位置</li>
<li>唯一一个无OOM的区域</li>
</ul>
</li>
<li><p>虚拟机栈（线程私有）</p>
<ul>
<li>虚拟机栈和线程的生命周期相同</li>
<li>一个线程中，每调用一个方法创建一个栈帧（Stack Frame)</li>
<li>栈帧的结构<ul>
<li>本地变量表Local Variable</li>
<li>操作数栈 Operand Stack</li>
<li>对运行时常量池的引用(Runtime Constant Pool Reference)</li>
</ul>
</li>
<li>异常<ul>
<li>线程请求的栈深度大于JVM所允许的深度（StackOverflowError）</li>
<li>若JVM允许动态扩展，若无法申请到足够内存(OutOfMemoryError)</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>本地方法区Native Method Stack（线程私有）<ul>
<li>异常<ul>
<li>线程请求的栈深度大于JVM所允许的深度(StackOverflowError)</li>
<li>若JVM允许动态扩展，当无法申请到足够内存(OutOfMemoryError)</li>
</ul>
</li>
</ul>
</li>
<li><p>堆（Heap-线程共享）-运行时数据区</p>
<ul>
<li><p>新生代</p>
<ul>
<li>eden</li>
<li>from survivor</li>
<li>to survivor</li>
</ul>
</li>
<li><p>老年代</p>
</li>
<li>异常 OutOfMemoryError</li>
</ul>
</li>
<li><p>方法区/永久代（线程共享)</p>
<ul>
<li>运行时常量池Runtime Constant Pool</li>
</ul>
</li>
<li><p>内存分配</p>
<ul>
<li>堆上分配</li>
<li>TLAB分配</li>
<li>栈上分配</li>
</ul>
</li>
<li><p>内存状况分析</p>
<ul>
<li>jconsole</li>
<li>visualvm</li>
<li>jstat</li>
<li>jmap</li>
<li>MAT</li>
</ul>
</li>
</ul>
<p><strong>JVM运行时内存</strong></p>
<p><strong>新生代</strong></p>
<ul>
<li>Eden区</li>
<li>ServivorFrom</li>
<li><p>ServivorTo</p>
</li>
<li><p>MinorGC的过程(复制-清空-互换）</p>
<ul>
<li>eden、servivorFrom复制到ServivorTo，年龄+1</li>
<li>清空eden、servivorFrom</li>
<li>ServivorTo和Servivor互换</li>
</ul>
</li>
</ul>
<p><strong>老年代</strong></p>
<p><strong>永久代(JAVA8改为元数据区)</strong></p>
<p><strong>垃圾回收与算法</strong></p>
<ul>
<li>如何确定垃圾<ul>
<li>引用计数法<ul>
<li>循环引用的问题</li>
</ul>
</li>
<li>可达性分析<ul>
<li>通过一系列成为GC Roots的点作为起点，向下搜索，当一个对象到任何GC Roots没有引用链相连，则表示其已死亡</li>
</ul>
</li>
<li>GC Roots<ul>
<li>VM栈中的引用</li>
<li>方法区中静态引用</li>
<li>JNI中的引用</li>
</ul>
</li>
</ul>
</li>
<li><p>算法</p>
<ul>
<li><p>标记清除算法（Mark-Sweep)</p>
<ul>
<li>效率低</li>
<li>内存碎片多</li>
</ul>
</li>
<li><p>复制算法（copying)</p>
<ul>
<li>eden</li>
<li>survivor</li>
</ul>
</li>
<li><p>标记整理算法（Mark-Compact)</p>
</li>
<li><p>分代收集算法</p>
<ul>
<li><p>新生代 复制算法</p>
</li>
<li><p>老年代 标记复制算法</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>JAVA四种引用类型</strong></p>
<ul>
<li>强引用</li>
<li>软引用</li>
<li>弱引用</li>
<li>虚引用</li>
</ul>
<p>GC粉黛收集算法VS分区收集算法</p>
<p><strong>分代收集算法</strong></p>
<ul>
<li><p>新生代-复制算法</p>
<ul>
<li><p>分代回收 </p>
<pre><code>- 新生代可用的GC
    - 串行copying
    - 并行回收copying
    - 并行copying

- Minor GC触发机制以及日志格式
- 老年代可用的GC
    - 串行Mark-Sweep-Compact
    - 并行Compacting
    - 并发Mark-Sweep
- Full GC出发机制以及日志格式
</code></pre></li>
</ul>
</li>
<li>老年代-标记整理算法</li>
</ul>
<p><strong>分区收集算法</strong></p>
<p><strong>GC垃圾收集器</strong></p>
<ul>
<li><p>Serial垃圾收集器(单线程、复制算法）</p>
</li>
<li><p>ParNew垃圾收集器（Serial+多线程)</p>
</li>
<li><p>Parallel Scavenge 收集器(多线程复制算法、高效)</p>
</li>
<li><p>Serial Old收集器(单线程标记整理算法)</p>
</li>
<li><p>Parallel Old收集器（多线程标记整理算法)</p>
</li>
<li><p>GMS收集器(多线程标记清除算法）</p>
<ul>
<li>初始标记</li>
<li>并发标记</li>
<li>重新标记</li>
<li>并发清除</li>
</ul>
</li>
<li><p>G1收集器</p>
</li>
</ul>
<p><strong>线程资源同步和交互机制</strong></p>
<ul>
<li><p>线程资源同步</p>
<ul>
<li><p>线程资源执行机制</p>
</li>
<li><p>线程资源同步机制</p>
<ul>
<li>Synchronized的实现机制</li>
<li>lock/unlock的实现机制</li>
</ul>
</li>
</ul>
</li>
<li><p>线程交互机制</p>
<ul>
<li>Object.wait/notify/notifyAll</li>
<li><p>Double check pattern</p>
</li>
<li><p>并发包提供的交互机制</p>
<ul>
<li>semaphore</li>
<li>CountdownLatch</li>
</ul>
</li>
</ul>
</li>
<li><p>线程状态及分析方法</p>
</li>
<li>jstack<ul>
<li>TDA</li>
</ul>
</li>
</ul>
<p><strong>参数</strong></p>
<p>Xms<br>Xmx<br>Xmn<br>-XX:+PrintGCDetail<br>-XX:SurvivorRatio=8<br>-XX:PretenureSizeThreshold=xxx<br>-XX:MaxTenuringThreshold<br>-XX:-=HandlePromotionFailure</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>LockSuport简述-1</title>
    <url>/2019/03/17/Java%20LockSupport/</url>
    <content><![CDATA[<blockquote>
<p>LockSupport是线程阻塞原语，用来阻塞线程和唤醒线程。每个使用LockSupport的线程都会与一个许可permit关联：</p>
</blockquote>
<ul>
<li><p>如果该许可可用，并且可在线程中使用，则调用park()将会立即返回，否则可能阻塞。</p>
</li>
<li><p>如果许可尚不可用，则调用unpark使其可用</p>
</li>
</ul>
<p>注意：</p>
<ul>
<li><p>许可不可重入，只能调用一次park方法，否则会一直阻塞。</p>
</li>
<li><p>和信号量不同，这个许可不能累加（即连续的unpark()和1次效果一样）。</p>
</li>
</ul>
<p><strong>阻塞线程</strong></p>
<ul>
<li><p>start void park():阻塞当前线程，如果调用unpark方法或当前线程被终断，从park()方法中返回。</p>
</li>
<li><p>static void park(Object blocker):阻塞当前线程，入参添加一个Obj对象，用来记录导致线程阻塞的阻塞对象，方便进行问题排查。</p>
</li>
<li><p>static void parkNanos(long nanos):阻塞当前线程，最长不超过nanos纳秒，增加了超时返回的特性。</p>
</li>
<li><p>static void parknanos(Object blocker,long nanos)阻塞当前线程，入参增加一个obj对象，用来记录导致线程阻塞的阻塞对象，方便问题排查。</p>
</li>
<li><p>static void parkUntil(long deadline)：阻塞当前线程，直到deadline</p>
</li>
</ul>
<p>static void parkUntil(Object blocker,long deadline):阻塞当前线程，入参增加一个obj对象，用来记录导致线程阻塞的阻塞对象，方便问题排查。</p>
<p><strong>唤醒线程</strong></p>
<ul>
<li>static void unpark(Thread thread):唤醒处理阻塞状态的指定线程。</li>
</ul>
<blockquote>
<p>实际LockSupport阻塞和唤醒线程的功能都依赖sun.misc.Unsafe</p>
</blockquote>
<pre><code>public class LockSuportTest {

    public static void main(String[] args) throws InterruptedException {
        Thread t = new Thread(() -&gt; {
            LockSupport.park();
            System.err.println(Thread.currentThread().getName() + &quot;started&quot;);
        });
        t.start();
        Thread.sleep(3000);
        LockSupport.unpark(t);
    }
}
</code></pre><p>Synchronized 与LockSupport</p>
<ul>
<li><p>synchronized使线程阻塞，线程进入blocked状态，而调用LockSupport.park()方法阻塞线程会致使线程进入到waiting状态</p>
</li>
<li><p>由synchronized阻塞的线程加入到同步队列，再次被唤醒的线程是随机从同步队列中选择的，而LockSupport.unpark(thread)可以指定线程对象唤醒指定线程。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>lock</category>
      </categories>
      <tags>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux中搭建maven+nexus仓库</title>
    <url>/2018/09/22/Linux%E4%B8%AD%E6%90%AD%E5%BB%BAmaven+nexus%E7%A7%81%E4%BA%BA%E4%BB%93%E5%BA%93/</url>
    <content><![CDATA[<p>Linux中搭建maven+nexus私人仓库</p>
<p><strong>1.安装maven</strong></p>
<ul>
<li><p>1.1 将下载好的apache-maven-3.0.5-bin.tar.gz包，用FTP工具传至服务器上</p>
</li>
<li><p>1.2 在/usr/local/下新建maven3目录<br>在该目录中解压：tar -zvxf apache-maven-3.0.5-bin.tar.gz</p>
</li>
</ul>
<ul>
<li><p>1.3 配置环境变量：vim /etc/profile加入： </p>
<p>  export MAVEN_HOME=/usr/local/apache-maven-3.3.9</p>
<p>  export PATH=$PATH:$MAVEN_HOME/bin</p>
</li>
<li><p>1.4 让系统重新执行下/etc/profile命令</p>
<p>  source /etc/profile  或   . /etc/profile</p>
</li>
<li><p>1.5 检查maven是否安装成功</p>
<p>  mvn -version</p>
</li>
</ul>
<p><strong>2.安装nexus</strong></p>
<ul>
<li><p>2.1 下载地址：<a href="http://www.sonatype.org/nexus/go/" target="_blank" rel="noopener">http://www.sonatype.org/nexus/go/</a></p>
</li>
<li><p>2.2 在/usr/local/下新建nexus目录</p>
<ul>
<li><p>2.2.1 将nexus-2.11.2-03-bundle.tar.gz移到该目录下</p>
</li>
<li><p>2.2.2 解压： tar -zxvf nexus-2.11.2-03-bundle.tar.gz</p>
</li>
<li><p>2.2.3 解压后两个文件： nexus-2.11.2-03 sonatype-work</p>
</li>
</ul>
</li>
<li><p>2.3 可以配置访问nexus端口：</p>
<p>  在nexus.properties文件中（该文件位于nexus-2.11.2-03/conf/),默认为8081端口。</p>
</li>
<li><p>2.4 配置nexus配置文件</p>
<p>  切换目录： /nexus/nexus-2.11.2-03/bin/下</p>
<p>  打开文件 nexus, vim nexus</p>
<p>  NEXUS_HOME=”..”改为(不修改默认也可以）：NEXUS_HOME=”nexus安装目录”</p>
<p>  RUN_AS_USER= 改为 RUN_AS_USER=root</p>
</li>
<li><p>2.5 打开linux系统8081端口：</p>
<p>  filewall -cmd add -port = 8020 /tcp -permanent</p>
<p>  重启防火墙： systemctl stop firewalld</p>
</li>
<li><p>2.6 启动nexus:</p>
<p>  切换目录：cd /usr/local/nexus/nexus-2.11.2-03/bin/</p>
<p>  启动：  ./nexus start</p>
</li>
<li><p>2.7 浏览器访问地址：</p>
<p>  <a href="http://ip:8081/nexus" target="_blank" rel="noopener">http://ip:8081/nexus</a></p>
<p>  登陆：默认名称admin  默认密码：admin123</p>
</li>
<li><p>2.8 加入jar包到私人库</p>
</li>
</ul>
<p><img src="/images/nexus/000001.png" alt="Alt text"></p>
<p><img src="/images/nexus/000002.png" alt="Alt text"></p>
<p><img src="/images/nexus/000003.png" alt="Alt text"></p>
<p><img src="/images/nexus/000004.png" alt="Alt text"></p>
<p><img src="/images/nexus/000005.png" alt="Alt text"></p>
<p>一般项目jar比较多，可通过ftp形式上传至maven仓库，目录为（/home/fhapp/sonatype-work/nexus/storage/thirdparty<br>（/usr/local/nexus/sonatype-work/nexus/storage/thirdparty）</p>
]]></content>
      <categories>
        <category>nexus</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>maven</tag>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven中问题点滴记录</title>
    <url>/2016/06/19/Maven%E4%B8%AD%E9%97%AE%E9%A2%98%E7%82%B9%E6%BB%B4%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p>Maven项目在进行maven install时中出现：<br>    Failed to execute goal on project …: Could not resolve dependencies for project …</p>
<p>解决方式：</p>
<p>1.项目结构为一个父项目，多个子项目目录如下：</p>
<p><img src="/images/maven_0001/maven_00001.jpg" alt="Alt text"></p>
<p>2.举个栗子：应用的是account、gateway这两个项目</p>
<p>3.这两个项目都继承父项目 xpay</p>
<p>4.在模块中gateway依赖与xxaccount,在xxaccount中执行完clean和install之后，本地仓库也存在依赖，但是在domain中进行install就会出现</p>
<pre><code>Failed to execute goal on project ...: Could not resolve dependencies for project ...
</code></pre><p>这样的错误，后来发现是自己没有首先对父项目也就是xpay项目尽心clean和install。</p>
<p>5.总结：在父项目下有子项目在首次运行clean和install前应该先运行父项目的clean和install。</p>
]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title>Mysql存储引擎InnoDB是怎样解决幻读的</title>
    <url>/2020/09/19/Mysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8EInnoDB%E6%98%AF%E6%80%8E%E6%A0%B7%E8%A7%A3%E5%86%B3%E5%B9%BB%E8%AF%BB/</url>
    <content><![CDATA[<p>。</p>
<p><strong>1.结论</strong></p>
<p>在RR的隔离级别下，InnoDB使用MVCC和next-key locks解决幻读，MVCC解决的是普通读（快照读）的幻读，next-key locks解决的是当前读情况下的幻读。</p>
<p><strong>2.幻读是什么</strong></p>
<p>事务A，先执行：</p>
<p>update table set name = ‘kkk’ where id &gt; 9 ;</p>
<p>结果：</p>
<p>OK row xx表名成功影响多少行数据</p>
<p>事务B，后执行，并且提交</p>
<p>insert into table values( 12, uu);</p>
<p>commit;</p>
<p>事务A，然后在select一下：</p>
<p>select * from table where id &gt; 9 ;</p>
<p>结果集为：</p>
<p>  …..12,uu….</p>
<p>事务A懵了，刚才不是id&gt;9全部更新了吗，怎么又出现一个未更新的数据。主要是因为这次是已提交事务B对事务A产生的影响，这个影响叫做幻读。<br>（一个事务范围操作时，另一个事务进行了新增、删除操作）</p>
<p>幻读、不可重复读区别： </p>
<ul>
<li>幻读：一个范围</li>
<li>不可重复读：本身</li>
</ul>
<p><strong>3.怎样解决</strong></p>
<ul>
<li><p>3.1当前读</p>
<p>所谓当前读，指加锁的select(S或X)、update、delete等语句。在RR事务隔离级别下，数据库会使用next-key locks来锁住本条记录以及索引区间。</p>
</li>
</ul>
<p>使用上个例子，在RR的情况下，假设使用的是当前读，加锁了的读 select * from table where id &gt; 3 锁住的就是id = 3 这条记录及id &gt; 3这个区间范围，锁住索引记录之间的范围，避免范围插入记录，已避免产生幻影行记录。</p>
<ul>
<li>3.2普通读</li>
</ul>
<p>普通读是不会加锁读，故不会有next-key locks的使用，解决幻读的手段是MVCC。<br>MVCC会给每行元组加一些辅助字段，记录创建版本号和删除版本号，。</p>
<p>每个事务在启动时，都有一个唯一的递增的版本号。每开启一个新事务，事务的版本号就会递增。</p>
<p><strong>默认的隔离级别（Repeatable Read)下，增删改查 变成了这样：</strong></p>
<ul>
<li>SELECT： 读取创建版本小于或等于当前事务版本号，并且删除版本为空或大于当前事务版本号的记录。这样可以保证在读取之前记录是存在的。</li>
</ul>
<ul>
<li>INSERT： 将当前事务的版本号保存至行的创建版本号。</li>
</ul>
<ul>
<li>UPDATE： 新插入一行，并以当前事务的版本号作为新行的创建版本号，同时将原记录行的删除版本号设置为当前事务版本号。</li>
</ul>
<ul>
<li>DELETE： 将当前事务的版本号保存至行的删除版本号。</li>
</ul>
<p>如插入一条记录，事务id假设为1，那么记录如下，就是创建版本号就是事务版本号。</p>
<p><img src="/images/MySQL_InnoDB_RR_001/000001.png" alt="Alt text"></p>
<p>如更新的话，事务id假设是2</p>
<p><img src="/images/MySQL_InnoDB_RR_001/000002.png" alt="Alt text"></p>
<p>这里是把name更新为taotao，原来的元组deleteversion版本号为这个事务的id，并且新增一条。</p>
<p>如删除的话，假设事务id=3，</p>
<p><img src="/images/MySQL_InnoDB_RR_001/000003.png" alt="Alt text"></p>
<p><strong>关键点</strong></p>
<p>现读取必须满足两个条件：</p>
<ul>
<li><p>读取创建版本小于或等于当前事务版本号  意味着数据在这个事务之前被创建。</p>
</li>
<li><p>删除版本为空或大于当前事务版本号的记录。意味着删除操作在这个事务之后发生的。</p>
</li>
</ul>
<p>以上面例子，当前数据库的状态</p>
<p><img src="/images/MySQL_InnoDB_RR_001/000004.png" alt="Alt text"></p>
<p>假设事务A的id=10</p>
<p>现在update table set name = “kkkkk” where id &gt; 3 ;执行这条语句。</p>
<p><img src="/images/MySQL_InnoDB_RR_001/000005.png" alt="Alt text"></p>
<p>事务B的id  = 12</p>
<p>insert into table values(12, uu);</p>
<p><img src="/images/MySQL_InnoDB_RR_001/000006.png" alt="Alt text"></p>
<p>最后事务A(id = 10)在此读取</p>
<p> select * from table where id &gt; 3;</p>
<p>根据上述规则，读取创建版本号小于等于当前事务的-&gt; 那么（4,a)<br>(5,b) (4,hh) (5,hh)</p>
<p>上面规则的输出作为下面规则的输入的话，删除版本为空或大于当前事务版本号的记录-&gt;（4，hh) (5,hh)<br>读取就没有读到事务B新插入的那行，解决幻读。</p>
<p>如果事务B是更新id = 4的元组 name = cc呢。同理，根据update的规则</p>
<p><img src="/images/MySQL_InnoDB_RR_001/000007.png" alt="Alt text"></p>
<p>然后根据select的规则去读取的话，得到的还是(4,hh) (5,hh)<br><strong><br>综述：</strong></p>
<p>在RC的模式下，MVCC解决不了幻读、不可重复读，因为每次读都会读它自己刷新的快照版本，简单来说就是另一个事务提交，他就刷新一次，去读最新的。</p>
]]></content>
      <categories>
        <category>事务</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>幻读</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot中定时任务配置多线程</title>
    <url>/2019/05/18/SpringBoot%E4%B8%AD%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E9%85%8D%E7%BD%AE%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%89%A7%E8%A1%8C/</url>
    <content><![CDATA[<p>SpringBoot中定时任务在不配置线程池时，默认是单线程执行的。系统中配置多个定时任务，会按照列队进行执行。这样执行效率低，可能对Corn配置的存在影响。</p>
<pre><code>//多线程执行定时任务
@Slf4j
@Configuration
public class ScheduleConfig implements SchedulingConfigurer {
@Override
public void configureTasks(ScheduledTaskRegistrar taskRegistrar) {
  log.info(&quot;定时任务配置10个线程&quot;);
taskRegistrar.setScheduler(Executors.newScheduledThreadPool(10));
}
}
</code></pre><p>添加后，定时任务就以10个线程进行执行。</p>
]]></content>
      <categories>
        <category>定时任务</category>
      </categories>
      <tags>
        <tag>定时任务</tag>
        <tag>多线程</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux修改防火墙</title>
    <url>/2015/06/22/Linux%E4%BF%AE%E6%94%B9%E9%98%B2%E7%81%AB%E5%A2%99/</url>
    <content><![CDATA[<p><strong>虚拟机为CentOs7,修改防火墙配置时找不到iptables文件。</strong></p>
<p><strong>解决办法如下：</strong><br>因为模式使用的是firewall作为防火墙，先把它停掉装iptable</p>
<p>systemctl stop firewalld</p>
<p>systemctl mask firewalld</p>
<p>yum install -y iptables</p>
<p>yum install iptables-services</p>
<p>然后就可找到iptables文件进行配置</p>
<p>开启服务</p>
<p>systemctl start iptables.service</p>
<p>systemctl restart iptables.service //重启防火墙使配置生效</p>
<p>systemctl enable iptables.service //设置防火墙开机启动</p>
<p><strong>其他命令：</strong></p>
<p>检查是否安装iptables<br>service iptables status</p>
<p>安装iptables<br>yum install -y iptables</p>
<p>升级iptables<br>yum update iptables</p>
<p>安装iptables-service<br>yum install iptables-service</p>
<p>禁用iptables服务<br>systemctl disable iptables</p>
<p>暂停服务<br>systemctl stop iptables</p>
<p>解除禁止iptables<br>systemctl enable iptables</p>
<p>开启服务<br>systemctl start iptables</p>
<p><strong>配置信息</strong></p>
<p>修改防火墙端口配置文件：vim /etc/sysconfig/iptables</p>
<p>调整端口：-A INPUT -p tcp -m tcp –dport 80 -j ACCEPT</p>
<p>开通8080端口<br>                -A INPUT -p tcp -m tcp –dport 8080 -j ACCEPT</p>
<p>修改防火墙配置后保存：（/etc/sysconfig）chkconfig iptables on 保存成功</p>
<p>查看CentOS防火墙信息：/etc/init.d/iptables status<br>关闭CentOS防火墙服务：/etc/init.d/iptables stop</p>
<p>重启CentOS防火墙服务：/etc/init.d/iptables restart </p>
<p>查看nginx进程：<br>ps aux|grep nginx</p>
<p>ps -ef|grep nginx</p>
<p>启动nginx:<br>在当前路径下(/usr/local/nginx/sbin)执行./nginx</p>
<p>停止nginx:<br>在当前路径下(/usr/local/nginx/sbin)执行./nginx -s stop</p>
<p>重启nginx:<br>在当前路径下(/usr/local/nginx/sbin)执行./nginx -s reload</p>
]]></content>
      <categories>
        <category>linux,iptables</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL三大日志(bin log、redo log、undo log)</title>
    <url>/2020/09/05/MySQL%E4%B8%89%E5%A4%A7%E6%97%A5%E5%BF%97(bin%20log%E3%80%81redo%20log%E3%80%81undo%20log)/</url>
    <content><![CDATA[<p>日志是mysql数据库的重要组成部分，记录着数据库运行期间各种状态信息。mysql日志主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。作为后端开发，需要重点关注的是二进制日志(binlog)和事务日志(包括redo log和undo log)，接下来会详细介绍</p>
<p><strong>binlog</strong></p>
<p>binlog用于记录数据库执行的写入性操作（不包括查询）信息，以二进制的形式保存在磁盘中。binlog是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录binlog日志。</p>
<ul>
<li><p>逻辑日志： 记录的就是sql语句。</p>
</li>
<li><p>物理日志： 因为mysql数据最终是保存在数据页中的，屋里日志记录的就是数据页变更。</p>
</li>
</ul>
<p>binlog是以追加的方式进行写入的，可通过max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值后，会生成新的文件来保存日志。</p>
<p><strong>binlog使用场景</strong></p>
<p>在实际应用中，binlog的主要是用场景有两个，分别是主从复制和数据恢复。</p>
<ul>
<li><p>主从复制：在Master端开启binlog,然后将binlog发送到各个slave端，slave端重放binlog从而达到主从一致。</p>
</li>
<li><p>数据恢复：通过使用mysqlbinlog工具来恢复数据。</p>
</li>
</ul>
<p><strong>binlog刷盘时机</strong></p>
<p>对于InnoDB存储引擎，只有在事务提交时才会记录binlog，此时记录还在内存中，那binlog是什么时候刷到磁盘中的？mysql通过sync_binlog参数控制binlog的刷盘时机，其值范围0-N：</p>
<p>0：不强制要求，由系统自行判断何时写入磁盘。<br>1：每次commit时都要将binlog写入磁盘。<br>N: 每N个事务，才会将binlog写入磁盘。</p>
<p>由此可见，sync_binlog最安全是设置1，这也是MySQL5.7.7版本后的默认值，但是设置一个大一些的值可以提升数据库性能，因此实际情况也可将值适当调大，牺牲一定的一致性来获取更好的性能。</p>
<p><strong>binlog日志格式</strong></p>
<p>binlog日志有三种格式，分为为STATEMENT、ROW和MIXED。</p>
<p>MySQL5.7.7前，默认格式是STATEMENT，MySQL5.7.7后，默认是ROW。日志格式通过binlog-format指定。</p>
<ul>
<li><p>STATEMENT<br>：基于SQL语句复制(statement-based replication,SBR），每一条会修改数据的sql语句会记录到binlog中。</p>
<ul>
<li><p>优点</p>
<pre><code>不需要记录每一行的变化，减少了binlog日志量，节约了IO，从而提高性能。
</code></pre></li>
<li><p>缺点：</p>
<pre><code>某些情况下会导致主从数据不一致，比如执行sysdate()、sleep()等。
</code></pre></li>
</ul>
</li>
</ul>
<ul>
<li><p>ROW</p>
<p>  基于行的复制(row-based replication,RBR),不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了。</p>
<ul>
<li><p>优点：<br>不会出现某些特定情况下的存储过程、function、trigger的调用触发无法被正常赋值的问题。</p>
</li>
<li><p>缺点：会产生大量的日志，尤其是alter table的时候会让日志暴涨。</p>
</li>
</ul>
</li>
<li><p>MIXED<br>基于STATEMENT和ROW两种模式的混合赋值(mixed-based replication, MBR),一般的赋值使用STATEMENT模式保存binlog,对于STATEMENT模式无法复制的操作使用ROW模式来保存binlog。</p>
</li>
</ul>
<p><strong>redo log</strong></p>
<p>事务的四大特性有一个是持久性，只要数据提交成功，那么对数据库做的修改就被永久保存下来了。不可能因为任何原因再回到原来的状态。mysql是怎样保证一致性的呢？简单的做法是每次事务提交时，将事务设计修改的数据页全部刷新到磁盘中。但是这么做再在两方面有严重的性能问题：</p>
<ul>
<li><p>因为InnoDB是以页为单位进行磁盘交互的，一个事务很可能只修改一个数据页里的几个字节，这时将完整的数据页刷新到磁盘，太浪费资源了。</p>
</li>
<li><p>一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差。</p>
</li>
</ul>
<p>因此mysql涉及了redo log，它就是只记录事务对数据页做了哪些修改，这样就能完美地解决性能问题了（相对而言文件更小且顺序IO）</p>
<p><strong>redo log基本概念：</strong></p>
<p>redo log 包括两部分,一个是内存中的日志缓冲（redo log buffer),另一个是磁盘上的日志文件（redo log file)。mysql每执行一条DML语句，先将记录写入redo log buffer,后续某个时间点再一次性将多个记录写到redo log file。这种先写日志，在写磁盘的技术就是mysql中常说的WAL（Write-Ahead Logging)技术。</p>
<p>计算机中操作系统，用户空间(user space)下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间（kernel space)缓冲区（OS Buffer)。因此，redo log buffer 写入redo log file实际上是先写入OS Buffer,然后再通过系统调用fsync()将其刷到redo log file中，过程如：</p>
<p><img src="/images/mysql_3_log/000001.png" alt="Alt text"></p>
<p>mysql支持三种将redo log buffer写入 redo log file的时机，可通过innodb_flush_log_at_trx_commit参数设置，各参数值含义如下：</p>
<p><img src="/images/mysql_3_log/000002.png" alt="Alt text"></p>
<p><strong>redo log 记录形式</strong></p>
<p>redo log实际上记录数据页的变更，这种变更是没必要全部保存，因此redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。如下：</p>
<p><img src="/images/mysql_3_log/000003.png" alt="Alt text"></p>
<p>同时在InnoDB中，既有redo log需要刷盘，还有数据页也需要刷盘，redo log存在的含义主要是降低对数据页刷盘的要求。如上图，write pos标识redo log当前记录的LSN（逻辑序列号)位置，check point标识数据页更改记录刷盘后对应redo log所处的LSN（逻辑序列号)位置。</p>
<p>write pos到check point之间的部分是redo log空着的部分，用于记录新的记录；check point到write pos之间是redo log待落盘的数据页更改记录。当write pos追上check point时，会先推动check point向前移动，空出位置在记录新的日志。</p>
<p>启动InnoDB时，不管上次是否正常关闭，总是会进行恢复操作。因为redo log记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志（binlog）要快很多。</p>
<p>重启InnoDB时，首先会检查磁盘中数据页的LSN，如数据页的LSN小于日志中的LSN,则会从checkpoint开始恢复。</p>
<p>还有一种情况，在宕机前正处于checkpoint的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的LSN大于日志中的LSN，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。</p>
<p><img src="/images/mysql_3_log/000004.png" alt="Alt text"></p>
<p><strong>redo log与binlog区别</strong></p>
<p>由binlog和redo log的区别可知：binlog日志只用于归档，只依靠binlog是没有crash-safe能力的。但只有redo log也不行，因为redo log是InnoDB特有的，且日志上的记录落盘后会被覆盖掉。因此需要binlog和redo log二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失。</p>
<p><strong>undo log</strong></p>
<p>数据库事务四大特性中有一个是原子性，具体来说就是 原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况。<br>实际上，原子性底层就是通过undo log实现的。undo log主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。推荐阅读：Java面试题拆解<br>同时，undo log也是MVCC(多版本并发控制)实现的关键，这部分内容在面试中的老大难-mysql事务和锁，一次性讲清楚！中有介绍，不再赘述。</p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title>spring中单例bean与原型bean区别</title>
    <url>/2016/06/18/Spring%E4%B8%AD%E5%8D%95%E4%BE%8B%E4%B8%8E%E5%8E%9F%E5%9E%8Bbean/</url>
    <content><![CDATA[<p><strong>spring中单例bean与原型bean区别</strong></p>
<blockquote>
<p>bean被声明为单例时，处理多次请求时在spring容器里只实例化出一个bean,后续请求都公用这个bean对象，这个对象会保存一个map中。当有请求来的时候从缓存（map)中查看有无，有则直接使用这个对象，无则实例化一个新的bean对象，所以这个是单例的。</p>
</blockquote>
<blockquote>
<p>bean被声明为原型时，处理每次请求时直接实例化新的bean，没有缓存及从缓存中查的过程。</p>
</blockquote>
<p>1.单例的bean只有第一次创建新的bean，后面都会复用该bean,所以不会频繁创建对象。</p>
<p>2.原型bean每次都会新创建。</p>
<p><strong>单例bean的优势：</strong></p>
<blockquote>
<p>不会每次都创建新对象所以有几个性能上的优势：</p>
</blockquote>
<ul>
<li><p>1.减少新生成实例的消耗</p>
<blockquote>
<p>新生成实例消耗包括两个方面，第一，spring会通过反射、cglib来生成bean实例，这都是性能消耗，其次是给对象分配内存也会涉及复杂算法。</p>
</blockquote>
</li>
<li><p>2.减少jvm垃圾回收</p>
</li>
<li><p>由于不会给每个请求都新生成bean实例，所以回收的对象少了。</p>
</li>
</ul>
<ul>
<li>3.可以快速获取到bean</li>
</ul>
<p>因为单例的获取bean操作除了第一次生成之外，其余的都是从缓存中获取，所以很快。</p>
<p><strong>单例bean的劣势：</strong><br>线程不安全，所有请求都共享一个实例bean，所以这个bean要是有状态的一个bean,可能在并发场景下出现问题。原型bean不会出现此问题。（出发他被其他单例bean依赖）因为每个请求都是新创建实例。</p>
<p><strong>概述：</strong></p>
<blockquote>
<p> spring默认把bean设置成单例为了提高性能。</p>
</blockquote>
<ul>
<li>1.少创建实例</li>
<li>2.垃圾回收</li>
<li><p>3.缓存快速获取</p>
<p>劣势：有状态的话并发环境不安全。  </p>
</li>
</ul>
]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>bean</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux之lsof命令</title>
    <url>/2015/06/21/Linux%E4%B9%8Blsof%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>lsof命令简介：<br>lsof（list open files）是一个列出当前系统打开文件的工具。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以，lsof的功能很强大。一般root用户才能执行lsof命令，普通用户可以看见/usr/sbin/lsof命令，但是普通用户执行会显示“permission denied”。因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。</p>
<p>在终端下输入lsof即可显示系统打开的文件，因为 lsof 需要访问核心内存和各种文件，所以必须以 root 用户的身份运行它才能够充分地发挥其功能。</p>
<p><img src="/images/201712192039201.jpg" alt="Alt text"></p>
<p>每行显示一个打开的文件，若不指定条件默认将显示所有进程打开的所有文件。lsof输出各列信息的意义如下：<br>COMMAND：进程的名称<br>PID：进程标识符<br>USER：进程所有者<br>FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等<br>TYPE：文件类型，如DIR、REG等<br>DEVICE：指定磁盘的名称<br>SIZE：文件的大小<br>NODE：索引节点（文件在磁盘上的标识）<br>NAME：打开文件的确切名称</p>
<p>lsof指令的用法如下：<br>lsof abc.txt 显示开启文件abc.txt的进程<br>lsof 目录名 查找谁在使用文件目录系统</p>
<p><img src="/images/201712192039202.jpg" alt="Alt text"></p>
<p>lsof -i :22 知道22端口被哪个进程占用<br>lsof -c abc 显示abc进程现在打开的文件<br>lsof -g gid 显示归属gid的进程情况<br>lsof -n 不将IP转换为hostname，缺省是不加上-n参数<br>lsof -p 12 看进程号为12的进程打开了哪些文件<br>lsof -u username 查看用户打开哪些文件<br>lsof -i @192.168.1.111 查看远程已打开的网络连接（连接到192.168.1.111）<br>－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－<br>lsof -i 用以显示符合条件的进程情况<br>语法: lsof -i[46] [protocol][@hostname|hostaddr][:service|port]<br>46 -&gt; IPv4 or IPv6<br>protocol -&gt; TCP or UDP<br>hostname -&gt; Internet host name<br>hostaddr -&gt; IPv4位置<br>service -&gt; /etc/service中的 service name (可以不只一个)<br>port -&gt; 端口号 (可以不只一个)<br>－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－<br>lsof +|-r [t] 控制lsof不断重复执行，缺省是15s刷新<br>-r，lsof会永远不断的执行，直到收到中断信号<br>+r，lsof会一直执行，直到没有档案被显示<br>例子：不断查看目前ftp连接的情况：lsof -i <a href="mailto:tcp@192.168.1.111" target="_blank" rel="noopener">tcp@192.168.1.111</a>:ftp -r</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker日志实时查看和清理</title>
    <url>/2021/09/25/docker%E6%97%A5%E5%BF%97%E5%AE%9E%E6%97%B6%E6%9F%A5%E7%9C%8B%E4%B8%8E%E6%B8%85%E7%90%86/</url>
    <content><![CDATA[<h1 id="Docker日志实时查看和清理"><a href="#Docker日志实时查看和清理" class="headerlink" title="Docker日志实时查看和清理"></a>Docker日志实时查看和清理</h1><h2 id="一、docker-logs-查看实时日志"><a href="#一、docker-logs-查看实时日志" class="headerlink" title="一、docker logs 查看实时日志"></a>一、docker logs 查看实时日志</h2><p>docker logs -f -t –since=“2021-09-25” –tail=10 edu_web_1</p>
<p>命令说明： –since : 此参数指定了输出日志开始日期，即只输出指定日期之后的日志。 -f : 查看实时日志 -t : 查看日志产生的日期 -tail=10 : 查看最后的10条日志。 edu_web_1 : 容器名称</p>
<h2 id="二、docker容器日志"><a href="#二、docker容器日志" class="headerlink" title="二、docker容器日志"></a>二、docker容器日志</h2><ul>
<li><p>1.问题： docker容器日志导致主机磁盘空间满了。docker logs -f container_name很占用空间，不用的日志可以清理掉了。</p>
</li>
<li><p>2.查找容器日志: 在linux上，容器日志一般存放在/var/lib/docker/containers/container_id/下面， 以json.log结尾的文件（业务日志）很大，查看各个日志文件大小的脚本docker_log_size.sh，内容如下：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">!/bin/sh</span><br><span class="line"></span><br><span class="line">echo &quot;======== docker containers logs file size ========&quot;  </span><br><span class="line"></span><br><span class="line">logs=$(find /var/lib/docker/containers/ -name *-json.log)  </span><br><span class="line"></span><br><span class="line">for log in $logs  </span><br><span class="line">        do  </span><br><span class="line">             ls -lh $log   </span><br><span class="line">        done  </span><br><span class="line">chmod +x docker_log_size.sh</span><br><span class="line"></span><br><span class="line">./docker_log_size.sh</span><br></pre></td></tr></table></figure>
<ul>
<li style="list-style: none"><input type="checkbox" checked> 2.2 清理Docker容器日志（治标）<br>如果docker容器正在运行，那么使用rm -rf方式删除日志后，通过df -h会发现磁盘空间并没有释放。原因是在Linux或者Unix系统中，通过rm -rf或者文件管理器删除文件，将会从文件系统的目录结构上解除链接（unlink）。如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。正确姿势是cat /dev/null &gt; *-json.log，当然你也可以通过rm -rf删除后重启docker。接下来，提供一个日志清理脚本clean_docker_log.sh，内容如下：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">!/bin/sh</span><br><span class="line"></span><br><span class="line">echo &quot;======== docker containers logs file size ========&quot;  </span><br><span class="line"></span><br><span class="line">logs=$(find /var/lib/docker/containers/ -name *-json.log)  </span><br><span class="line"></span><br><span class="line">for log in $logs  </span><br><span class="line">        do  </span><br><span class="line">             ls -lh $log   </span><br><span class="line">        done  </span><br><span class="line">chmod +x docker_log_size.sh</span><br><span class="line"></span><br><span class="line">./docker_log_size.sh</span><br></pre></td></tr></table></figure>
<p>但是，这样清理之后，随着时间的推移，容器日志会像杂草一样，卷土重来。</p>
<ul>
<li style="list-style: none"><input type="checkbox" checked> 2.3 设置Docker容器日志大小（治本）</li>
</ul>
<p>设置一个容器服务的日志大小上限 上述方法，日志文件迟早又会涨回来。要从根本上解决问题，需要限制容器服务的日志大小上限。这个通过配置容器docker-compose的max-size选项来实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx: </span><br><span class="line">  image: nginx:1.12.1 </span><br><span class="line">  restart: always </span><br><span class="line">  logging: </span><br><span class="line">    driver: “json-file” </span><br><span class="line">    options: </span><br><span class="line">      max-size: “5g”</span><br></pre></td></tr></table></figure>
<p>重启nginx容器之后，其日志文件的大小就被限制在5GB，再也不用担心了。<br>全局设置 新建/etc/docker/daemon.json，若有就不用新建了。添加log-dirver和log-opts参数，样例如下：</p>
<p><code>`</code><br>vim /etc/docker/daemon.json</p>
<p>{<br>  “registry-mirrors”: [“<a href="http://f613ce8f.m.daocloud.io&quot;]" target="_blank" rel="noopener">http://f613ce8f.m.daocloud.io&quot;]</a>,<br>  “log-driver”:”json-file”,<br>  “log-opts”: {“max-size”:”500m”, “max-file”:”3”}<br>}<br>max-size=500m，意味着一个容器日志大小上限是500M， max-file=3，意味着一个容器有三个日志，分别是id+.json、id+1.json、id+2.json。</p>
<p>//重启docker守护进程</p>
<p>#systemctl daemon-reload</p>
<p>#systemctl restart docker</p>
<p><code>`</code>注意：设置的日志大小，只对新建的容器有效</p>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title>final、finally、finalize</title>
    <url>/2015/07/12/final%E3%80%81finally%E3%80%81finalize%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p><strong>final、finally、finalize的区别？</strong></p>
<p><strong>1.final</strong></p>
<p>在Java中，final可以用来修改类，方法和变量（成员变量或局部变量）。如下对其详细介绍。</p>
<p><strong>1.1修饰类</strong></p>
<p>当用final修饰类的时候，表名该类不能被其他类继承。当需要让一个类永远不被继承，可使用final修改。但要注意：final类中所有的成员方法都会隐式的定义为final方法。</p>
<p><strong>1.2修饰方法</strong></p>
<p>使用final方法的原因有二</p>
<p>（1)把方法锁定，防止继承类对其进行更改。</p>
<p>（2）效率，在早期java版本中，将final方法转为内嵌调用。但若方法过于庞大，可能在性能上不会有所提升。因此近期版本中，不需使用final方法进行这些优化。</p>
<p>final方法意味着“最后的、最终的”含义，即此方法不能被重写。</p>
<p>注意：若父类中final方法的访问权限为private，将导致子类中不能直接继承该方法，因此，此时可以在子类中定义相同方法名的函数，此时不会与重写final的矛盾，而是在子类中重新定义了新方法。</p>
<pre><code>class A{
    private final void getName(){}
}

public class B extends A{
    public void getName(){}

    public static void main(String[] args){
        System.err.println(&quot;OK&quot;);
    }
}
</code></pre><p><strong>1.3修饰变量</strong></p>
<p>final成员变量标识常量，只能被赋值一次，赋值后其值不再改变。</p>
<p>当final修饰一个基本数据类型时，表示该基本数据类型的值一旦初始化便不能发生变化。如果final修饰一个引用类型时，则在对其初始化之后便不能再让其指向其他对象了，但该引用所指向的对象内是可以改变的。因为引用的值是一个地址，final要求值，即地址的值不发生变化。</p>
<p> final修饰一个成员变量（属性），必须要显示初始化。有两种初始化方式，一种是在变量声明的时候初始化；二种方法是在声明变量的时候不赋值，但要在这个变量所在的类的所有构造方法中对这个变量赋初始值。</p>
<p> 当函数的参数类型声明为final时，说明该参数是只读型。可读取使用该参数，但无法改变该参数的值。</p>
<p><img src="/images/final/1.jpg" alt="Alt text"></p>
<p>在java中，String被设计成final类，那么为什么平时使用时，String的值可以被改变呢？</p>
<p> 字符串常量池是java堆内存中一个特殊的存储区域，创建一个String对象时，假设常量池不存在该字符串，创建一个若存在直接引用这个存在的字符串。当改变String对象值时，例如 String a=”A”; a=”B” 。a是String对象的一个引用（我们这里所说的String对象其实是指字符串常量），当a=“B”执行时，并不是原本String对象(“A”)发生改变，而是创建一个新的对象(“B”)，令a引用它。</p>
<p><strong>2.finally</strong></p>
<p> finally作为异常处理的一部分，只能用在try/catch语句中，并附带一个语句块，标识这段语句最终一定会被执行（不管有没有抛出异常），经常被用在需要释放资源的情况下（这句话其实存在一定问题）。</p>
<p> 很多人认为finally语句块一定会执行，但真是这样么？否定的。</p>
<p><img src="/images/final/2.jpg" alt="Alt text"></p>
<p><img src="/images/final/3.jpg" alt="Alt text"></p>
<p>为什么以上两种情况没有执行finally语句呢，说明了问题。</p>
<p>只有与finally对应的try语句块得到执行的情况下，finally语句块才会执行。以上两种情况在执行try语句块之前已经返回或抛出异常，所以try对应的finally语句并没有执行。</p>
<p>但在某些情况下，即使try语句执行了，finally语句也不一定执行。如：</p>
<p><img src="/images/final/4.jpg" alt="Alt text"></p>
<p>– try语句执行了，也不一定执行finally，使用了system.exit(0);</p>
<p>finally语句块还是没有执行，因为在try语句块中执行了System.exit(0)语句，终止了Java虚拟机的运行。一般java应用中基本上是不会调用这个System.exit(0)方法的。但是不调用System.exit(0)这个方法，finally语句块就一定执行吗？当然也不一定会执行。当一个线程在执行try语句块或catch语句块时被打断（interrupted）或被终止(killed)，与其相应的finally语句块可能不会执行。还有更极端的情况，就是在线程运行try语句或者catch语句时，突然宕机或断电，finally语句块肯定不会执行了。</p>
<p><strong>易错点</strong></p>
<p>在try-catch-finally语句中执行return语句，如下代码？</p>
<p><img src="/images/final/5.jpg" alt="Alt text"></p>
<p>返回： 4、4、4，为什么呢？</p>
<p>首先finally语句在该代码中一定会执行，从运行结果中看，每次return的结果都是4（即finally语句），仿佛其他return语句被屏蔽了。</p>
<p>事实也是如此，因为finally用法特殊，所以会撤销之前的return语句，继续执行最后的finally块中的代码。</p>
<p><strong>3.finalize</strong></p>
<p>finalize()是在java.lang.Object里定义的，即每个对象都有这个方法。这个方法在GC启动，该对象被回收的时候被调用。其实GC可以回收大部分对象（凡是new出来的对象，GC都能搞定，一般情况下我们又不会使用new以外的方式去创建对象），所以一般是不需要程序员去实现finalize的。特殊情况下，需要程序员实现finalize，当对象被回收的时候释放一些资源。如：socket链接，在对象初始化时创建，整个生命周期内有效，那么就需要实现finalize，关闭这个链接。</p>
<p>　使用finalize还需要注意一个事，调用super.finalize();</p>
<p>　　一个对象的finalize()方法只会被调用一次，而且finalize()被调用不意味着gc会立即回收该对象，所以有可能调用finalize()后，该对象又不需要被回收了，然后到了真正要被回收的时候，因为前面调用过一次，所以不会调用finalize()，产生问题。 所以，推荐不要使用finalize()方法，它跟析构函数不一样。</p>
]]></content>
      <categories>
        <category>J2SE</category>
      </categories>
      <tags>
        <tag>J2SE</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Security 入门（四）：自定义-Filter</title>
    <url>/2015/06/28/SpringSecurity%E5%85%A5%E9%97%A8%EF%BC%88%E5%9B%9B%EF%BC%89%E8%87%AA%E5%AE%9A%E4%B9%89-Filter/</url>
    <content><![CDATA[<ul>
<li><p>Spring Security入门（一）：登录与退出</p>
</li>
<li><p>Spring Security入门（二）：基于数据库验证</p>
</li>
<li><p>Spring Security入门（三）：密码加密</p>
</li>
</ul>
<p>本文解决问题</p>
<p>将自定义的 Filter 加入到 Spring Security 中的 Filter 链中的指定位置。</p>
<p>Spring Security 默认的过滤器链<br>官网位置<a href="http://docs.spring.io/spring-security/site/docs/5.0.0.M1/reference/htmlsingle/#ns-custom-filters" target="_blank" rel="noopener">http://docs.spring.io/spring-security/site/docs/5.0.0.M1/reference/htmlsingle/#ns-custom-filters</a></p>
<table><tr><th>别名</th><th>类名称</th><th>Namespace Element or Attribute</th></tr><tr><th>CHANNEL_FILTER</th><th>ChannelProcessingFilter</th><th>http/intercept-url@requires-channel</th></tr><tr><th>SECURITYCONTEXTFILTER</th><th>SecurityContextPersistenceFilter</th><th>http</th></tr><tr><th>CONCURRENTSESSIONFILTER</th><th>ConcurrentSessionFilter</th><th>session-management/concurrency-control</th></tr><tr><th>HEADERS_FILTER</th><th>HeaderWriterFilter</th><th>http/headers</th></tr><tr><th>CSRF_FILTER</th><th>CsrfFilter</th><th>http/csrf</th></tr><tr><th>LOGOUT_FILTER</th><th>LogoutFilter</th><th>http/logout</th></tr><tr><th>X509_FILTER</th><th>X509AuthenticationFilter</th><th>http/x509</th></tr><tr><th>PREAUTHFILTER</th><th>AbstractPreAuthenticatedProcessingFilter( Subclasses)</th><th>N/A</th></tr><tr><th>CAS_FILTER</th><th>CasAuthenticationFilter</th><th>N/A</th></tr><tr><th>FORMLOGINFILTER</th><th>UsernamePasswordAuthenticationFilter</th><th>http/form-login</th></tr><tr><th>BASICAUTHFILTER</th><th>BasicAuthenticationFilter</th><th>http/http-basic</th></tr><tr><th>SERVLETAPISUPPORT_FILTER</th><th>SecurityContextHolderAwareRequestFilter</th><th>http/@servlet-api-provision</th></tr><tr><th>JAASAPISUPPORT_FILTER</th><th>JaasApiIntegrationFilter</th><th>http/@jaas-api-provision</th></tr><tr><th>REMEMBERMEFILTER</th><th>RememberMeAuthenticationFilter</th><th>http/remember-me</th></tr><tr><th>ANONYMOUS_FILTER</th><th>AnonymousAuthenticationFilter</th><th>http/anonymous</th></tr><tr><th>SESSIONMANAGEMENTFILTER</th><th>SessionManagementFilter</th><th>session-management</th></tr><tr><th>EXCEPTIONTRANSLATIONFILTER</th><th>ExceptionTranslationFilter</th><th>http</th></tr> <tr><th>FILTERSECURITYINTERCEPTOR</th><th>FilterSecurityInterceptor</th><th>http</th></tr> <tr><th>SWITCHUSERFILTER</th><th>SwitchUserFilter</th><th>N/A</th></tr></table>

<p>  过滤器顺序从上到下<br>  自定义 Filter</p>
<p>自定义的 Filter 建议继承 GenericFilterBean，本文示例：</p>
<pre><code>package org.xxpay.common.util;
 public class BeforeLoginFilter extends GenericFilterBean {

@Override
public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)
        throws IOException, ServletException {
    System.out.println(&quot;This is a filter before UsernamePasswordAuthenticationFilter.&quot;);
    // 继续调用 Filter 链
    filterChain.doFilter(servletRequest, servletResponse);
}    
</code></pre><p>}`<br>配置自定义 Filter 在 Spring Security 过滤器链中的位置<br>配置很简单，本文示例：</p>
<pre><code>protected void configure(HttpSecurity http) throws Exception {
    http.authorizeRequests().antMatchers(&quot;/&quot;).permitAll().antMatchers(&quot;/user/**&quot;).hasRole(&quot;USER&quot;).and().formLogin()
            .loginPage(&quot;/login&quot;).defaultSuccessUrl(&quot;/user&quot;).and().logout().logoutUrl(&quot;/logout&quot;)
            .logoutSuccessUrl(&quot;/login&quot;);
    // 在 UsernamePasswordAuthenticationFilter 前添加 BeforeLoginFilter
    http.addFilterBefore(new BeforeLoginFilter(), UsernamePasswordAuthenticationFilter.class);
    // 在 CsrfFilter 后添加 AfterCsrfFilter
    http.addFilterAfter(new AfterCsrfFilter(), CsrfFilter.class);
}
</code></pre><p>说明： HttpSecurity 有三个常用方法来配置：</p>
<pre><code>addFilterBefore(Filter filter, Class beforeFilter) 在 beforeFilter 之前添加 filter`
addFilterAfter(Filter filter, Class afterFilter) 在 afterFilter 之后添加 filter`
addFilterAt(Filter filter, Class atFilter) 在 atFilter 相同位置添加 filter， 此 filter 不覆盖 filter
</code></pre><p>通过在不同 Filter 的 doFilter() 方法中加断点调试，可以判断哪个 filter 先执行，从而判断 filter 的执行顺序 。</p>
]]></content>
      <categories>
        <category>springSecurity</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>springSecurity</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring传播机制及隔离级别</title>
    <url>/2015/09/20/Spring%E4%BC%A0%E6%92%AD%E6%9C%BA%E5%88%B6%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
    <content><![CDATA[<p><strong>7种事务的传播机制（可通过spring配置或注解来设置）</strong></p>
<ol>
<li><strong>REQUIRED（默认）：</strong>支持当前事务，当前事务不存在，则新建一个事务。</li>
<li><strong>SUPPORTS：</strong>支持当前事务，当前事务不存在，则不使用事务。</li>
<li><strong>MANDATORY：</strong>中文翻译为强制，支持使用当前事务，如果当前事务不存在，则抛出Exception。</li>
<li><strong>REQUIRES_NEW：</strong>创建一个新事务，如果当前事务存在，把当前事务挂起。</li>
<li><strong>NOT_SUPPORTED：</strong>无事务执行，如果当前事务存在，把当前事务挂起。</li>
<li><strong>NEVER：</strong>无事务执行，当前有事务则抛出Exception。</li>
<li><strong>NESTED：</strong>嵌套事务，如果当前事务存在，那么在嵌套的事务中执行。如果当前事务不存在，则表现跟REQUIRED一样。</li>
</ol>
<blockquote>
<p>注解配置时如：@Transactional(propagation=Propagation.REQUIRED) </p>
</blockquote>
<p><strong>四种隔离级别</strong></p>
<blockquote>
<p>注解配置时如：@Transaction(isolation = Isolation.READ_UNCOMMITTED)</p>
</blockquote>
<table>
<thead>
<tr>
<th>事务隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td>读未提交（read-uncommitted</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>读已提交（read-commit)</td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>重复读（repeatable-read)</td>
<td>否</td>
<td>否</td>
<td>是</td>
</tr>
<tr>
<td>串行化(seriablizable)</td>
<td>否</td>
<td>否</td>
<td>否</td>
</tr>
</tbody>
</table>
<p>其中：重复读（repeatable-read)表示：在开始读取数据（事务开启）时，不允许修改操作。</p>
<p><strong>mysql默认的事务隔离级别为可重复读（repeatabled-read）</strong></p>
<p>事务的并发问题(事务A: A  事务B: B)</p>
<p>1.脏读：A读了B更新的数据，B回滚操作，则A读到的就是脏数据。</p>
<p>2.不可重复读：A多次读同一数据，B在A读取的过程中，对数据做了更新并提交，导致A多次读取数据时，结果不一致。</p>
<p>3.幻读：A多次读取同一批数据，B在A读取过程中，新增了一条数据（删除一条），导致A读到的数据新增了一条，似产生幻觉。</p>
<blockquote>
<p>（不可重复读侧重于修改，幻读侧重于新增或删除）解决不可重复读问题只需锁住满足条件的行，解决幻读需要锁表）</p>
</blockquote>
]]></content>
      <categories>
        <category>事务</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>java中日期格式规范</title>
    <url>/2019/07/27/java%E4%B8%AD%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>日期格式的规范：</p>
<p><strong>1.日期格式化时，传入pattern中表示年份统一使用小写的y。</strong></p>
<p>desc:日期格式化，yyyy表示当天所在的年，而大写的YYYY代表是 week in which year（jdk7之后引入的概念)，意思是当天所在的周属于的年份，一周从周日开始，周六结束，只要本周跨年，返回的YYYY就是下一年。</p>
<p>例如：<br>new SimpleDateFormat(“yyyy-MM-dd HH:mm:ss”);<br>反例：<br>某业务因使用YYYY/MM/dd进行日期格式化，2017/12/31执行结果为2018/12/31，导致在2017年12月31日当日实时消耗跌0，造成P2故障。</p>
<p><strong>2.日期格式中大写M和小写m，大写的H和小写的h指代的意义。</strong></p>
<p>desc: 日期格式中的这两对字母表示意义：</p>
<p>表示月份大写M；<br>表示分钟小写m；<br>24小时制的是大写H；<br>12小时制的是小写h；</p>
<p><strong>3.获取当前毫秒数：System.currentTimeMillis()；而不是new Date().getTime();</strong></p>
<p>desc:如果想要获取更加精确纳秒级时间值，使用System.nanoTime的方式。在JDK8中，针对统计时间等场景，推荐使用Instant类。</p>
<p><strong>4.不允许在程序中使用java.sql.Date和java.sql.Time。</strong></p>
<p>desc:前者不记录时间，getHours()抛出异常。后者不记录日期，getYear()抛出异常。</p>
<p><strong>5.不要在程序中写死一年为365天，避免在闰年时出现日期转换错误或程序逻辑错误。</strong></p>
<pre><code>正例:
//获取今年的天数
int dayOfThisYear = LocalDate.now().lengthOfYear();

//获取指定某年的天数
LocalDate.of(2011,1,1).lengthOfYear();

反例：

// 第一种情况：在闰年366天时，出现数组越界异常
int[] dayArray = new int[365];

// 第二种情况：一年有效期的会员制，今年1月26日注册，硬编码365返回的却是1月25日
Calendar calendar = Calendar.getInstance();
calendar.set(2020, 1, 26);
calendar.add(Calendar.DATE, 365);
</code></pre><p><strong>6.避免闰年二月问题。闰年的二月份有29天，一周年后的那天不可能是2月29日。</strong></p>
<p><strong>7.使用枚举值来指代月份。如果使用数字，注意Date,Calendar等日期的相关类的月份month取值在0-11之间。</strong></p>
<p>说明：参考JDK原生注释：Month value is 0-based. e.g., 0 for January.</p>
<p>正例： Calendar.JANUARY，Calendar.FEBRUARY，Calendar.MARCH等来指代相应月份来进行传参或比较。</p>
]]></content>
      <categories>
        <category>日期格式</category>
      </categories>
      <tags>
        <tag>日期格式</tag>
      </tags>
  </entry>
  <entry>
    <title>Map简述（一）</title>
    <url>/2018/07/21/hashMap%E7%AE%80%E8%BF%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<p><strong>HashMNap内存结构</strong></p>
<p>jdk1.8版，内部使用数组+链表/红黑树</p>
<p><img src="/images/hashMap_0001/hashmap_001.jpg" alt="Alt text"></p>
<p><strong>数据插入原理</strong></p>
<p><img src="/images/hashMap_0001/hashmap_002.jpg" alt="Alt text"></p>
<ol>
<li><p>判断数组是否为空，为空进行初始化</p>
</li>
<li><p>不为空计算key的hash值，通过(n-1)&amp;hash计算应当存放在数组中的下标idnex</p>
</li>
<li><p>查看table[index]是否存在数据，没有数据就构造一个Node节点存放在table[index]中</p>
</li>
<li><p>存在数据，说明发生了hash冲突，再判断key是否相等，相等则用新的value替换原来数据(onlyIfAbsent为false)</p>
</li>
<li><p>如果不相等，判断当前结点类型是否为树形节点，create 树形节点插入红黑树中</p>
</li>
<li><p>如果不是树形节点，创建普通Node加入链表中；判断链表长度是否大于8，大于则将链表转为红黑树</p>
</li>
<li><p>插入完成后判断当前节点数是否大于阀值，如果大于开始扩容为原来数据的2倍</p>
</li>
</ol>
<p><strong>HashMap初始化，设定初始化容量大小</strong></p>
<p>new HashMap()不传值，默认大小为16，负载因子是0.75，如果传入自己的初始化大小为k,初始化大小为大于k的2的整数次方，例传入10，大小为16。</p>
<pre><code>static final int tableSizeFor(int cap) {
  int n = cap - 1;
  n |= n &gt;&gt;&gt; 1;
  n |= n &gt;&gt;&gt; 2;
  n |= n &gt;&gt;&gt; 4;
  n |= n &gt;&gt;&gt; 8;
  n |= n &gt;&gt;&gt; 16;
  return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
</code></pre><p><strong>HashMap的哈希函数设计：</strong></p>
<p>先拿到key的hashcode,是32位int值，然后让hashcode的高、低16位进行或异操作。</p>
<pre><code>static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);
}
</code></pre><p><strong>哈希函数（扰动函数）设计如此原因</strong></p>
<ol>
<li><p>尽可能降低hash碰撞，与分散越好。</p>
</li>
<li><p>算法一定要尽可能高效，因为这是频繁操作，因此采用位运算。</p>
</li>
</ol>
<p><strong>jdk1.8对hashMap的优化</strong></p>
<ol>
<li><p>数组+链表改为数组+链表+红黑树</p>
</li>
<li><p>链表的插入方式从头插法改为尾插法，也就是插入的时候，数据位置上已经有元素，1.7将新元素放到数组中，原始节点作为新节点的后继节点，1.8遍历链表，将元素放置到链表的最后。</p>
</li>
<li><p>扩容的时候1.7需要对原数组中的元素进行重新hash定位，确定在新数组中的位置。1.8采用更简单的判断逻辑，位置不变或引用+旧容量大小</p>
</li>
<li><p>插入时，1.7先判断是否需要扩容，再插入。1.8先进行插入，插入完成再判断是否需要扩容。</p>
</li>
</ol>
<p><strong>优化效果</strong></p>
<p>防止发生hash冲突，链表长度过长，将时间复杂度由O(n)降为O(log n)</p>
<p>因为1.7头插法扩容时，头插法会使链表发生反转，多线程环境下会产生环</p>
<p>A线程在插入节点B，B线程也在插入，遇到容量不够开始扩容，重新hash，放置元素，采用头插法后遍历到B节点放入到头部，这样形成了环。</p>
<p><img src="/images/hashMap_0001/hashmap_003.jpg" alt="Alt text"></p>
<p>1.7扩容调用transfer代码</p>
<pre><code>void transfer(Entry[] newTable, boolean rehash) {
    int newCapacity = newTable.length;
    for (Entry&lt;K,V&gt; e : table) {
        while(null != e) {
            Entry&lt;K,V&gt; next = e.next;
               if (rehash) {
                  e.hash = null == e.key ? 0 : hash(e.key);
               }
        int i = indexFor(e.hash, newCapacity);
        e.next = newTable[i]; //A线程如果执行到这一行挂起，B线程开始进行扩容
        newTable[i] = e;
        e = next;
       }
   }
}
</code></pre><p><strong>扩容时1.8可不重新hash就可直接定位原节点在新的数据位置。</strong></p>
<blockquote>
<p>这是由于扩容时扩大为原数组大小的2倍，计算数组位置的掩码仅仅只是高位多个一个1。</p>
<p>如：<br>   扩容前长度为16，用于计算 (n-1) &amp; hash 的二进制n - 1为0000 1111，<br>   扩容后为32后的二进制就高位多了1，============&gt;为0001 1111。</p>
</blockquote>
<p><strong>线程安全问题</strong><br>jdk1.7下会产生死循环、数据丢失、数据覆盖问题。</p>
<p>jdk1.8中会有覆盖的问题:</p>
<p>当A线程执行到下面代码5行判断index位置为空后正好挂起，B线程开始执行第6行，往index位置的写入节点数据，这是A线程恢复现场，执行赋值操作，就把A线程的数据给覆盖了。</p>
<pre><code>final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict){
  Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;
  if ((tab = table) == null || (n = tab.length) == 0)
n = (tab = resize()).length;
  if ((p = tab[i = (n - 1) &amp; hash]) == null)  //多线程执行到这里
tab[i] = newNode(hash, key, value, null);
  else {
Node&lt;K,V&gt; e; K k;
if (p.hash == hash &amp;&amp;
((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
  e = p;
else if (p instanceof TreeNode)
  e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
else {
  for (int binCount = 0; ; ++binCount) {
if ((e = p.next) == null) {
  p.next = newNode(hash, key, value, null);
  if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
treeifyBin(tab, hash);
  break;
}
if (e.hash == hash &amp;&amp;
((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
  break;
p = e;
  }
}
if (e != null) { // existing mapping for key
  V oldValue = e.value;
  if (!onlyIfAbsent || oldValue == null)
e.value = value;
  afterNodeAccess(e);
  return oldValue;
}
  }
  ++modCount;
  if (++size &gt; threshold) // 多个线程走到这，可能重复resize()
resize();
  afterNodeInsertion(evict);
  return null;
}
</code></pre><p><strong>java中有HashTable/Collections.synchronizedMap/ConcurrentHashMap可以实现线程安全问题</strong></p>
<ul>
<li><p>HashTable是直接在操作方法上加synchronized关键字，锁住整个数组，粒度比较大。</p>
</li>
<li><p>Collections.synchronizedMap使用Collection集合工具的内部类，通过传入Map封装出一个SynchronizedMap对象，内部定义了一个对象锁，方法内通过对象锁实现；</p>
</li>
<li><p>ConcurrentHashMap使用分段锁，降低了所粒度，让并发大大提高。</p>
</li>
</ul>
<p><strong>CurrentHashMap原理</strong></p>
<p>成员变量使用volatile修饰，免除了指令重排序，同时保证内存可见性，另外使用CAS操作和synchronized结合实现赋值操作，多线程操作只会锁住当前操作索引的节点。</p>
<p>如图，线程A锁住A节点所在的链表，线程B锁住B节点所在链表，操作互不干涉。</p>
<p><img src="/images/hashMap_0001/hashmap_004.jpg" alt="Alt text"></p>
<blockquote>
<p>链表长度达到阀值8时转为红黑树，红黑树转为链表阀值为6，因为<br>在hash函数设计的情况下，发生hash碰撞8次的几率为百万分之6，比较小。转为链表阀值为6，是因为如果hash碰撞次数在8附近徘徊，会一直发生链表和红黑树的转化。</p>
</blockquote>
<p>HashMap内部节点是无序的，根据hash值随机插入的，LinkedHashMap、TreeMap是有序的。</p>
<ul>
<li><strong>LinkedHashMap</strong></li>
</ul>
<blockquote>
<p>内部维护了一个单链表，有头尾节点，同时LinkedHashMap节点Entry内部出了继承HashMap的Node属性，还有before/after用于标识前置节点和后置节点。可实现按插入顺序或访问顺序排序。</p>
</blockquote>
<p><img src="/images/hashMap_0001/hashmap_005.jpg" alt="Alt text"></p>
<ul>
<li><strong>TreeMap</strong></li>
</ul>
<p>按照key的自然顺序或者Comprator顺序进行排序，内部是通过红黑树实现的。要么key所属的类实现Comparable接口，或者自定义一个实现了Comparator接口的比较器，传给TreeMap用户key的比较。</p>
]]></content>
      <categories>
        <category>集合</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
        <tag>LinkedHashMap</tag>
        <tag>TreeMap</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2025/06/09/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>java中的锁(偏向锁、轻量锁..）</title>
    <url>/2019/03/09/java%E4%B8%AD%E7%9A%84%E9%94%81(%E5%81%8F%E5%90%91%E9%94%81%E3%80%81%E8%BD%BB%E9%87%8F%E9%94%81..%EF%BC%89/</url>
    <content><![CDATA[<p><strong>CAS操作：</strong><br>compareAndSwap,比较并替换，实现并发算法常用技术</p>
<p>CAS需要有3个操作数：<br>内存地址V,旧预期值A，即将更新的目标值B。</p>
<p><strong>锁的升级：</strong></p>
<ul>
<li><p>jdk1.6后，锁共有四种状态：无锁状态、偏向锁状态、轻量锁状态、重量锁状态</p>
</li>
<li><p>锁的状态会随着竞争情况逐渐升级，锁允许升级但不允许降级</p>
</li>
<li><p>不允许降级的目的是提高获取锁和释放锁的效率</p>
</li>
</ul>
<p><strong>锁的升级过程</strong></p>
<blockquote>
<p>无锁–&gt;偏向锁–&gt;轻量级锁–&gt;重量级锁</p>
</blockquote>
<p><strong>偏向锁综述</strong></p>
<ul>
<li>问题：不是多线程竞争时，只是同一个线程多次获取同一锁，为让线程获得锁代价更低，自此设计了偏向锁。</li>
</ul>
<ul>
<li><p>目的：偏向锁降低了一个线程访问临界区资源的时候，频繁CAS加锁、解锁操作的开支</p>
</li>
<li><p>原理：只有一个线程执行同步块时，通过增加标记检查，而减少CAS操作进一步提供性能。</p>
</li>
</ul>
<ul>
<li>场景：只有一个线程访问临界区资源的时候。</li>
</ul>
<ul>
<li>数据结构： 占有锁的线程ID，是否偏向锁、epoch(偏向锁的时间戳)，对象分代年龄、锁标志位。</li>
</ul>
<p><img src="/images/java_lock_01/偏向锁_01.jpg" alt="Alt text"></p>
<p><strong>偏向锁流程图：</strong></p>
<ul>
<li><p>线程1：偏向锁初始化过程</p>
</li>
<li><p>线程2：偏向锁的撤销锁过程</p>
</li>
</ul>
<p><img src="/images/java_lock_01/轻量级锁_01.png" alt="Alt text"></p>
<blockquote>
<p>综述： 偏向锁适合只有一个线程访问同步代码块的场景。通过CAS操作来判断和更新对象头中的ThreadID。如果ThreadID是本线程，则直接进入同步代码块执行。无需进入和竞争内核级锁，原线程无间断继续执行。如果ThreadID不是本地线程或者CAS操作失败，则升级为轻量级锁。</p>
</blockquote>
<p><strong>偏向锁初始化</strong></p>
<ul>
<li><p>一个线程访问同步代码块获取到锁时，会在对象头和栈帧中的锁记录里，存储偏向锁的线程ID，以后该线程再进入和退出同步块时不需花费CAS操作来加锁和解锁，而是先检查对象头中的markword中是否存储了线程</p>
<ul>
<li><p>如果已存储，说明线程已经获取到锁，继续执行任务即可。</p>
</li>
<li><p>如果未存储，则需要再判断当前锁是否是偏向锁（对象头中偏向锁的标识是否设置为了1，锁标识位为01）:</p>
<ul>
<li><p>如果没有设置，则使用CAS竞争锁（说明此时不是偏向锁，一定是等级高于它的锁）</p>
</li>
<li><p>如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程，结构中的线程ID</p>
<blockquote>
<p>最顺利情况是线程ID指向该线程，只有一个线程频繁访问临界区资源，此时能够最大程度减少CAS操作。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>轻量级</strong></p>
<p>起源：由于线程阻塞、唤醒需要CPU在用户状态和内核状态间切换，频繁的转换会对CPU造成负担，对并发性能带来很大影响。</p>
<p>原理：只有两个线程并发访问资源区时，一个持有锁，另一个自旋等待。</p>
<p><strong>轻量锁加锁</strong></p>
<p>线程在执行同步块之前，JVM会先在当前线程的栈帧中创建用户储存锁记录的空间，并将对象头中的mark word复制到锁记录中（displaced mark word)做一份拷贝</p>
<p>拷贝成功后，线程尝试使用CAS将对象头中的mark word替换成指向锁记录的指针</p>
<p>  如果更新成功，当前线程获得锁，继续执行同步方法<br>  如果更新失败，代表其他线程持有锁，当前线程便尝试使用自旋来获取锁，自旋后没有获得锁，此时轻量级锁会升级为重量级锁，当前线程会被阻塞。</p>
<p><strong>轻量级锁解锁</strong></p>
<p>解锁时会使用CAS操作将Displaced Mark Word替换回到对象头</p>
<p>  如果解锁成功，则表示没有竞争发生</p>
<p>  如果解锁失败，表示当前锁存在竞争，锁会膨胀为重量级锁，需要在释放锁的同事唤醒被阻塞的线程，之后线程间要根据重量级锁规则重新竞争重量级锁。</p>
<p><img src="/images/java_lock_01/轻量级锁_01.png" alt="Alt text"></p>
<p>偏向锁、轻量级锁、重量级锁比较</p>
<p><img src="/images/java_lock_01/锁差异_01.png" alt="Alt text"></p>
<p><strong>ReentrantLock，独占式锁的加锁流程：</strong></p>
<ul>
<li><p>ReentrantLock的lock方法的实现委托给了ReentrantLock内部的AQS的实现类Sync的acquire(int args)方法，而Sync并没有重写该方法，acquire的具体实现在抽象类AbstractQueuedSynchronizer</p>
</li>
<li><p>acquire方法会调用tryAcquire方法尝试获取锁，这是发生多个线程竞争的地方，其中只有一个线程可通过CAS方法获得锁并返回true,竞争失败的线程都返回false</p>
</li>
<li><p>竞争失败的线程会被addWaiter方法包装成一个节点，放入到双向队列的尾部。</p>
</li>
<li><p>放入队列之后，在acquireQueued方法中进行自旋操作，但只有头节点的后继节点才能调用tryAcquire方法尝试获取锁，其他的后继节点只会空自旋。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>lock</category>
      </categories>
      <tags>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title>java中创建对象的五种形式</title>
    <url>/2015/06/18/java%E4%B8%AD%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E7%9A%84%E4%BA%94%E7%A7%8D%E5%BD%A2%E5%BC%8F/</url>
    <content><![CDATA[<p>我们每天创建很多对象，通常使用依赖管理，比如Spring去创建对象。然而这里有很多创建对象的方法，我们会在这篇文章中学到。</p>
<p><strong>Java中有5种创建对象的方式，下面给出它们的例子还有它们的字节码</strong></p>
<ol>
<li>使用new关键字    } → 调用了构造函数</li>
<li>使用Class类的newInstance方法    } → 调用了构造函数</li>
<li>使用Constructor类的newInstance方法    } → 调用了构造函数</li>
<li>使用clone方法    } → 没有调用构造函数</li>
<li>使用反序列化    } → 没有调用构造函数</li>
<li>如果你运行了末尾的的程序，你会发现方法1,2,3用构造函数创建对象，方法4,5没有调用构造函数。</li>
</ol>
<p><strong>1.使用new关键字</strong></p>
<p>这是最常见也是最简单的创建对象的方式了。通过这种方式，我们可以调用任意的构造函数(无参的和带参数的)。</p>
<pre><code>Employee emp1 = new Employee();
0: new   #19  // class org/programming/mitra/exercises/Employee
3: dup
4: invokespecial #21  // Method org/programming/mitra/exercises/Employee.&quot;&quot;:()V
</code></pre><p><strong>2.使用Class类的newInstance方法</strong></p>
<p>我们也可以使用Class类的newInstance方法创建对象。这个newInstance方法调用无参的构造函数创建对象。</p>
<p>我们可以通过下面方式调用newInstance方法创建对象:</p>
<pre><code>Employee emp2 = (Employee) Class.forName(&quot;org.programming.mitra.exercises.Employee&quot;).newInstance();
或者

Employee emp2 = Employee.class.newInstance();
51: invokevirtual#70// Method java/lang/Class.newInstance:()Ljava/lang/Object;
</code></pre><p><strong>3.使用Constructor类的newInstance方法</strong></p>
<p>和Class类的newInstance方法很像， java.lang.reflect.Constructor类里也有一个newInstance方法可以创建对象。我们可以通过这个newInstance方法调用有参数的和私有的构造函数。</p>
<pre><code>Constructor&lt;Employee&gt; constructor = Employee.class.getConstructor();
Employee emp3 = constructor.newInstance();
111: invokevirtual  #80  // Method java/lang/reflect/Constructor.newInstance:([Ljava/lang/Object;)Ljava/lang/Object;
</code></pre><p>这两种newInstance方法就是大家所说的反射。事实上Class的newInstance方法内部调用Constructor的newInstance方法。这也是众多框架，如Spring、Hibernate、Struts等使用后者的原因。想了解这两个newInstance方法的区别，请看这篇Creating objects through Reflection in Java with Example.</p>
<p><strong>4.使用clone方法</strong></p>
<p>无论何时我们调用一个对象的clone方法，jvm就会创建一个新的对象，将前面对象的内容全部拷贝进去。用clone方法创建对象并不会调用任何构造函数。</p>
<p>要使用clone方法，我们需要先实现Cloneable接口并实现其定义的clone方法。</p>
<pre><code>Employee emp4 = (Employee) emp3.clone();
162: invokevirtual #87  // Method org/programming/mitra/exercises/Employee.clone ()Ljava/lang/Object;
</code></pre><p><strong>5.使用反序列化</strong></p>
<p>当我们序列化和反序列化一个对象，jvm会给我们创建一个单独的对象。在反序列化时，jvm创建对象并不会调用任何构造函数。<br>为了反序列化一个对象，我们需要让我们的类实现Serializable接口</p>
<pre><code>ObjectInputStream in = new ObjectInputStream(new FileInputStream(&quot;data.obj&quot;));
Employee emp5 = (Employee) in.readObject();
261: invokevirtual  #118   // Method java/io/ObjectInputStream.readObject:()Ljava/lang/Object;
</code></pre><p>我们从上面的字节码片段可以看到，除了第1个方法，其他4个方法全都转变为invokevirtual(创建对象的直接方法)，第一个方法转变为两个调用，new和invokespecial(构造函数调用)。</p>
<p>例子</p>
<p>让我们看一看为下面这个Employee类创建对象：</p>
<pre><code>class Employee implements Cloneable, Serializable {
    private static final long serialVersionUID = 1L;
    private String name;
    public Employee() {
    System.out.println(&quot;Employee Constructor Called...&quot;);
}
public String getName() {
    return name;
}
public void setName(String name) {
    this.name = name;
}
@Override
public int hashCode() {
    final int prime = 31;
    int result = 1;
    result = prime * result + ((name == null) ? 0 : name.hashCode());
    return result;
}
@Override
public boolean equals(Object obj) {
    if (this == obj)
    return true;
    if (obj == null)
    return false;
    if (getClass() != obj.getClass())
    return false;
    Employee other = (Employee) obj;
    if (name == null) {
    if (other.name != null)
    return false;
    } else if (!name.equals(other.name))
    return false;
    return true;
}
@Override
public String toString() {
    return &quot;Employee [name=&quot; + name + &quot;]&quot;;
}
@Override
public Object clone() {
    Object obj = null;
    try {
    obj = super.clone();
    } catch (CloneNotSupportedException e) {
    e.printStackTrace();
    }
    return obj;
    }
}
</code></pre><p>下面的Java程序中，我们将用5种方式创建Employee对象。你可以从GitHub找到这些代码。</p>
<pre><code>public class ObjectCreation {
public static void main(String... args) throws Exception {
    // By using new keyword
    Employee emp1 = new Employee();
    emp1.setName(&quot;Naresh&quot;);
    System.out.println(emp1 + &quot;, hashcode : &quot; + emp1.hashCode());
    // By using Class class&apos;s newInstance() method
    Employee emp2 = (Employee) Class.forName(&quot;org.programming.mitra.exercises.Employee&quot;)
                           .newInstance();
    // Or we can simply do this
    // Employee emp2 = Employee.class.newInstance();
    emp2.setName(&quot;Rishi&quot;);
    System.out.println(emp2 + &quot;, hashcode : &quot; + emp2.hashCode());
    // By using Constructor class&apos;s newInstance() method
    Constructor&lt;Employee&gt; constructor = Employee.class.getConstructor();
    Employee emp3 = constructor.newInstance();
    emp3.setName(&quot;Yogesh&quot;);
    System.out.println(emp3 + &quot;, hashcode : &quot; + emp3.hashCode());
    // By using clone() method
    Employee emp4 = (Employee) emp3.clone();
    emp4.setName(&quot;Atul&quot;);
    System.out.println(emp4 + &quot;, hashcode : &quot; + emp4.hashCode());
    // By using Deserialization
    // Serialization
    ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(&quot;data.obj&quot;));
    out.writeObject(emp4);
    out.close();
    //Deserialization
    ObjectInputStream in = new ObjectInputStream(new FileInputStream(&quot;data.obj&quot;));
    Employee emp5 = (Employee) in.readObject();
    in.close();
    emp5.setName(&quot;Akash&quot;);
    System.out.println(emp5 + &quot;, hashcode : &quot; + emp5.hashCode());
}
</code></pre><p>}<br>程序会输出：</p>
<pre><code>Employee Constructor Called...
Employee [name=Naresh], hashcode : -1968815046
Employee Constructor Called...
Employee [name=Rishi], hashcode : 78970652
Employee Constructor Called...
Employee [name=Yogesh], hashcode : -1641292792
Employee [name=Atul], hashcode : 2051657
Employee [name=Akash], hashcode : 63313419
</code></pre>]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>java静态代理、动态代理（jdk,cglib)</title>
    <url>/2015/06/23/java%E9%9D%99%E6%80%81%E4%BB%A3%E7%90%86%E3%80%81%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%EF%BC%88jdk,cglib)/</url>
    <content><![CDATA[<p>一：代理模式（静态代理）</p>
<p>  代理模式是常用设计模式的一种，我们在软件设计时常用的代理一般是指静态代理，也就是在代码中显式指定的代理。</p>
<p>  静态代理由 业务实现类、业务代理类 两部分组成。业务实现类 负责实现主要的业务方法，业务代理类负责对调用的业务方法作拦截、过滤、预处理，主要是在方法中首先进行预处理动作，然后调用业务实现类的方法，还可以规定调用后的操作。我们在需要调用业务时，不是直接通过业务实现类来调用的，而是通过业务代理类的同名方法来调用被代理类处理过的业务方法。</p>
<p>  静态代理的实现：<br>    1：首先定义一个接口，说明业务逻辑。          </p>
<pre><code>package net.battier.dao;      
/** 
 * 定义一个账户接口 
 * @author Administrator
 */  
public interface Count {  
    // 查询账户
    public void queryCount();  

    // 修改账户  
    public void updateCount();  

}  
</code></pre><p>  2：然后，定义业务实现类，实现业务逻辑接口</p>
<p>import net.battier.dao.Count;<br>/** </p>
<ul>
<li>委托类(包含业务逻辑) </li>
<li></li>
<li>@author Administrator </li>
<li><p>*/<br>public class CountImpl implements Count {  </p>
<p>@Override<br>public void queryCount() {  </p>
<pre><code>System.out.println(&quot;查看账户...&quot;);  
</code></pre><p>}  </p>
<p>@Override<br>public void updateCount() {  </p>
<pre><code>System.out.println(&quot;修改账户...&quot;);  
</code></pre><p>}  </p>
</li>
</ul>
<p>}  </p>
<p> 3：定义业务代理类：通过组合，在代理类中创建一个业务实现类对象来调用具体的业务方法；通过实现业务逻辑接口，<br>  来统一业务方法；在代理类中实现业务逻辑接口中的方法时，进行预处理操作、通过业务实现类对象调用真正的业务方法、<br>  进行调用后操作的定义。</p>
<p>public class CountProxy implements Count {<br>    private CountImpl countImpl;  //组合一个业务实现类对象来进行真正的业务方法的调用</p>
<pre><code>/** 
 * 覆盖默认构造器 
 *  
 * @param countImpl 
 */  
public CountProxy(CountImpl countImpl) {  
    this.countImpl = countImpl;  
}  

@Override  
public void queryCount() {  
    System.out.println(&quot;查询账户的预处理——————&quot;);  
    // 调用真正的查询账户方法
    countImpl.queryCount();  
    System.out.println(&quot;查询账户之后————————&quot;);  
}  

@Override  
public void updateCount() {  
    System.out.println(&quot;修改账户之前的预处理——————&quot;);  
    // 调用真正的修改账户操作
    countImpl.updateCount();  
    System.out.println(&quot;修改账户之后——————————&quot;);  

}  
</code></pre><p>}  </p>
<p> 4：在使用时，首先创建业务实现类对象，然后把业务实现类对象作构造参数创建一个代理类对象，最后通过代理类对象进行业务方法的调用。</p>
<p> public static void main(String[] args) {<br>        CountImpl countImpl = new CountImpl();<br>        CountProxy countProxy = new CountProxy(countImpl);<br>        countProxy.updateCount();<br>        countProxy.queryCount();  </p>
<pre><code>}  
</code></pre><p>  静态代理的缺点很明显：一个代理类只能对一个业务接口的实现类进行包装，如果有多个业务接口的话就要定义很多实现类<br>  和代理类才行。而且，如果代理类对业务方法的预处理、调用后操作都是一样的（比如：调用前输出提示、调用后自动关闭<br>  连接），则多个代理类就会有很多重复代码。这时我们可以定义这样一个代理类，它能代理所有实现类的方法调用：根据传进<br>  来的业务实现类和方法名进行具体调用。——那就是动态代理。</p>
<p> 二：动态代理的第一种实现——JDK动态代理</p>
<p> JDK动态代理所用到的代理类在程序调用到代理类对象时才由JVM真正创建，JVM根据传进来的 业务实现类对象 以及 方法名 ，动态地创建了一个代理类的class文件并被字节码引擎执行，然后通过该代理类对象进行方法调用。我们需要做的，只需指定代理类的预处理、调用后操作即可。</p>
<p> 1：首先，定义业务逻辑接口</p>
<pre><code>public interface BookFacade {  
    public void addBook();  
} 
       2：然后，实现业务逻辑接口创建业务实现类


public class BookFacadeImpl implements BookFacade {   
    @Override  
    public void addBook() {  
    System.out.println(&quot;增加图书方法。。。&quot;);  
    }  

} 
</code></pre><p> 3：最后，实现 调用管理接口InvocationHandler  创建动态代理类</p>
<pre><code>public class BookFacadeProxy implements InvocationHandler {  
    private Object target;//这其实业务实现类对象，用来调用具体的业务方法 
    /** 
     * 绑定业务对象并返回一个代理类  
     */  
    public Object bind(Object target) {  
    this.target = target;  //接收业务实现类对象参数

       //通过反射机制，创建一个代理类对象实例并返回。用户进行方法调用时使用
       //创建代理对象时，需要传递该业务类的类加载器（用来获取业务实现类的元数据，在包装方法是调用真正的业务方法）、接口、handler实现类
    return Proxy.newProxyInstance(target.getClass().getClassLoader(),  
        target.getClass().getInterfaces(), this); }  
    /** 
     * 包装调用方法：进行预处理、调用后处理 
     */  
    public Object invoke(Object proxy, Method method, Object[] args)  
        throws Throwable {  
    Object result=null;  

    System.out.println(&quot;预处理操作——————&quot;);  
    //调用真正的业务方法  
    result=method.invoke(target, args);  

    System.out.println(&quot;调用后处理——————&quot;);  
    return result;  
    }  

}  
</code></pre><p> 4：在使用时，首先创建一个业务实现类对象和一个代理类对象，然后定义接口引用（这里使用向上转型）并用代理对象.bind<br> (业务实现类对象)的返回值进行赋值。最后通过接口引用调用业务方法即可。（接口引用真正指向的是一个绑定了业务类的<br> 代理类对象，所以通过接口方法名调用的是被代理的方法们）</p>
<p>public static void main(String[] args) {<br>        BookFacadeImpl bookFacadeImpl=new BookFacadeImpl();<br>        BookFacadeProxy proxy = new BookFacadeProxy();<br>        BookFacade bookfacade = (BookFacade) proxy.bind(bookFacadeImpl);<br>        bookfacade.addBook();<br>    }  </p>
<p>  JDK动态代理的代理对象在创建时，需要使用业务实现类所实现的接口作为参数（因为在后面代理方法时需要根据接口内的方法名进行调用）。如果业务实现类是没有实现接口而是直接定义业务方法的话，就无法使用JDK动态代理了。并且，如果业务实现类中新增了接口中没有的方法，这些方法是无法被代理的（因为无法被调用）。</p>
<p>  三：动态代理的第二种实现——CGlib</p>
<p>  cglib是针对类来实现代理的，原理是对指定的业务类生成一个子类，并覆盖其中业务方法实现代理。因为采用的是继承，所以不能对final修饰的类进行代理。 </p>
<p>  1：首先定义业务类，无需实现接口（当然，实现接口也可以，不影响的）</p>
<pre><code>/**
* 
* @ClassName: RealSubject.java
* @Description: 被代理对象（真实对象）
* @version: v1.0.0
* @author: Administrator
*
 */
public class RealSubject {

  public void realSubjectMethod(){
        System.err.println(&quot;被代理对象realSubject:realSubjectMethod测试....&quot;);
  }
} 
</code></pre><p>  2：实现 MethodInterceptor方法代理接口，创建代理类</p>
<pre><code>package com.lance.test.cglib;
import java.lang.reflect.Method;
import org.springframework.cglib.proxy.Enhancer;
import org.springframework.cglib.proxy.MethodInterceptor;
import org.springframework.cglib.proxy.MethodProxy;
/**
 * cglib是针对类来实现的代理，原理是对指定的业务类生成一个子类，并覆盖其中业务的方法实现代理。
 * 因为采用的是集成，所以不能对final修饰的类进行代理。 
 *
 */
public class CglibProxy implements MethodInterceptor{

     private Object target;//业务类对象，供代理方法中进行真正的业务方法的调用

     //public CglibProxy(){}
     //生成代理对象
     /*
    public Object getInstance(Object target){
        this.target = target;//给业务对象赋值
        Enhancer enhancer = new Enhancer();//创建业务加强器，用来创建动态代理类
        enhancer.setSuperclass(target.getClass());//加强器指定要代理的业务（为下面生成的代理类指定父类）
        enhancer.setCallback(this);//设置回调：对于代理类上所有的方法调用，都会调用callBack,而callBack则需要实现interceptor()方法进行拦截

        return enhancer.create();//创建动态代理类并返回
    }
     */
     public CglibProxy(Object target){
     this.target = target;
     }
     public Object getInstance(Class cls){
    Enhancer enhancer = new Enhancer();
    enhancer.setSuperclass(cls);
    return enhancer.create(cls, this);
         }
     @Override
     public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {
    System.err.println(&quot;调用方法之前....&quot;);
    Object resObj = proxy.invokeSuper(obj, args);//调用业务类（父类中）的方法
    System.err.println(&quot;调用方法之后....&quot;);
    return resObj;
    }
}
</code></pre><p>  3：创建业务类和代理类对象，然后通过  代理类对象.getInstance(业务类对象)  返回一个动态代理类对象<br>  （它是业务类的子类，可以用业务类引用指向它）。最后通过动态代理类对象进行方法调用。</p>
<pre><code>public class CglibTest {
public static void main(String[] args) {
    //创建业务类和代理类对象，然后通过 代理类对象.getInstance(业务类对象) 返回一个动态代理类对象
    //RealSubject realSubject = new RealSubject();
    //CglibProxy cglibProxy = new CglibProxy();
    //RealSubject proxy = (RealSubject) cglibProxy.getInstance(realSubject);
    //proxy.realSubjectMethod();
    CglibProxy cglibProxy = new CglibProxy(new RealSubject());
    RealSubject proxySubject = (RealSubject) cglibProxy.getInstance(RealSubject.class);
    proxySubject.realSubjectMethod();
}
   } 
</code></pre><p>  四：比较</p>
<p>  静态代理是通过在代码中显式定义一个业务实现类一个代理，在代理类中对同名的业务方法进行包装，用户通过代理类<br>  调用被包装过的业务方法；</p>
<p>  JDK动态代理是通过接口中的方法名，在动态生成的代理类中调用业务实现类的同名方法；</p>
<p>  CGlib动态代理是通过继承业务类，生成的动态代理类是业务类的子类，通过重写业务方法进行代理；</p>
]]></content>
      <categories>
        <category>proxy</category>
      </categories>
      <tags>
        <tag>proxy</tag>
      </tags>
  </entry>
  <entry>
    <title>java类加载过程-jvm class loading 加载类机制</title>
    <url>/2015/07/12/java%E7%B1%BB%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%E8%AF%A6%E7%BB%86%E8%A7%A3%E8%AF%BB/</url>
    <content><![CDATA[<ul>
<li><p>什么是类的加载</p>
</li>
<li><p>类的生命周期</p>
</li>
<li><p>运行时（晚期）绑定</p>
<p>java源文件被javac编译为class字节码文件。<br>javac编译时不进行连接分配内存工作，而是在jvm运行时才动态加载和动态连接。</p>
</li>
</ul>
<ul>
<li>什么是类的加载</li>
</ul>
<blockquote>
<p>JVM将class文件读取到内存中，经过对class文件的校验、转换、解析、初始化，最终在jvm<br>的heap和方法区分配内存形成可以被jvm直接使用的类型的过程。</p>
</blockquote>
<p>  <strong>类的生命周期</strong></p>
<p>  7个阶段依次为：loading verification preparation resolution initialization using unloading</p>
<p><img src="/images/classload_001/0001.jpg" alt="Alt text"></p>
<p>  加载、验证、准备、初始化、卸载的顺序是确定的，“解析”不一定在初始化之前，也可能是在初始化之后。</p>
<p>  <strong>运行时（晚期）绑定</strong></p>
<p>  一个阶段的执行过程中会调用或激活另一个阶段</p>
<p>  <strong>分阶段</strong></p>
<ul>
<li>1、加载loading</li>
</ul>
<blockquote>
<p>这个阶段jvm完成如下工作：<br>首先  类加载器通过类的全路径限定名读取类的二进制字节流。<br>然后  将二进制字节流代表的类结构转化到运行时数据区的 方法区中。<br>最后  jvm heap中生成代表这个类的java.lang.class实例（不是这个类的实例）。</p>
</blockquote>
<p>  类加载器: </p>
<blockquote>
<p>获取类的二进制流可以使用jvm自带的类加载器，也可以使用自己写的类加载器，这是可控的。不同的类加载器<br>可以从各种地方读取：zip包、jar包、class文件、网络流等读取类的二进制字节流。<br>同一个加载器加载的同源类才是真的同类。不同加载器加载同源类，不是同类！ instanceof为false</p>
</blockquote>
<p>类加载的双亲委派模型:</p>
<blockquote>
<p>各个加载器都是先委托自己的父加载器加载类，若确实没加载到再自己来加载。<br>于是java默认的类查找加载顺序是自顶向下的，树状结构。<br>双亲委托的意图是保证java类型体系中最基础的行为一致，优先加载jdk中的类。</p>
</blockquote>
<p><img src="/images/classload_001/0002.jpg" alt="Alt text"></p>
<p>加载器主要有四种：</p>
<blockquote>
<p>jvm启动类加载器bootstrap loader，用c++实现为jvm的一部分（仅指sun的hotspot)，负责JAVA_HOME/lib下面<br>的类库中的类的加载，这个加载器，java程序无法引用到。</p>
<p>扩展类加载器 Extension loader，由sun.misc.Launcher$ExtClassLoader类实现，可在java中使用，<br>负责JAVA_HOME/lib/ext目录和java.ext.dir目录中类库的类的加载。</p>
<p>应用系统类加载器Application System Loader，由sum.misc.Louncher$AppClassLoader实现，负责加载<br>用户类路径中类库中的类，如果没有使用自定义的加载器，这个就是默认加载器。</p>
</blockquote>
<p>OSGI的网状加载模型</p>
<p><img src="/images/classload_001/0003.jpg" alt="Alt text"></p>
<ul>
<li>2、验证verification</li>
</ul>
<blockquote>
<p>Loading和验证是交叉进行的，验证二进制字节流代表的字节码文件是否合格，从以下几个方面判断：<br>文件格式：参看class文件格式详解，经过文件格式验证之后的字节流才能进入方法区分配内存来储存。<br>元数据验证：数据流和控制流的分析，最复杂。<br>符号引用验证：符号引用转化为直接引用时（解析阶段），检测对类自身以外的信息进行存在性，可访问性验证<br>如果确认代码安全，可用-Xverify:none关闭大部分类的验证，加快雷佳在时间。</p>
</blockquote>
<ul>
<li>3、准备preparation</li>
</ul>
<blockquote>
<p>在方法区中类的类变量（static修饰）分配内存。<br>然后初始化其值，如果类变量是常量，则直接赋值为该变量值否则为java类型的默认的零值。</p>
</blockquote>
<ul>
<li>4、解析resolution</li>
</ul>
<blockquote>
<p>指将常量池内的符号引用替换为直接引用的过程。</p>
</blockquote>
<ul>
<li>5、初始化initialization</li>
</ul>
<blockquote>
<p>这个阶段才真正开始执行java代码，静态代码块和设置变量的初始化值为程序员设定的值。</p>
</blockquote>
<p><strong>主动引用</strong></p>
<blockquote>
<p>有且只有下面五种情况才会立即初始化类，成为主动引用：</p>
<ol>
<li><p>new 对象时</p>
</li>
<li><p>读取或设置类的静态字段（除了被final，已在编译期把结果放入常量池的静态字段）或调用类的</p>
</li>
<li><p>静态方法时；用java.lang.reflect包的方法对类进行反射调用没初始化过的类时</p>
</li>
<li><p>初始化一个雷时发现其父类没初始化，则要先初始化其父类。含main方法的那个类，jvm启动时，</p>
</li>
<li><p>需要指定一个执行主类，jvm先初始化这个类，其他对类的引用成为被动引用，加载类时不会进行初始化。</p>
</li>
</ol>
<p><strong>子类继承父类时的初始化顺序</strong></p>
<ol>
<li>首先初始化父类的static变量和static块，按出现顺序。</li>
<li>初始化子类的static变量和static块，按出现顺序。</li>
<li>初始化父类的普通变量，调用父类的构造函数。</li>
<li>初始化子类的普通变量，调用子类的构造函数。</li>
</ol>
</blockquote>
<p><a href="https://blog.csdn.net/tangdong3415/article/details/53768099" target="_blank" rel="noopener">https://blog.csdn.net/tangdong3415/article/details/53768099</a></p>
]]></content>
      <categories>
        <category>classloader</category>
      </categories>
      <tags>
        <tag>classloader</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title>jdk8链接mysql问题</title>
    <url>/2021/09/22/jdk8%E9%93%BE%E6%8E%A5mysql%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>前几天发现一直跑的项目本地无法启动了：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure</span><br><span class="line"></span><br><span class="line">The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.</span><br><span class="line">	at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:174) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:64) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.mysql.cj.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:827) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.mysql.cj.jdbc.ConnectionImpl.&lt;init&gt;(ConnectionImpl.java:447) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.mysql.cj.jdbc.ConnectionImpl.getInstance(ConnectionImpl.java:237) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.mysql.cj.jdbc.NonRegisteringDriver.connect(NonRegisteringDriver.java:199) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.zaxxer.hikari.util.DriverDataSource.getConnection(DriverDataSource.java:136) ~[HikariCP-3.2.0.jar:na]</span><br><span class="line">	at com.zaxxer.hikari.pool.PoolBase.newConnection(PoolBase.java:369) ~[HikariCP-3.2.0.jar:na]</span><br><span class="line">	at com.zaxxer.hikari.pool.PoolBase.newPoolEntry(PoolBase.java:198) ~[HikariCP-3.2.0.jar:na]</span><br><span class="line">	at com.zaxxer.hikari.pool.HikariPool.createPoolEntry(HikariPool.java:467) [HikariCP-3.2.0.jar:na]</span><br><span class="line">	at com.zaxxer.hikari.pool.HikariPool.checkFailFast(HikariPool.java:541) [HikariCP-3.2.0.jar:na]</span><br><span class="line">	at com.zaxxer.hikari.pool.HikariPool.&lt;init&gt;(HikariPool.java:115) [HikariCP-3.2.0.jar:na]</span><br><span class="line">	at com.zaxxer.hikari.HikariDataSource.getConnection(HikariDataSource.java:112) [HikariCP-3.2.0.jar:na]</span><br><span class="line">	at com.zaxxer.hikari.HikariDataSource$$FastClassBySpringCGLIB$$eeb1ae86.invoke(&lt;generated&gt;) [HikariCP-3.2.0.jar:na]</span><br></pre></td></tr></table></figure></p>
<p>看到Communications link failure初步认为是超时了，网络问题导致的，但在解决了网络问题后发现依旧报相同的错，这就奇怪了，然后一条一条的看报错日志，找到：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">javax.net.ssl.SSLHandshakeException: No appropriate protocol (protocol is disabled or cipher suites are inappropriate)</span><br><span class="line">	at sun.security.ssl.HandshakeContext.&lt;init&gt;(HandshakeContext.java:171) ~[na:1.8.0_292]</span><br><span class="line">	at sun.security.ssl.ClientHandshakeContext.&lt;init&gt;(ClientHandshakeContext.java:98) ~[na:1.8.0_292]</span><br><span class="line">	at sun.security.ssl.TransportContext.kickstart(TransportContext.java:220) ~[na:1.8.0_292]</span><br><span class="line">	at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:428) ~[na:1.8.0_292]</span><br><span class="line">	at com.mysql.cj.protocol.ExportControlled.performTlsHandshake(ExportControlled.java:316) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.mysql.cj.protocol.StandardSocketFactory.performTlsHandshake(StandardSocketFactory.java:188) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.mysql.cj.protocol.a.NativeSocketConnection.performTlsHandshake(NativeSocketConnection.java:99) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	at com.mysql.cj.protocol.a.NativeProtocol.negotiateSSLConnection(NativeProtocol.java:331) ~[mysql-connector-java-8.0.17.jar:8.0.17]</span><br><span class="line">	... 68 common frames omitted</span><br></pre></td></tr></table></figure></p>
<p>看到SSLHandshakeException，心里打起了问号？这个错误比较反常，最终网上找了一番，问题定位了：</p>
<p>JDK 8高版本导致的，之前用的1.8.0_281，前些天捣鼓Homebrew，发现JDK 8有新版本，就升级了1.8.0_292，然后发现项目无法启动了。</p>
<p>查看/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/jre/lib/security/java.security（Mac上；Windows同理，在jre/lib/security/java.security里面）发现：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># Example:</span><br><span class="line">#   jdk.tls.disabledAlgorithms=MD5, SSLv3, DSA, RSA keySize &lt; 2048</span><br><span class="line">jdk.tls.disabledAlgorithms=SSLv3, TLSv1, TLSv1.1, RC4, DES, MD5withRSA, \</span><br><span class="line">    DH keySize &lt; 1024, EC keySize &lt; 224, 3DES_EDE_CBC, anon, NULL, \</span><br><span class="line">    include jdk.disabled.namedCurves</span><br></pre></td></tr></table></figure></p>
<p>方法一：</p>
<p>此处连接的MySQL，导致的报错，修改jdbcUrl，在其后面加useSSL=false后运行正常</p>
<p>方法二：</p>
<p>删除SSLv3, TLSv1, TLSv1.1并保存java.security文件，重启项目即可解决问题，删除后此处为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># Example:</span><br><span class="line">#   jdk.tls.disabledAlgorithms=MD5, SSLv3, DSA, RSA keySize &lt; 2048</span><br><span class="line">jdk.tls.disabledAlgorithms=RC4, DES, MD5withRSA, \</span><br><span class="line">    DH keySize &lt; 1024, EC keySize &lt; 224, 3DES_EDE_CBC, anon, NULL, \</span><br><span class="line">    include jdk.disabled.namedCurves</span><br></pre></td></tr></table></figure></p>
<p>方法三：</p>
<p>降低JDK版本，这个相当也容易操作，比如可以从1.8.0_292降到1.8.0_281，甚至是1.8.0_275版本，但个人不建议，因为Oracle对JDK 8的支持一直会到2030年：</p>
<p>image-20210602182131342.png</p>
<p>即使很长一段时间用JDK 8，但JDK 8本身也是有小版本迭代的，比如你明年换了电脑，安装JDK，基本是1.8.0_292之后的版本，那这个问题会一直存在</p>
<p>方法四：</p>
<p>方法一 能解决由SSL调用权限导致的所有问题，但破坏了安全性<br>方法二 针对MySQL的问题，可以快速解决<br>方法三 不推荐</p>
<p>因此，碰到类似问题，基本的思路是兼容JDK 8高版本甚至JDK高版本，比如代码层面的：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">private Socket overrideTlsProtocol(final Socket socket) &#123;</span><br><span class="line">    if (!(socket instanceof SSLSocket)) &#123;</span><br><span class="line">        throw new RuntimeException(&quot;Error, an instance of SSLSocket is expected&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    ((SSLSocket) socket).setEnabledProtocols(new String[]&#123;&quot;SSLv3&quot;&#125;);</span><br><span class="line">    return socket;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>修改为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">private Socket overrideTlsProtocol(final Socket socket) &#123;</span><br><span class="line">    if (!(socket instanceof SSLSocket)) &#123;</span><br><span class="line">        throw new RuntimeException(&quot;Error, an instance of SSLSocket is expected&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    ((SSLSocket) socket).setEnabledProtocols(new String[]&#123;&quot;SSLv3&quot;, &quot;TLSv1&quot;,&quot;TLSv1.1&quot;&#125;);</span><br><span class="line">    return socket;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>jdk8</category>
      </categories>
      <tags>
        <tag>jdk8</tag>
      </tags>
  </entry>
  <entry>
    <title>linux开放新端口</title>
    <url>/2017/12/18/linux%E5%BC%80%E6%94%BE%E6%96%B0%E7%AB%AF%E5%8F%A3/</url>
    <content><![CDATA[<p>1.到linux根目录<br> cd /</p>
<p>2.查找iptables的位置<br>find -name iptables</p>
<p>编辑器打开iptables文件即可查看已经开放的端口，并可以添加新的规则<br>方法1：直接编辑器加入新的规则保存: -A INPUT -p tcp -m tcp –dport 13389 -j ACCEPT<br>方法2：通过命令：<br>/sbin/iptables -I INPUT -p tcp –dport 13389 -j ACCEPT</p>
]]></content>
      <categories>
        <category>开放端口</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>port</tag>
      </tags>
  </entry>
  <entry>
    <title>linux配置调度任务</title>
    <url>/2015/06/20/linux%E8%B0%83%E5%BA%A6%E4%BB%BB%E5%8A%A1%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>1.linux crontab yum 安装<br>  1.1 检查是否安装crontab</p>
<pre><code># crontab
-bash: crontab: command not found
</code></pre><p>   执行crontab命令如果报 comman not found，表明没有安装。<br>  1.2 yum安装</p>
<pre><code># yum -y install vixie-cron
 Loaded plusgins:security
 ........
</code></pre><p>  1.3 安装完成后，可使用info crontab命令查看详细的帮助信息<br>  cron服务提供crontab命令来设定cron服务的，以下命令的一些参数说明：<br>    crontab -u //设定某个用户的cron服务，一般root用户在执行这个命令的时候<br>    需要此参数<br>    crontab -l //列出某个用户cron服务的详细内容<br>    crontab -r //删除每个用户的cron服务<br>    crontab -e //编辑某个用户的cron服务<br>  例如：root查看自己的cron设置：  crontab -u root -l<br>        root想删除fred的cron设置：crontab -u fred -r<br>    在编辑cron服务时，编辑的内容有一些格式和约定，输入：<br>    crontab -u root -e<br>   1.4 crontab 服务状态操作：<br>     /sbin/service crond start    //启动服务<br>     /sbin/service crond stop     //关闭服务<br>     /sbin/service crond restart  //重启服务<br>     /sbin/service crond reload   //重新载入配置<br>     /sbin/service crond status   //查看状态<br>    或者</p>
<pre><code># service crond start
# service crond stop
# service crond restart
# service crond reload
# service crond status 
</code></pre><p>   1.5 添加开机服务<br>     在/etc/rc.d/rc.local这个脚本的末尾加上：<br>      /sbin/service crond start</p>
<ol start="2">
<li>配置linux自动执行任务<br>crontab -e<br>10 1 <em> </em> * /data/pay/bin/project-job.sh(每天凌晨一点十分执行)</li>
</ol>
<p>3.在/data/pay/bin/配置执行脚本<br>project-job.sh<br>   source /etc/profile<br>     source ~/.bash_profile</p>
<pre><code>#sudo chown -R lemsuser.lemsuser /share/NSIT_LEMS/* &gt;/dev/null 2&gt;&amp;1
#sudo chmod -R 777 /share/NSIT_LEMS/* &gt;/dev/null 2&gt;&amp;1
java -jar /project/apps/project-job/project-job.jar &gt;/dev/null 2&gt;&amp;1
</code></pre><p>4.授权project-job.sh文件</p>
<p>  chmod 755 *</p>
<p>5.jar包位置：<br>    /project/apps/project-job/project-job.jar</p>
]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title>mybatis动态代理</title>
    <url>/2015/06/25/mybatis%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/</url>
    <content><![CDATA[<p>在使用Mybatis的时候，我们可以只定义一个XxxMaper接口，然后直接利用这个接口定义的抽象方法来进行增删改查操作，Mybatis内部实际上利用了动态代理技术帮我们生成了这个接口的代理类。<br>举例来说，假设有映射文件：<br><img src="/images/mybatis/20171019215820.jpg" alt="Alt text"></p>
<p>我们只要定义一个UserMapper接口，注意这个接口的路径就是映射文件的namespace属性值，然后在这个接口中定义几个方法，方法名分别于映射文件中定义的<insert>、<select>等元素的id属性值相同，如下：</select></insert></p>
<p><img src="/images/mybatis/20171019215821.jpg" alt="Alt text"></p>
<p>之后我们就可以直接使用UserMapper类来进行增删改查，使用方式如下：</p>
<p><img src="/images/mybatis/20171019215822.jpg" alt="Alt text"></p>
<p>之所以可以这样使用，是因为Mybatis对生成了UserMapper接口的动态代理类，当执行某个方法时，代理类内部会首选获取调用的方法的全路径，例如当我们调用UserMapper的insert方法时，其对应的全路径是com.tianshouzhi.mybatis.quickstart.UserMapper.insert。而这个值刚好对应着namespace属性值为com.tianshouzhi.mybatis.quickstart.UserMapper的mapper映射文件的id=”insert”的insert元素，从而执行相应的sql。真正在执行时，还是利用SqlSession的insert方法来执行的，只不过这个过程对于用于来说屏蔽了。<br>我们带着2个问题来进行源码分析：<br>1、动态代理类是如何生成的<br>2、动态代理类是如何对方法进行拦截的<br>一、动态代理类的生成时机<br>每次当我们调用sqlSession的getMapper方法时，都会创建一个新的动态代理类实例，如：</p>
<p><img src="/images/mybatis/20171019215823.jpg" alt="Alt text"></p>
<p>也就是说，生成的动态代理类不是唯一的，而是每次都创建一个新的。<br>而SqlSession对象又将getMapper方法委给了Configuration对象执行，如下所示：</p>
<p><img src="/images/mybatis/20171019215824.jpg" alt="Alt text"></p>
<p>Configuration类里面通过MapperRegistry对象维护了所有要生成动态代理类的XxxMapper接口信息。</p>
<p><img src="/images/mybatis/20171019215825.jpg" alt="Alt text"></p>
<p>其中，getMapper方法就是用于创建接口的动态类。而addMapper方法是mybatis在解析配置文件时，会将需要生成动态代理类的接口注册到其中。目前我们主要介绍的getMapper方法，addMapper方法我们将会在之后进行介绍。<br>可以看到Configuration类的addMapper和getMapper方法最终又都是委派给MapperRegistry的addMapper和getMapper方法执行的。<br>MapperRegistry类的getMapper方法源码如下所示：</p>
<p><img src="/images/mybatis/20171019215826.jpg" alt="Alt text"></p>
<p>可以看到，创建动态代理类的核心代码都位于MapperProxyFactory的newInstance方法中。目前对这个方法不做分析，放到后面分析生成的代理类是如何对接口的方法进行拦截一起说。目前只需要知道，每次调用SqlSession的getMapper方法，都会创建一个新的代理类即可。<br>现在我们考虑，Mybatis是如何知道要生成一个类的动态代理类的，这个过程是在mybatis解析xml配置文件的时候就确定了。<br>具体逻辑是，根据<mapper namespace="....">的namespace属性值，判断有没有这样一个接口的全路径与namespace属性值完全相同，如果有，就生成这个接口的动态代理类。<br>相关解析代码位于XMLMapperBuilder的 parse方法中：</mapper></p>
<p><img src="/images/mybatis/20171019215827.jpg" alt="Alt text"></p>
<p>bindMapperForNamespace方法源码如下所示：</p>
<p><img src="/images/mybatis/20171019215828.jpg" alt="Alt text"></p>
<p>在前面的代码中，我们已经看到，Configuration的addMapper方法是委派给MapperRegistry的addMapper进行的，源码如下所示：<br>org.apache.ibatis.binding.MapperRegistry#addMapper</p>
<p><img src="/images/mybatis/20171019215829.jpg" alt="Alt text"></p>
<p>二、动态代理类是如何对方法进行拦截的<br>通过前面的分析，我们知道当调用SqlSession的getMapper方法时，通过一层一层的委派，最终会通过MapperProxyFactory的newInstance(sqlSession)方法，来创建动态代理类，MapperProxyFactory类源码如下所示：</p>
<p><img src="/images/mybatis/a.jpg" alt="Alt text"></p>
<p>可以看到，MapperProxyFactory的newInstance(sqlSession)方法中，首先会创建一个MapperProxy对象，然后将其当做参数传递给newInstance(mapperProxy)方法，这个方法内部通过JDK提供的Proxy.newProxyInstance方法生成动态代理类。Proxy.newProxyInstance方法声明如下所示：<br>java.lang.reflect.Proxy#newProxyInstance</p>
<p><img src="/images/mybatis/b.jpg" alt="Alt text"></p>
<p>InvocationHandler接口定义如下所示：</p>
<p><img src="/images/mybatis/c.jpg" alt="Alt text"></p>
<p>当接口中的任何一个方法被调用时，JVM都会回调InvocationHandler接口实现类的invoke方法。并会传递三个回调参数：<br>Object proxy：被代理的类<br>Method method：表示当前被调用的接口的方法对象<br>Object[] args：表示接口方法被调用时，传递的参数。<br>MapperProxy类实现了InvocationHandler接口，因此我们只要从其实现的invoke方法入手进行分析</p>
<p><img src="/images/mybatis/d.jpg" alt="Alt text"></p>
<p>现在我们定义为到，最终的拦截代码位于MapperMethod类的execute方法中，当把这个方法的代码分析完成，本小节也就分析完成了。MapperMethod类源码如下所示：</p>
<p><img src="/images/mybatis/e.jpg" alt="Alt text"></p>
<p>在MapperMethod的构造方法中，例如参数构造了两个对象SqlCommand、MethodSignature，这两个类都是MapperMethod的内部类。<br>而execute方法中，会首选调用SqlCommand的getType方法，判断要执行的sql类型INSERT、UPDATE、DELETE、SELECT、FLUSH。然后分别调用SqlSession的insert、update、delete、selectOne、selectMap、selectList等方法来执行。<br>这说明，我们通过SqlSession的getMapper方法获得接口代理来进行CRUD操作，其底层还是依赖于最原始的SqlSession的使用方法。<br>关于SqlCommand，我们不做过多介绍，这里只提一点，SqlCommand.getType中是如何确定当前要执行的sql类型的。因为不同的Sql类型意味着我们要对sql操作的结果做不同的处理，例如：<br>对于insert、update和delete，这样的sql，其返回值是影响的结果集的行数，因此我们看到上述相关代码在执行的时候，都调用了一个rowCountResult方法。<br>对于select：要对查询的结果集ResultSet进行封装。由于SqlSession提供了众多方法对查询结果集进行处理，例如selectOne，selectMap、selectList等，因此根据接口中定义的方法的返回值的类型，来选择执行不同的方法，对ResultSet进行封装。<br>由于我们在SqlCommand对象构造的时候，将当前代理的接口和当执行被调用的方法method对象传递过去，其内部会通过以下方式查找对应的MappedStatement对象</p>
<p><img src="/images/mybatis/f.jpg" alt="Alt text"></p>
<p>MappedStatement是我们在定义mapper映射文件时，内部的<insert>、<update>、<delete>、<select>元素的解析结果，每个这样的元素都会被解析成一个MappedStatement对象，并保存到Configuration类中的mappedStatements 属性中。</select></delete></update></insert></p>
<p><img src="/images/mybatis/f.jpg" alt="Alt text"></p>
<p>其中key就是就是”namespace.id”，由于我们定义的映射文件中，namespace属性就是XxxMapper的全路径，而<insert>等元素的id属性就是方法名，因此可以通过这种方式找到对应的解析后的MappedStatement。<br>由于这些标签(<insert>、<update>…)本身就代表了自己的sql类型，这些信息也会被保存到MappedStatement对象中，因此我们就可以通过SqlCommand的getType方法获取当前要执行的sql类型。<br>当调用SqlSession的相关方法时，第一个参数都是传入的都是command.getName方法，这个方法返回值，也是”namespace.id”，不再做过多分析。</update></insert></insert></p>
]]></content>
      <categories>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM精简知识点(一)</title>
    <url>/2016/07/02/jvm%E7%B2%BE%E7%AE%80%E7%9F%A5%E8%AF%86%E7%82%B9(%E4%B8%80)/</url>
    <content><![CDATA[<p>  java的垃圾回收是不需要程序员进行手动控制的，而是由JVM去完成。以下是JVM进行垃圾回收的<br>  各种算法。</p>
<p>  1.如何确定某对象是垃圾</p>
<pre><code>* 引用计数算法：java中，引用和对象是有关联的。操作对象必须用引用进行，所以
通过引用计数来判断一个对象是否可回收。一个对象没有任何与之关联的引用，说明对象不
太可能再被用到，这个对象就是可回收对象。这种方式为引用计数法。但是这种方式无法解
决循环引用的问题，如：
   public static void main(String[] args) {
    Object obj1 = new Object();
    Object obj2 = new Object();
    obj1.object = obj2;
    obj2.object = obj1;
    obj1 = null;
    obj2 = null;
    } 

最后obj1和obj2的内存块都不能在被访问到了，但它们的引用计数不为0，这样会使它们永远不能被清楚。


* 可达分析算法
   为了解决引用计数法的循环引用问题，java使用的可达性分析方法。通过一系列的&quot;GC ROOT&quot; 对象作
   为起点搜索。如果在&quot;GC ROOTS&quot;和一个对象之间没有可达路径，则称该对象是不可达。注意：不可达对象
   不等价于可回收对象，不可达对象变为可回收对象至少要经过两次标记过程。两次标记后仍是可回收对象，
   则将面临回收。

比较常见的将对象视为可回收对象的原因：
  *  显示地将对象的唯一强引用指向新的对象。
  *  显示地将对象的唯一弱引用赋值为null。
  *  局部引用所指向的对象（如，方法内对象）。

以下代码，每次循环结束，object都会被视为可回收对象。
void function(){

for(int i=0;i&lt;10;i++){
    Object obj = new Object();
    System.out.println(ojb.getClass());
}
}

  * 只有弱引用于其关联的对象。

典型的垃圾回收算法

* 标记-清除算法（mark-sweep)
最基础的垃圾回收算法，分为两个阶段，标记和清楚。标记阶段标记出所有需要回收的对象，清除阶段
回收被标记的对象所占用的空间。
</code></pre><p> <img src="/images/jvm/mark-sweep.jpg" alt="Alt text"></p>
<pre><code>缺点： 内存碎片化严重，后续可能发生大对象不能找到可利用空间的问题。

* 复制算法(copying)
为了解决mark-sweep 算法内存碎片化的缺陷而被提出的算法。按内存容量将内存划分为等大小的两块。
每次只使用其中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用的内存清掉。




    * 标记-整理算法(mark-compact)
  综合标记删除、复制算法，为了避免缺陷而得出。标记阶段和mark-sweep算法相同，标记后不是清理
  对象。而是将存活对象移向内存的一端。然后清除端边界外的对象。
</code></pre><p> <img src="/images/jvm/mark-compact.jpg" alt="Alt text"></p>
<pre><code>    * 分代收集算法
  目前大部分JVM采用的方法，核心思想是根据对象存活的不同生命周期将内存划分为不同的域，一般情况
下将GC堆划分为老年代(Tenured/Old GEneration)和新生代(Young Generation).老年代的特点是每次垃圾回收
时只有少量对象需要被回收，新生代的特点每次垃圾回收时都有大量垃圾需要被回收,因此可根据不同区域选择
不同的算法。
   目前大部分JVM的GC对于新生代都采用copying算法，因为新生代中每次垃圾回收都需要回收大部分对
象，即复制的操作比较少，但通常不是按照1:1来划分新生代。一般将新生代划分为一块较大的Eden空间
和两块较小的Survivor空间(From Space,To Space),每次使用Eden空间和其中一块Survivor空间，当进行
垃圾回收时，将该两块空间中还存活的对象复制到另一块survivor空间中。
</code></pre><p> <img src="/images/jvm/young-generation.jpg" alt="Alt text">    </p>
<pre><code>而老年代因为每次只回收少量对象，因而采用mark-compact 标记整理算法。

处于方法区的永久代(Permanet Generation)。它用来存储class类，常量，方法等。对于永久代的回收主要包括
废弃常量和无用的类。

对象的内存分配主要在新生代的Eden Space 和Survivor Space的From Space(Survivor目前存放
对象那一块)，
</code></pre><p>少数情况直接分配到老年代。当新生代的Eden Space和From Space空间不足时就会发生一次GC,进行GC后,Eden Space<br>和From Space区存活对象会被挪到To Space,然后将Eden Space和From Space进行清理。如果To Space无法足够存储某个<br>对象，则将这个对象存储到老年代。在进行GC后，使用的便是Eden Space和To Space了，如此反复循环。当对象在<br>Survivor区躲过一次GC后，其年龄就会+1。默认情况下年龄达到15的对象会被移到老年代中。</p>
<p>  垃圾收集算法是垃圾收集器的理论基础，而垃圾收集器就是其具体实现。下面介绍HotSpot虚拟机提供的几种垃圾收集器。<br>3.1. Serial/Serial Old<br>最古老的一个单线程收集器，进行垃圾回收时，必须暂停所有用户线程。Serial是针对新生代的收集器，采用Copying-复制算法；而Serial Old是针对老生代的收集器，采用Mark-Compact-标记整理算法。优点是简单高效，缺点是需要暂停用户线程。<br>3.2. ParNew<br>Seral/Serial Old的多线程版本，使用多个线程进行垃圾收集。<br>3.3. Parallel Scavenge<br>新生代的并行收集器，回收期间不需要暂停其他线程，采用Copying-复制算法。该收集器与前两个收集器不同，主要为了达到一个可控的吞吐量。<br>3.4. Parallel Old<br>Parallel Scavenge的老生代版本，采用Mark-Compact算法和多线程。<br>3.5. CMS<br>Current Mark Sweep收集器是一种以最小回收时间停顿为目标的并发回收器，因而采用Mark-Sweep算法。<br>3.6. G1<br>G1(Garbage First)收集器技术的前沿成果，是面向服务端的收集器，能充分利用CPU和多核环境。是一款并行与并发收集器，它能够建立可预测的停顿时间模型。</p>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>索引添加的几种方式</title>
    <url>/2014/03/15/mysql%E6%B7%BB%E5%8A%A0%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<p><strong>索引</strong></p>
<ul>
<li>是一种特殊的文件：它们包含着对数据表里所有记录的引用指针（InnoDB数据表上的索引是表空间的一个组成部分）。</li>
<li>是一种数据结构：数据库索引是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中的数据。索引的实现通常使用B树及B+树。</li>
<li>相当于一个目录：查找书中内容，通常为了方便对内容建立索引形成目录。索引是一个文件，会占据物理空间。</li>
</ul>
<p><strong>索引有哪些优缺点：</strong></p>
<ul>
<li><p>索引的优点</p>
<ul>
<li>加快数据检索速度，是创建索引原因。</li>
<li>使用索引可在查询过程中优化隐藏器，提高系统性能。</li>
</ul>
</li>
<li><p>索引的缺点</p>
<ul>
<li>时间方面：创建和维护索引要消耗时间，具体地当对表中的数据进行增删改时，索引也需动态维护，会降低增删改的执行效率。</li>
<li>空间方面：索引需占物理内存。</li>
</ul>
</li>
</ul>
<p><strong>索引的几种类型</strong></p>
<ul>
<li><p>主键索引(Primary Key)<br>定义：数据列不可重复，不能为null,一个表中只有一个主键</p>
</li>
<li><p>唯一索引(Unique) 定义：数据列不能重复，允许为null，一个表允许多个列创建唯一索引</p>
<ul>
<li>创建唯一索引：可通过ALTER TABLE table_name ADD UNIQUE (column);</li>
<li>创建唯一组合索引：ALTER TABLE table_name ADD UNIQUE(column1,column2);</li>
<li>建表后添加：CREATE UNIQUE INDEX <code>UK_uname</code> ON userinfo(<code>uname</code>)</li>
</ul>
</li>
<li><p>普通索引(index)：基本的索引类型，么有唯一性限制，允许为null</p>
<ul>
<li>创建普通索引：ALTER TABLE table_name ADD INDEX index_name(column);</li>
<li>创建组合索引：ALTER TABLE table_name ADD INDEX index_name(column1,column2);</li>
</ul>
</li>
<li><p>组合索引(index):创建一个（多个字段的索引），这个概念相对于上面的的单列索引而言，组合索引遵循最左侧前缀原则。</p>
</li>
<li><p>全文索引： 目前搜索引擎使用的一种关键技术。</p>
<ul>
<li>创建：ALTER TABLE table_name ADD FULLTEXT(column);</li>
</ul>
</li>
<li><p>聚簇索引和非聚簇索引：概念上要比上面的大，属于包含和被包含关系。如：InnoDB中主键索引使用的就是聚簇索引。</p>
</li>
</ul>
<p><strong>创建索引的三种方式，删除索引</strong></p>
<ul>
<li><p>第一种方式：再执行create table 时创建索引</p>
<p>  CREATE TABLE user_index2 (<br>  id INT auto_increment PRIMARY KEY,<br>  first_name VARCHAR (16),<br>  last_name VARCHAR (16),<br>  id_card VARCHAR (18),<br>  information text,<br>  KEY name (first_name, last_name),<br>  FULLTEXT KEY (information),<br>  UNIQUE KEY (id_card)<br>  );</p>
</li>
</ul>
<ul>
<li><p>第二种方式：使用ALTER TABLE 命令去添加索引</p>
<ul>
<li>ALTER TABLE用来创建普通索引、UNIQUE索引或PRIMARY KEY索引。</li>
<li>table_name 是要添加索引的表名,</li>
<li>column_list指出对哪些列进行索引，多列时各列之间用逗号分割。</li>
<li><p>索引名index_name可自命名，缺省时，MYSQL根据第一个索引列赋一个名称。另外，ALTER TABLE允许在单个语句中更改多个表，因此可在同事创建多个索引。</p>
<pre><code>ALTER TABLE table_name ADD INDEX index_name(column_list);
</code></pre></li>
</ul>
</li>
</ul>
<ul>
<li>第三种方式：使用create index创建</li>
</ul>
<p>create index index_name on table_name (column_list);</p>
<p>create index 可对表添加普通索引或UNIQUE索引。（但不能创建PRIMARY KEY索引）</p>
<ul>
<li>删除索引</li>
</ul>
<p>根据索引名删除普通索引、唯一索引、全文索引；alter table 表名 drop KEY 索引名</p>
<pre><code>alter table user_index drop KEY name;

alter table user_index drop KEY id_card;

alter table user_index drop KEY information;
</code></pre><p><strong>删除主键索引</strong>：alter table 表名 drop primary key （因为主键只有一个）。注意：如主键自增长，不可直接执行此操作（自增长依赖主键索引）</p>
<pre><code>alter table user_index drop primary key;

[SQL] alter table user_index drop primary key
[ERR] 1075 - Incorrect table definition;there can be only one auto column and it must be ....
</code></pre><p><strong>需要取消自增长再进行删除：</strong></p>
<pre><code>alert table user_index
--重新定义字段
MODIFY id int,
drop PRIMARY KEY
</code></pre><blockquote>
<p>一般不会删除主键，设计主键一定与业务逻辑无关。</p>
</blockquote>
<p><strong>组合(复合)索引的最左侧优先原则</strong></p>
<blockquote>
<p>最左侧优先，在检索数据时从联合索引的最左边开始匹配，组合索引的第一个字段必须出现在查询组句中，这个索引才会被用到。</p>
<p>对于列col1、col2、col3建立联合索引</p>
<p>key test_col1_col2_col3 on test(col1,col2,col3);</p>
<p>联合索引test_col1_col2_col3 可以看成建立了（col1)、（col1,col2)、（col1,col2,col3)三个索引。实则是建立个一个B+树索引。</p>
<p>根据最左侧披索原则，where语句必须要有col1才能调用索引（如果没有col1字段那么一个索引也不调用），如果where 语句后同时出现col1、col2，则会调用两者的组合索引，如果where语句后同时出现col1、col2、col3作为条件，则调用三者的组合索引。</p>
</blockquote>
]]></content>
      <categories>
        <category>索引</category>
      </categories>
      <tags>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title>redis内存管理及数据淘汰机制</title>
    <url>/2017/03/18/redis%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>  最大内存设置<br>     默认情况下，32为OS中，redis最大使用3G的内存，在64为OS中则没有限制。</p>
<pre><code> 在使用redis时，应该对数据占用的最大空间有一个基本准确的预估，并为redis设定最大使用的内存。
 否则在64位OS中reids会无限制的占用内存（物理内存被占满后会使用swap空间），容易引起各种各样
 的问题。

 通过如下配置控制redis使用的最大内存：
 maxmemory 100mb

 在内存占用达到了maxmemory后，再向redis写入数据时，redis会：

* 根据配置的数据淘汰策略尝试淘汰数据，释放空间。
* 如果没有数据可以淘汰，或者没有配置数据淘汰策略，那么redis会对所有写请求返回错误，但读
  请求仍然可以正常执行。

 在为redis设置maxmemory时，需要注意：

* 如果采用了redis的主从同步，主节点向从节点同步数据时，会占用掉一部分内存空间，如果
maxmemory过于接近主机的可用内存，导致数据同步时内存不足。所以设置的maxmemory不要过于接近
主机可用的内存，留出一部分预留用作主从同步。
</code></pre><p>  数据淘汰机制</p>
<pre><code>  redis提供了5中数据淘汰策略：

*  volatile-lru: 使用LRU算法进行数据淘汰（淘汰上次使用时间最早且使用次数最少的key)，
   只淘汰设定了有效期的key。

*  allkeys-lru: 使用LRU算法进行数据淘汰，所有的key都可以被淘汰。

*  volatile-random: 随机淘汰数据，只淘汰设定了有效期的key.

*  allkeys-random:  随机淘汰数据，所有的key都可以被淘汰。

*  volatile-ttl： 淘汰剩余有效期最短的key。
</code></pre><p>   为redis制定一种有效的数据淘汰策略以配合maxmemory设置，避免在内存使用满后发生写入失败的情况。</p>
<pre><code>一般情况推荐使用的策略是 volatile-lru，并辨识redis中保存的数据的重要性。对于那些重要的，
</code></pre><p>   绝对不能丢弃的，数据（如配置类数据等），应该不设置有效期，这样redis就永远不会淘汰这些数据。<br>   对于那些相对不是那么重要的，并且能够热加载的数据（比如缓存最近登录的用户信息，当redis中找不<br>   到时，程序会从DB中获取），可以设置有效期，这样在内存不够时reids就会淘汰这部分数据。</p>
<pre><code>配置方法：
  maxmemory-policy volatile-lru #默认是 noeviction,即不进行数据淘汰。
</code></pre>]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>java中Orderd接口</title>
    <url>/2018/04/17/ordered%E6%8E%A5%E5%8F%A3%E5%92%8Corder%E6%B3%A8%E8%A7%A3/</url>
    <content><![CDATA[<p><strong>ordered接口和order注解</strong></p>
<blockquote>
<p>ordered接口和@order注解都可控制类的处理顺序，遵循数字越小，优先加载。</p>
</blockquote>
<p><strong>场景：</strong></p>
<ul>
<li><p>过滤器filter中可以使用@order注解控制filter的拦截顺序</p>
</li>
<li><p>Spring中采用实现Ordered接口来控制拦截顺序。Spring中提供了AnnotationAwareOrderComparator类，只要实现接口ordered或用@order注解都可完成对类的排序。</p>
</li>
</ul>
<p>例：</p>
<pre><code>public abstract class ReadService {

     public abstract void read();

}


public class WriteJavaServiceImpl extends WriteService implements Ordered {

        @Override
        public void write() {
            System.err.println(&quot;6.写java&quot;);
        }

        @Override
        public int getOrder() {

            return 6;
        }
}

@Order(2)
public class WritePythonServiceImpl extends WriteService {

    @Override
    public void write() {
        System.err.println(&quot;2.写Python&quot;);
    }
}

@RunWith(SpringRunner.class)
@SpringBootTest
public class OrderTest {

    @Test
    public void orderTest() {
        List&lt;WriteService&gt; list = new ArrayList&lt;&gt;();
        list.add(new WriteJavaServiceImpl());
        list.add(new WritePythonServiceImpl());
        //对list进行排序
        AnnotationAwareOrderComparator.sort(list);
        list.forEach(WriteService::write);
    }
}
</code></pre>]]></content>
      <categories>
        <category>orderd</category>
      </categories>
      <tags>
        <tag>orderd</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Cloud简略概述（一）</title>
    <url>/2018/12/08/microservice/</url>
    <content><![CDATA[<p>Spring Cloud的服务发现框架-Eureka</p>
<p><strong>服务发现：</strong>相当于中介，整个过程中三个角色：服务提供者（出租房屋）、服务消耗者（租客）、服务中介（房屋中介）</p>
<p><strong>服务提供者(eureka client)：</strong> 提供一些自己能够执行的一些服务给外界。</p>
<p><strong>服务消费者(eureka client)：</strong> 使用服务的用户</p>
<p><strong>服务中介(eureka server)：</strong><br>服务提供者和消费者之间的桥梁，服务提供者可以把自己注册到注册中心，消费者可在注册中心找注册的服务提供者。</p>
<p><strong>服务注册Register：</strong></p>
<p>当Eureka客户端向Eureka Server注册时，它提供自身的元数据，如IP地址、端口、运行状态指示符URL,主页等。<br>例如：<br>房东（提供者Eureka Provider)在中介（服务器Eureka Server)登记房屋的信息，比如面积、价格、地段等（元数据DataMeta)。</p>
<p><strong>服务续约（Renew)</strong></p>
<p>Eureka client 会每隔30秒（默认情况下)发送一次心跳来续约。通过续约来告知注册中心（Eureka Server）该Eureka Client还存在，没有挂掉。正常情况下，如果注册中心(Eureka Server)在90秒没收到Eureka Client的续约，他将会实例从其注册表中删除。</p>
<p>（房东（eureka provider)定期告诉中介（eureka server)我的房子还租（续约），中介（服务器eureka server)收到之后继续保留房屋的信息。</p>
<p><strong>获取注册列表信息Fetch Registries:</strong></p>
<ul>
<li><p>Eureka客户端从注册中心(Eureka Server)获取注册表信息，并将其缓存在本地。</p>
</li>
<li><p>客户端会使用该信息查找其他服务，从而进行远程调用。</p>
</li>
<li><p>该注册列表信息定期（30s）更新一次。每次返回注册列表信息可能与Eureka client的缓存信息不通，Eureka client 自动处理。</p>
</li>
<li><p>如果由于某种原因导致注册列表信息不能及时匹配。Eureka客户端会重新获取整个注册表信息。</p>
</li>
<li><p>Eureka服务器缓存注册列表信息，整个注册表以及每个应用程序的信息进行了压缩，压缩内容和没压缩的内容完全相同。</p>
</li>
<li><p>Eureka客户端和Eureka服务器可以使用JSON/XML格式进行通讯。默认情况下Eureka客户端使用压缩JSON格式来获取注册列表的信息。</p>
</li>
</ul>
<p><strong>服务下线Cancel:</strong></p>
<p>Eureka客户端在程序关闭时向Eureka服务器发送取消请求。发送请求后，该客户端实例信息将从服务器的实例注册表中删除。该下线请求不会自动完成，它需要调用以下内容：DiscoveryManager.getInstance().shutdownComponent();</p>
<p><strong>服务剔除Eviction:</strong></p>
<p>eureka客户端连续90s(3个续约周期）没有向eureka服务器发送服务续约（心跳），eureka服务器会将该服务器实例从注册中心服务剔除。</p>
<p><strong>Eureka高可用</strong></p>
<p>eureka具有高可用，任时服务消费者都能正常获取服务列表，但不保证数据强一致性，消费者可能拿到过期的服务列表。保留可用及过期数据总比丢掉可用性好。</p>
<p><strong>eureka数据同步方式</strong><br> 分布式系统的数据在多节点之间的数据同步方式有两种：</p>
<ul>
<li>主从复制</li>
</ul>
<ul>
<li>对等复制</li>
</ul>
<p><strong>负载均衡Ribbon</strong></p>
<p>RestTemplate是什么</p>
<p>RestTemplate是Spring提供的一个访问Http服务的客户端类，微服务之间调用使用的RestTemplate。<br>消费者B调用提供者A所提供的服务，代码如下</p>
<pre><code>@Autowired
private RestTemplate restTemplate;
// 这里是提供者A的ip地址，但是如果使用了 Eureka 那么就应该是提供者A的名称
private static final String SERVICE_PROVIDER_A = &quot;http://localhost:8081&quot;;

@PostMapping(&quot;/judge&quot;)
public boolean judge(@RequestBody Request request) {
String url = SERVICE_PROVIDER_A + &quot;/service1&quot;;
return restTemplate.postForObject(url, request, Boolean.class);
}
</code></pre><p>Eureka框架中的注册、续约等，底层都使用的RestTemplate。</p>
<p><strong>使用Ribbon</strong></p>
<blockquote>
<p>Ribbon是Netflix公司开源负载均衡项目，是一个客户端、进程内负载均衡器，运行在消费端。</p>
</blockquote>
<p>一个秒杀系统，为了系统高可用，将系统做成集群，消费者就可有多个秒杀系统调用途径。</p>
<p><img src="/images/microservice/0001.png" alt="Alt text"></p>
<p>这时无均衡操作，对秒杀系统1大量调用，另两个基本不请求，将导致秒杀系统1崩溃，另两个无用，集群无意义。</p>
<p>此时Ribbon出现，它是<strong>运行在消费者端的负载均衡器</strong>。</p>
<p><img src="/images/microservice/0002.png" alt="Alt text"></p>
<blockquote>
<p>其实就是Consumer端获取到了所有的服务列表后，在其内部使用的负载均衡算法对多个系统调用。</p>
</blockquote>
<p>Nginx/Ribbon对比</p>
<p>Nginx<br>  一种集中式的负载均衡器，将所有请求集中起来，然后进行负载均衡</p>
<p><img src="/images/microservice/0003.png" alt="Alt text"></p>
<blockquote>
<p>nginx接收了所有的请求进行负载均衡，Ribbon在消费端进行负载均衡</p>
</blockquote>
<p><img src="/images/microservice/0004.png" alt="Alt text"></p>
<blockquote>
<p>关注Request的位置，在Nginx中请求是先进入负载均衡器，而Ribbon中是现在客户端进行负载均衡才进行请求的。</p>
</blockquote>
<p><strong>Ribbon的几种负载均衡算法</strong></p>
<blockquote>
<p>nginx使用的是轮询和加权轮询算法。</p>
</blockquote>
<p><strong>Ribbon使用的是负载均衡调度算法。</strong>（默认RoundRobinRule 轮询策略。）</p>
<ul>
<li><p>RoundRobinRule:轮询策略。Ribbon默认采用的策略。经过一轮轮询没找到可用的provider，最多轮询10轮。若最终没找到，则返回null</p>
</li>
<li><p>RandomRule:随机策略，从所有可用的provider中随机选择一个</p>
</li>
<li><p>RetryRule：重试策略。先RoundRobinRule/轮询策略获取provider服务提供方，获取失败则在指定时限内重试。默认时限500ms。</p>
</li>
</ul>
<blockquote>
<p>默认是轮询算法，且可能换默认负载均衡算法，配置文件中</p>
</blockquote>
<pre><code>providerName:
    ribbon:
        NFLoadBalanceRuleClassName: com.netflix.loadbalance.RandomRule
</code></pre><blockquote>
<p>也可自定义负载均衡算法，需时限IRule接口，然后修改配置文件或自定义Java Config类。</p>
</blockquote>
<p><strong>Open Feign</strong></p>
<p>每次调用RestTemplate的Api太麻烦，能否像调用原来代码一样进行各个服务间的调用，可使用映射，类似域名与IP的映射。可将调用的服务代码映射到消费端。</p>
<blockquote>
<p>OpenFeign 也是运行在消费端的，使用Ribbon进行负载均衡，所以OpenFeign内置了Ribbon。</p>
</blockquote>
<p>导入OpenFeign可更方便书写客户端代码</p>
<pre><code>// 使用 @FeignClient 注解来指定提供者的名字
@FeignClient(value = &quot;eureka-client-provider&quot;)
public interface TestClient {
        // 这里一定要注意需要使用的是提供者那端的请求相对路径，这里就相当于映射了
     @RequestMapping(value = &quot;/provider/xxx&quot;,method = RequestMethod.POST)
     CommonResponse&lt;List&lt;Plan&gt;&gt; getPlans(@RequestBody planGetRequest request);
}
</code></pre><p>可以在Controller中像调用Service层一样调用它</p>
<pre><code>@RestController
public class TestController {
     // 这里就相当于原来自动注入的 Service
     @Autowired
     private TestClient testClient;
     // controller 调用 service 层代码
     @RequestMapping(value = &quot;/test&quot;, method = RequestMethod.POST)
     public CommonResponse&lt;List&lt;Plan&gt;&gt; get(@RequestBody planGetRequest request) {
         return testClient.getPlans(request);
  }
}
</code></pre><p><strong>Hystrix熔断与降级</strong></p>
<p>Hystrix是一个熔断、降级的库，可提高这个系统弹性。</p>
<p>例如：服务A调用了服务B，服务B调用了服务C，但是某些原因，服务C顶不住乐，这时大量请求会在服务C端积压阻塞。</p>
<p><img src="/images/microservice/0005.png" alt="Alt text"></p>
<p>此时服务C不能返回响应，那么服务B调用服务C的请求就会阻塞，同理服务B阻塞了，服务A也会阻塞崩溃。</p>
<p>因为这些请求会消耗占用系统的线程、IO等资源，消耗完你这个系统服务器就挂了。这也叫服务雪崩。</p>
<p><img src="/images/microservice/0006.png" alt="Alt text">  </p>
<blockquote>
<p>熔断是服务雪崩的一种有效解决方案。指定时间内的请求失败率达到了设定阀值，系统将通过熔断器直接将此请求链路断开。</p>
</blockquote>
<blockquote>
<p>如服务B调用服务C在指定时间窗内，调用的失败率达到了一定值，那Hystrix则会自动将服务B和服务C之间的请求断开，疫苗导致服务雪崩现象。</p>
</blockquote>
<p>这里的熔断指Hystrix中的熔断模式，可用@[Hystrix]Command注解来标注某个方法，这样Hystrix就会使用断路器来包装这个方法。每当调用时间超过指定时间时（1000ms),断路器将会中断对这个方法的调用。</p>
<pre><code>@HystrixCommand(
commandProperties = {@HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;,value = &quot;1200&quot;)})
public List&lt;Xxx&gt; getXxxx() {
// ...省略代码逻辑
}
</code></pre><p>降级是为了更好的用户体验，当一个方法调用发生异常，通过执行另一种代码逻辑来给用户友好回复。这也是Hystrix的后被处理模式。可通过设置fallbackMethod来给一个方法设置备用的代码逻辑。</p>
<pre><code>// 指定了后备方法调用
@HystrixCommand(fallbackMethod = &quot;getHystrixNews&quot;)
@GetMapping(&quot;/get/news&quot;)
public News getNews(@PathVariable(&quot;id&quot;) int id) {
  // 调用新闻系统的获取新闻api 代码逻辑省略
}
//
public News getHystrixNews(@PathVariable(&quot;id&quot;) int id) {
  // 做服务降级
  // 返回当前人数太多，请稍后查看
}
</code></pre>]]></content>
      <categories>
        <category>微服务</category>
      </categories>
      <tags>
        <tag>微服务</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>spring-boot中关于jpa异常问题</title>
    <url>/2020/11/24/spring-boot%E4%B8%AD%E5%BC%82%E5%B8%B8%E6%83%85%E5%86%B5%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<p><strong>spring-boot异常问题记录</strong></p>
<p>Bug in org.springframework.boot on 2.2.3.RELEASE version</p>
<p>当我们使用spring-boot 的版本为2.2.3.RELEASE时，持久层ORM使用JPA时，会出现异常问题。</p>
<pre><code>org.springframework.transaction.CannotCreateTransactionException: Could not open JPA EntityManager for transaction; nested exception is java.lang.NoSuchMethodError: org.springframework.orm.jpa.JpaTransactionManager$JpaTransactionObject.setReadOnly(Z)V
    at org.springframework.orm.jpa.JpaTransactionManager.doBegin(JpaTransactionManager.java:448)
    at org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:376)
Caused by: java.lang.NoSuchMethodError: org.springframework.orm.jpa.JpaTransactionManager$JpaTransactionObject.setReadOnly(Z)V
</code></pre><p>解决方式：<br>将spring-jdbc改为5.2.6.RELEASE,spring-orm改为5.2.6RELEASE</p>
<pre><code>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;
    &lt;version&gt;5.2.6.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework&lt;/groupId&gt;
    &lt;artifactId&gt;spring-orm&lt;/artifactId&gt;
    &lt;version&gt;5.2.6.RELEASE&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>]]></content>
      <categories>
        <category>jpa</category>
      </categories>
      <tags>
        <tag>spring-boot</tag>
        <tag>jpa</tag>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title>window中将redis注册为本地服务</title>
    <url>/2016/08/06/window%E4%B8%AD%E5%B0%86redis%E6%B3%A8%E5%86%8C%E4%B8%BA%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<p><strong>在window中将redis注册为本地服务</strong></p>
<p>一般可以通过 redis-server.exe 和配置文件启动redis服务 :</p>
<p>redis-server.exe  redis.windows.conf </p>
<p>另外开启一个命令行窗口 redis-cli.exe 即可做一些简单的操作命令行</p>
<p>但我们关闭控制台，Redis服务也跟随着一起关闭了，想使用的时候又得执行命令重新开启动redis 服务，是非常低效又麻烦的。</p>
<p>在Windows中有个本地服务的概念，我们的目标就是将Redis注册成这里面的一个服务，然后就可以不受控制台退出的影响了。</p>
<p><strong>注册为本地服务</strong></p>
<p>redis-server.exe –service-install redis.windows.conf </p>
<p><img src="/images/window_install_redis_001/00001.png" alt="图1"></p>
<p>从图中看到已成功授权并且注册成功，接下来，我们到windows服务中去看一下是否有redis服务：</p>
<p><img src="/images/window_install_redis_001/00002.png" alt="图2"></p>
<p>查看已在</p>
<p><strong>开启Redis服务</strong></p>
<ul>
<li>方法一：选中Redis项右击-》启动</li>
</ul>
<p><img src="/images/window_install_redis_001/00003.png" alt="图3"></p>
<ul>
<li>方法二：redis-server –service-start</li>
</ul>
<p><img src="/images/window_install_redis_001/00004.png" alt="图4"></p>
<p><strong>常用命令：</strong></p>
<ul>
<li><p>注册服务   redis-server –service-install redis.windows.conf</p>
</li>
<li><p>删除服务   redis-server –service-uninstall</p>
</li>
<li><p>开启服务   redis-server –service-start</p>
</li>
<li><p>停止服务   redis-server –service-stop</p>
</li>
</ul>
<p><strong>创建多个Redis实例</strong></p>
<ul>
<li>1.复制一份redis.windows.conf 配置文件，改名为 redis.windows10001.conf</li>
</ul>
<p><img src="/images/window_install_redis_001/00005.png" alt="图5"></p>
<ul>
<li>2.更改 redis.windows10001.conf 配置文件的信息 端口号 port 为 10001</li>
</ul>
<ul>
<li>3.注册为window服务</li>
</ul>
<p>redis-server.exe –service-install redis.windows10001.conf –service-name redis10001 –port 10001</p>
<p><img src="/images/window_install_redis_001/00006.png" alt="图6"></p>
<p>从windows服务中可以看到，有两个redis服务，刚才注册的是redis10001，服务还未开启，如下图所示：</p>
<p><img src="/images/window_install_redis_001/00007.png" alt="图7"></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>window</tag>
      </tags>
  </entry>
  <entry>
    <title>redis持久化机制</title>
    <url>/2018/08/25/redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p><strong>redis持久化机制</strong></p>
<p>概述：将内存中的数据写到磁盘中(同步或异步)，并永久性保存。支持RDB、AOF。</p>
<p><strong>RDB持久化</strong></p>
<p>定义：将当前进程中数据生成快照保存到硬盘（快照持久化)，保存的文件后缀是RDB;当redis重新启动时，能读取快照文件恢复数据。触发RDB持久化过程分为手动触发、自动触发。</p>
<p><strong>触发机制</strong></p>
<ul>
<li><p>手动触发：save/bgsave命令</p>
<ul>
<li><p>save命令：阻塞当前redis服务器，直到RDB持久化完成，对内存较大实例会长时间阻塞(线上一般不适用）</p>
<pre><code>127.0.0.1:6379
save
OK
(1.31s)
</code></pre></li>
<li><p>bgsave命令：会创建一个子进程，子进程负责创建RDB文件，父进程（redis主进程)继续处理请求。</p>
<pre><code>127.0.0.1:6379&gt; bgsave
Background saving started
</code></pre></li>
</ul>
</li>
</ul>
<pre><code>bgsave命令是针对save阻塞问题做的优化。redis内部所有涉及RDB的操作都采用bgsave方式，save命令已废弃。
</code></pre><ul>
<li>自动触发：save m n </li>
</ul>
<p><strong>执行流程</strong></p>
<ol>
<li><p>redis主进程首先判断：当前是否在执行save，或bgsave、bgwriteAOF的子进程，如果在执行则bgsave命令直接就返回。</p>
</li>
<li><p>父进程执行fork操作创建子进程，这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令。</p>
</li>
<li><p>父进程fork后，bgsave命令返回Background saving started 信息并不在阻塞父进程，并可以响应其他命令。</p>
</li>
<li><p>子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换。</p>
</li>
<li><p>子进程发送消息给父进程标识完成，父进程更新统计信息。</p>
</li>
</ol>
<p><strong>常用配置：</strong></p>
<ul>
<li><p>save m n :bgsave自动触发的条件；如果没有save m n 配置，相当于自动的RDB持久化关闭，不过此时仍可以通过其他方式触发。</p>
</li>
<li><p>stop-write-on-bgsave-error yes:当bgsave出现错误时，redis是否停止执行写命令；设置为yes，则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；设置为no,则redis无视bgsave的错误继续执行写命令，当Redis服务器的系统（硬盘..）使用了监控时，该选项考虑设置为no</p>
</li>
<li><p>rdbcompression yes: 是否开启RDB文件压缩。</p>
</li>
<li><p>rdbchecksum yes：是否开启RDB文件的校验，在写入文件和读取文件时都起作用；关闭checksum在写入文件和启动文件时大约能带来10%的性能提升，但是数据损坏时无法发现。</p>
</li>
<li><p>dbfilename dump.rdb： RDB文件名称</p>
</li>
<li><p>dir./: RDB文件和AOF文件所在目录</p>
</li>
</ul>
<p><strong>AOF持久化</strong></p>
<p>定义：将redis的每次执行的命令记录写到日志文件中(似mysql中binlog），当redis重启时再次执行AOF文件中的命令进行恢复</p>
<p><strong>触发机制</strong>：修改配置appendonly 为yes</p>
<p><strong>执行流程</strong></p>
<ol>
<li><p>所有的写入命令会追加到aof_buf（缓冲区）中。</p>
</li>
<li><p>AOF缓冲区根据对应的策略向硬盘做同步操作。</p>
</li>
<li><p>随着AOF文件越来越大，需定期对AOF文件进行重写，进行压缩的目的</p>
</li>
<li><p>redis服务器重启时，可以加载AOF文件进行数据恢复。</p>
</li>
</ol>
<p><strong>持久化策略对比</strong></p>
<ul>
<li><p>RDB优缺点</p>
<p>   优点：RDB文件紧凑，体积小，网络传输快，适合全量复制。</p>
<p>   缺点：持久化实时性不高，数据会存在丢失情况。</p>
</li>
<li><p>AOF优缺点：</p>
<p>  优点：支持秒级持久化、兼容性好</p>
<p>  缺点：文件大、恢复速度慢，对性能影响大。</p>
</li>
</ul>
<p><strong>常见问题和优化方案</strong></p>
<ul>
<li><p>fork操作阻塞</p>
</li>
<li><p>cpu消耗阻塞</p>
</li>
<li><p>硬盘消耗阻塞</p>
</li>
</ul>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>reids</tag>
        <tag>rdb</tag>
        <tag>aof</tag>
      </tags>
  </entry>
  <entry>
    <title>synchronized关键字的介绍</title>
    <url>/2018/10/05/synchronized%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<p>synchronized关键字的介绍</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java提供了内置锁来支持多线程的同步，JVM根据synchronized关键字来标识同步代码块，当线程进入同步代码块时会自动获取锁，退出同步代码块时会自动释放锁，一个线程获得锁后其他线程将会被阻塞。<br></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;每个Java对象都可以用做一个实现同步的锁，synchronized关键字可以用来修饰对象方法，静态方法和代码块，当修饰对象方法和静态方法时锁分别是方法所在的对象和Class对象，<br>当修饰代码块时需提供额外的对象作为锁。每个Java对象之所以可以作为锁，是因为在对象头中关联了一个monitor对象(管程)，线程进入同步代码块时会自动持有monitor对象，退出时会自动释放monitor对象，当monitor对象被持有时其他线程将会被阻塞。当然这些同步操作都由JVM底层帮你实现了，但以synchronized关键字修饰的方法和代码块在底层实现上还是有些区别的。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;synchronized关键字修饰的方法是隐式同步的，即无需通过字节码指令来控制的，JVM可以根据方法表中的ACC_SYNCHRONIZED访问标志来区分一个方法是否是同步方法；而synchronized关键字修饰的代码块是显式同步的，它是通过monitorenter和monitorexit字节码指令来控制线程对管程的持有和释放。<br></p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;monitor对象内部持有_count字段，_count等于0表示管程未被持有，_count大于0表示管程已被持有，每次持有线程重入时_count都会加1，每次持有线程退出时_count都会减1，这就是内置锁重入性的实现原理。<br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外，monitor对象内部还有两条队列_EntryList和_WaitSet，对应着AQS的同步队列和条件队列，当线程获取锁失败时会到_EntryList中阻塞，当调用锁对象的wait方法时线程将会进入_WaitSet中等待，这是内置锁的线程同步和条件等待的实现原理</p>
]]></content>
      <categories>
        <category>synchronized</category>
      </categories>
      <tags>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title>事务传播机制及隔离级别</title>
    <url>/2016/08/20/%E4%BA%8B%E5%8A%A1%E4%BC%A0%E6%92%AD%E6%96%B9%E5%BC%8F%E5%8F%8A%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
    <content><![CDATA[<ul>
<li>7种事务的传播机制（可通过spring配置或注解来设置<ul>
<li>REQUIRED（默认）：支持当前事务，当前事务不存在，则新建一个事务。</li>
<li>REQUIRES_NEW：创建一个新事务，如果当前事务存在，把当前事务挂起。</li>
<li>SUPPORTS：支持当前事务，当前事务不存在，则不使用事务。</li>
<li>NOT_SUPPORTED：无事务执行，如果当前事务存在，把当前事务挂起。</li>
<li>MANDATORY：中文翻译为强制，支持使用当前事务，如果当前事务不存在，则抛出Exception。</li>
<li>NEVER：无事务执行，当前有事务则抛出Exception。</li>
<li>NESTED：嵌套事务，如果当前事务存在，那么在嵌套的事务中执行。如果当前事务不存在，则表现跟REQUIRED一样。</li>
</ul>
</li>
</ul>
<blockquote>
<p>注解配置时如：@Transactional(propagation=Propagation.REQUIRED) </p>
</blockquote>
<ul>
<li>四种隔离级别</li>
</ul>
<blockquote>
<p>注解配置时如：@Transaction(isolation = Isolation.READ_UNCOMMITTED)</p>
</blockquote>
<table>
<thead>
<tr>
<th style="text-align:left">事物隔离级别</th>
<th style="text-align:left">脏读</th>
<th style="text-align:left">不可重复度</th>
<th style="text-align:left">幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">读未提交（read-uncommited）</td>
<td style="text-align:left">是</td>
<td style="text-align:left">是</td>
<td style="text-align:left">是</td>
</tr>
<tr>
<td style="text-align:left">读已提交（read-commit）</td>
<td style="text-align:left">否</td>
<td style="text-align:left">是</td>
<td style="text-align:left">是</td>
</tr>
<tr>
<td style="text-align:left">重复度（repeatable-read）</td>
<td style="text-align:left">否</td>
<td style="text-align:left">否</td>
<td style="text-align:left">是</td>
</tr>
<tr>
<td style="text-align:left">串行化（seriablizable）</td>
<td style="text-align:left">否</td>
<td style="text-align:left">否</td>
<td style="text-align:left">否</td>
</tr>
</tbody>
</table>
<p>其中：重复读（repeatable-read)表示：在开始读取数据（事务开启）时，不允许修改操作。</p>
<p><strong>mysql默认的事务隔离级别为可重复读（repeatabled-read）</strong></p>
<p>事务的并发问题(事务A: A  事务B: B)</p>
<p>1.脏读：A读了B更新的数据，B回滚操作，则A读到的就是脏数据。</p>
<p>2.不可重复读：A多次读同一数据，B在A读取的过程中，对数据做了更新并提交，导致A多次读取数据时，结果不一致。</p>
<p>3.幻读：A多次读取同一批数据，B在A读取过程中，新增了一条数据（删除一条），导致A读到的数据新增了一条，似产生幻觉。</p>
<blockquote>
<p>（不可重复读侧重于修改，幻读侧重于新增或删除）解决不可重复读问题只需锁住满足条件的行，解决幻读需要锁表）</p>
</blockquote>
]]></content>
      <categories>
        <category>事务</category>
      </categories>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>java中Orderd接口</title>
    <url>/2018/06/10/%E5%88%86%E5%B8%83%E5%BC%8FCAP%E8%A7%84%E5%88%99/</url>
    <content><![CDATA[<p><strong>分区容错性Partition</strong></p>
<p>分布式系统中的某个节点出现故障问题，整个系统仍能对外提供满足一致性和可用性的服务。</p>
<p><strong>可用性Availability</strong><br>一直可正常访问并得到系统的正常响应。</p>
<p><strong>一致性Consistency</strong><br>分布式系统中各节点时刻保持数据一致。如完成写操作后，任何操作都应该可获取到改写操作的写入的最新值。</p>
<p><strong>CAP三者不可兼得</strong></p>
<p>CA:优先保持一致性、可用性，放弃容错性。放弃系统扩展性，系统不合符腹分布式系统设计。</p>
<p>CP:优先保持一致性、容错性。放弃可用性。数据一致性要求较高时使用，发生网络故障、消息丢失，以用户体验为代价，等恢复后才可逐渐访问。</p>
<p>AP：优先保证可用性和分区容错性，放弃一致性。做相应补偿机制来处理一致性问题。</p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>CAP</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>多线程中ThreadLocal</title>
    <url>/2019/01/05/%E5%85%B3%E4%BA%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%ADThreadLocal/</url>
    <content><![CDATA[<p><strong>一、ThreadLocal介绍</strong>：</p>
<p><strong><em>变量的种类：</em></strong> </p>
<ol>
<li>成员变量：整个类中可以访问</li>
<li>局部变量：代码块中可以访问</li>
<li>线程局部的变量</li>
</ol>
<p>Thread并不是一个Thread（线程)，而是Thread的局部变量（ThreadLocalVariable),当时用<br>ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供了独立的变量副本，所以没<br>个线程都可以改变独立的改变线程内自己的变量副本，而不会影响其他线程所对应的副本。</p>
<p>   从线程的角度看，目标变量就像是线程的本地变量，这也是“local”所要表达的意思！</p>
<p> ThreadLocal不是一个线程，它是一个容器，就是像是hashMap一样，用来保存数据的。<br>它的key值，不用你指定，它的key值默认是Thread.currentThread();<br>对于threadlLocal来说，一个项目中只要有一个就可以了。可以缓存所有线程。</p>
<p><strong>ThreadLocal中的方法</strong></p>
<ul>
<li><p>void set（Object value):设置当前线程的线程局部变量的值！</p>
</li>
<li><p>public Object get():该方法返回当前线程所对应的线程局部变量！</p>
</li>
<li><p>public void remove():将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK1,5新增的方法。当线程结束后，对应线程的局部变量将自动被垃圾回收，所以显示调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度！</p>
</li>
<li><p>protected Object initialValue():返回该线程局部变量的初始值。这个方法是一个延迟调用方法，在线程第一次调用get()或set(Object)时才执行，并且仅执行一次。ThreadLocal中的缺省实现直接返回一个Null</p>
</li>
</ul>
<p><strong>ThreadLocal是如何为每个线程维护变量的副本</strong></p>
<p>  在ThreadLocal中定义了一个ThreadLocalMap，每一个Thread中都有一个该类型的变量–Threadlocals—用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值为对应线程的变量副本！</p>
<p>  <img src="/images/threadLocal_01/00001.jpg" alt="Alt text"></p>
]]></content>
      <categories>
        <category>ThreadLocal</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title>排序算法-冒泡</title>
    <url>/2015/05/17/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95-%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<ul>
<li><p>冒泡排序</p>
<p>待排序的数据中，自上而下对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">/**</span><br><span class="line">  * 冒泡排序（待排序的数据中，自上而下对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒）</span><br><span class="line">  */</span><br><span class="line"></span><br><span class="line"> public int[] bubbleSort() &#123;</span><br><span class="line">     int[] a = &#123;10, 2, 3, 5, 6, 12, 89&#125;;</span><br><span class="line"></span><br><span class="line">     for (int i = 0; i &lt; a.length; i++) &#123;</span><br><span class="line">         for (int j = 0; j &lt; a.length - 1 - i; j++) &#123;</span><br><span class="line">             if (a[j + 1] &lt; a[j]) &#123;</span><br><span class="line">                 int temp = a[j + 1];</span><br><span class="line">                 a[j + 1] = a[j];</span><br><span class="line">                 a[j] = temp;</span><br><span class="line">             &#125;</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     return a;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> @Test</span><br><span class="line"> public void bubbleSortTest() &#123;</span><br><span class="line"></span><br><span class="line">     int[] result = bubbleSort();</span><br><span class="line">     for (int i=0;i&lt;result.length;i++) &#123;</span><br><span class="line">         System.err.println(result[i]);</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>排序</category>
      </categories>
      <tags>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title>redis集群中哨兵机制</title>
    <url>/2018/09/15/%E5%93%A8%E5%85%B5/</url>
    <content><![CDATA[<p><strong>哨兵</strong></p>
<p><img src="/images/sentinel_01/00001.jpg" alt="Alt text"></p>
<p>定义：哨兵是redis集群机构中重要的一个组件，有以下功能：</p>
<ul>
<li><p>集群监控：负责监控redis master、slave进行是否正常（redis主从是否正常）</p>
</li>
<li><p>消息通知：某个redis实例有故障，哨兵负责发送报警消息给管理员。</p>
</li>
</ul>
<ul>
<li>故障转移：如果master node挂了，会自动转移到slave node上。（主节点挂了自动转移到从节点）</li>
</ul>
<ul>
<li>配置中心：故障转移发生了，通知client客户端新的master地址。</li>
</ul>
<blockquote>
<p>哨兵用于redis集群的高可用，是分布式的，作为一个哨兵集群去运行，互相协同工作。</p>
</blockquote>
<ul>
<li><p>故障转移时，判断一个master node(主节点）是否宕机需大部分哨兵同意才可，设计分布式选举。</p>
</li>
<li><p>部分哨兵节点挂了，哨兵集群还是可正常运行的。如果作为一个高可用机制重要组成部分的故障转移系统本身是单点的，有点扯。</p>
</li>
</ul>
<p><strong>核心点</strong></p>
<ul>
<li><p>哨兵至少需3个实例保证自身健壮性。</p>
</li>
<li><p>哨兵+redis主从部署架构，不保证数据无丢失，只保证redis集群的高可用。</p>
</li>
<li><p>哨兵+redis主从这种复杂部署架构，需在测试环境及生产环境进行充足的测试、演练。</p>
</li>
</ul>
<p>Redis Cluster方案服务端路由查询</p>
<p><img src="/images/sentinel_01/00002.jpg" alt="Alt text"></p>
<ol>
<li>redis集群模式工作原理</li>
<li>集群模式下，redis的key如何寻址</li>
<li>分布式寻址有哪些算法</li>
<li>一致性hash算法原理</li>
</ol>
<p>Redis Cluster是一种服务端Sharding技术，3.0版本提供。Redis Cluster并没有使用一致性hash。而是采用slot（槽）概念。一共分为16384个槽。将请求发送到任意节点，接收到请求的节点会将查询请求发送到正确节点上运行。</p>
<p><strong>方案说明：</strong></p>
<ol>
<li><p>通过哈希方式，将数据分片，每个节点均分储存一定哈希槽（哈希值）区间的数据，默认分配了16384个槽位。</p>
</li>
<li><p>每份数据分片储存在多个互为主从多节点上。</p>
</li>
<li><p>数据写入先写主节点，再同步到从节点（支持配置为阻塞同步）</p>
</li>
<li><p>同一分片多个节点间的数据不保持一致性。</p>
</li>
<li><p>读取数据时，客户端操作的key没有分配在该节点上时，redis会返回指向指令，指向正确的节点。</p>
</li>
<li><p>扩容时需把旧节点数据迁移一部分到新节点。</p>
</li>
</ol>
<p>在redis cluster架构下，每个redis要开放两个端口号，如一个是6379，另一个是16379.</p>
<p>16379端口号用来进行节点间通信（也是cluster bus的东西），cluster bus的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus用了另外一种二进制的协议，gossip协议，用于节点间进行高效的数据交换，占用更少的网络宽带和处理时间。</p>
<p><strong>节点间的内部通信机制</strong></p>
<p>原理：集群元数据维护有两种方式：集中式、Gossip协议。Redis Cluster节点间采用了Gossip协议进行通信。</p>
<p><strong>分布式寻址算法</strong></p>
<ul>
<li>hash算法（大量缓存重建）</li>
</ul>
<p>一致性hash算法（自动缓存迁移）+虚拟节点（自动负载均衡）</p>
<ul>
<li>redis cluster的hash slot算法</li>
</ul>
<p><strong>优点：</strong></p>
<ul>
<li><p>无中心架构，支持动态扩容，对业务透明。</p>
</li>
<li><p>具备Sentinel的监控和自动Failover（故障转移）能力</p>
</li>
<li><p>客户端无需连接集群所有结点，连接集群中任何一个可用节点即可。</p>
</li>
<li><p>高性能，客户端直连redis服务，免去了proxy代理的损耗</p>
</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li><p>运维复杂、数据迁移需人工干预</p>
</li>
<li><p>只能用0号数据库</p>
</li>
<li><p>不支持批量操作（pipeline管道操作）</p>
</li>
<li><p>分布式逻辑和储存模块耦合</p>
</li>
</ul>
<p><strong>基于客户端分配</strong></p>
<p><img src="/images/sentinel_01/00003.jpg" alt="Alt text"></p>
<p>介绍：Redis Sharding是Redis Cluster出来之前，普遍使用的多Redis实例集群方法。其主要思想是采用哈希算法将Redis数据的key进行散列，通过hash函数，特定的key会映射到特定的Redis节点上。Java redis客户端jedis，支持redis shareing功能，即ShardedJedis以及结合缓存池ShardedJedisPool。</p>
<p><strong>优点：</strong></p>
<p>非常简单，服务器的Redis实例彼此独立，相互无关联，每个Redis实例像单服务器一样运行，容易线性扩展，灵活性高。</p>
<p><strong>缺点：</strong></p>
<ul>
<li>由于Sharding处理放到客户端，规模扩大时给运维带来挑战。</li>
</ul>
<p>客户端sharding不支持动态增删节点。服务端Redis实例群拓扑结构变化时，每个客户端都需要更新调整。连接不能共享，应用规则增大会资源浪费制约。</p>
<p><strong>基于代理服务器分片</strong></p>
<p><img src="/images/sentinel_01/00004.jpg" alt="Alt text"></p>
<p>简介</p>
<p>客户端发送请求到一个代理组件，代理解析客户端数据，并将请求转发到正确的节点，最后将结果回复给客户端。</p>
<p><strong>特征：</strong></p>
<ul>
<li><p>透明接入，业务程序不用关系后端Redis实例，切换成本低。</p>
</li>
<li><p>Proxy的逻辑和储存的逻辑是隔离的</p>
</li>
<li><p>代理层多了一次转发，性能有所损耗</p>
</li>
</ul>
<p><strong>业界开源方案</strong></p>
<ul>
<li><p>Twtter 开源 Twemproxy</p>
</li>
<li><p>豌豆荚开源的Codis</p>
</li>
</ul>
<p><strong>Redis主从架构</strong></p>
<p>单机的Redis，能够承载的QPS大概上万到几万不等。对于缓存，一般都是用来支撑读高并发的。架构都做成主从（master-slave)架构，一主多从，主负责写，并且将数据复制到其他的slave节点，从节点负责读。所有的读请求全部走从节点。这样可轻松实现水平扩容，支撑读高并发。</p>
<p><img src="/images/sentinel_01/00005.jpg" alt="Alt text"></p>
<p>redis replication-&gt;主从架构-&gt;读写分离-&gt;水平扩容支撑读高并发</p>
<p><strong>redis replication核心机制</strong></p>
<ul>
<li><p>redis采用异步方式复制数据到slave节点，不过Redis2.8开始，从节点(slave node)会周期性的确认自己每次复制的质量。</p>
</li>
<li><p>一个master node是可以配置多个slave node的。</p>
</li>
<li><p>slave node 也可连接其他的slave node </p>
</li>
<li><p>slave node 做复制时，不会block master node正常工作。</p>
</li>
<li><p>slave node在做复制时，也不会block对自己的查询操作，它会用旧的数据集来提供服务；但复制完成时，需删除旧数据集，加载新数据集，这时会暂停对外服务</p>
</li>
<li><p>slave node 主要用来进行横向扩容，做读写分离，扩容的slave node可提高读的吞吐量。</p>
</li>
</ul>
<blockquote>
<p>如采用了主从架构，建议必须开启master node的持久化，不建议用从节点（slave node）作为主节点（master node）的数据热备，如你关掉master持久化，可能在主节点（master）宕机重启时数据是空的，然后一经复制，slave node的数据也丢了。</p>
</blockquote>
<p>Redis主从复制的核心原理</p>
<p>启动从节点(slave node)时，它会发送一个PSYNC命令给主节点(Master Node)</p>
<p>如果是从节点（slave node)初次连接到主节点（master node)，那么会触发一次full resynchronization 全量复制。此时主服务节点(master)会启动一个后台线程，开始生成一份RDB快照文件。<br>同时还会将从客户端client新收到的所有写命令缓存到内存中。RDB文件生成完毕后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中，<br>主服务节点（master)会将内存中缓存的写命令发送到从服务节点（slave）,从服务节点（slave)也会同步这些数据。</p>
<p>从节点（slave node)如果跟主节点（master node)存在网络故障，断开连接了，会自动重连，连接后主节点（master node)仅<br>会复制给slave部分缺少的数据。</p>
<p>图六</p>
<p><strong>过程原理</strong></p>
<ul>
<li><p>当从库和主库建立MS关系后，会向主数据库发送SYNC命令</p>
</li>
<li><p>主库接收到SYNC命令后开始在后台保存快照（RDB持久化过程），并将周期接收到的写命令缓存起来。</p>
</li>
<li><p>当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis</p>
</li>
<li><p>从Redis接收到后，会载入快照文件并且执行收到的缓存命令</p>
</li>
<li><p>主Redis每当接收到写命令就会将命令发送给Redis，从而保证数据的一致</p>
</li>
</ul>
<p><strong>缺点：</strong></p>
<p>所有的slave节点数据的复制和同步都由master节点来处理，会造成master节点压力太大，使用主从结构来解决。</p>
<p><strong>Redis集群的主从复制模型</strong></p>
<p>集群使用了主从复制模型，每个节点都会有N-1个复制品，为了使在部分节点失败或大部分节点无法通信情况下集群仍可用。</p>
<p><strong>Redis哈希槽概念</strong></p>
<p>Redis集群没有使用一致性hash，而是引入哈希槽概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群每个节点负责一部分hash槽。</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>reids</tag>
        <tag>sentinel</tag>
        <tag>哨兵</tag>
      </tags>
  </entry>
  <entry>
    <title>并发编程设置合适线程数</title>
    <url>/2020/09/06/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%88%9B%E5%BB%BA%E5%A4%9A%E5%B0%91%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%90%88%E9%80%82/</url>
    <content><![CDATA[<p>并发编程创建多少个线程合适？</p>
<ul>
<li>并发编程在所有场景下都是快的吗？</li>
<li>快怎样度量</li>
</ul>
<p>需要从定性—-&gt;定量的分析过程。</p>
<p>正确的场景下、设置正确个数才能达到最优运行（充分利用CPU和I/O的利用率）</p>
<ul>
<li><p>CPU密集型程序</p>
<p>  一个完成的请求，I/O操作可以在很短时间内完成，CPU还有很多运算要处理。也就是说CPU计算的比例占很大一部分。</p>
<p>  如我们要计算1+2+3….+10000亿的总和，这就是一个CPU密集型程序。<br>  单核CPU下，我们创建4个线程来分段计算，如：<br>   1.线程1计算[1，2500亿）<br>   2.线程2计算…<br>   3.线程3计算…<br>   4.线程4计算[7500亿，10000亿]</p>
</li>
</ul>
<p><img src="/images/threadNumber/000001.png" alt="Alt text"></p>
<p>   因为是单核CPU，所有线程都在等待CPU时间片。按照理想状态，四个线程执行的时间总和与一个线程5独自完成是相等的。（在忽略四个线程上线文切换的开销情况下）</p>
<p>  <strong>所以单核CPU处理CPU密集型程序并不太适合使用多线程。</strong>  </p>
<p>如果在四核CPU下，同样创建四个线程来分段计算，如图：</p>
<p><img src="/images/threadNumber/000002.png" alt="Alt text"></p>
<p>每个线程都有CPU来运行，并不会发生等待CPU时间片的情况，也没有线程切换的开销。理论情况来看效率提升4倍。</p>
<p><strong>所以，如果是多核CPU处理CPU密集型程序，完全可以最大化的利用CPU核心数，应用并发编程来提高效率</strong></p>
<ul>
<li>I/O密集型程序</li>
</ul>
<p>与CPU密集型程序相对，一个完整请求，CPU运算操作完成之后还有很多I/O操作要做，也就是说I/O操作占比很大。</p>
<p>进行I/O操作时，CPU是空闲状态，所以我们要最大化利用CPU，不能让其是空闲状态。</p>
<p>同样的单核CPU情况下：</p>
<p><img src="/images/threadNumber/000003.png" alt="Alt text"></p>
<p>综合两种情况可总结：</p>
<p><strong>线程等待时间所占比例越高，需要越多线程；线程CPU时间所占比例越高，需要越少线程。</strong></p>
<ul>
<li>CPU密集型程序创建多少个线程？<br>理论上 <strong>线程数量 = CPU核数 (逻辑)</strong> 就可以了。但是实际数量一般会设置为CPU核数（逻辑）+1 。</li>
</ul>
<p>计算(CPU）密集型的线程恰好在某时因为发生一个页错误或者因其他原因而暂停，刚好有一个额外的线程，可以确保这种情况下CPU周期不会中断工作。</p>
<p>对于CPU密集型程序，CPU核数(逻辑)+1个线程数是比较好的经验值的原因了。</p>
<p><strong>I/O密集型程序创建多少个线程合适</strong></p>
<p> 对于单核CPU计算：</p>
<p>   最佳线程数 = （1/CPU利用率) = 1+(I/O耗时/CPU耗时）</p>
<p> 对于多核CPU计算：</p>
<p>   最佳线程数 = CPU核心数<em>（1/CPU利用率）= CPU核心数 </em> （1+（I/O耗时/CPU耗时)) </p>
<p>在I/O密集型程序，不知CPU利用率的情况下。按照上面公式，假如几乎全是I/O耗时，所以纯理论可以认为：</p>
<p> 线程数 = 2N(N=CPU核数)，也可认为 2N+1的（一个线程作为backup)</p>
]]></content>
      <categories>
        <category>thread</category>
      </categories>
      <tags>
        <tag>线程数</tag>
      </tags>
  </entry>
  <entry>
    <title>初步理解线程池核心知识</title>
    <url>/2017/06/25/%E5%88%9D%E6%AD%A5%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<p>  先从基础概念开始到最后的并发模型由浅入深来加深理解，总结下线程方面的认知。</p>
<p>  <strong>并发与并行</strong></p>
<p>   并行：表示两个线程同时做事情。<br>   并发：表示一会儿做这个事情，一会儿做另一个事情，存在着调度，单核cpu不可能存在并行，</p>
<p>  临界区</p>
<pre><code>临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每一次，只能有一个线程
使用它，一旦临界区资源被占用，其他线程要想使用这个资源，就必须等待。
</code></pre><p>   <img src="/images/threadPool/1.jpg" alt="Alt text"></p>
<p>  <strong>阻塞与非阻塞</strong></p>
<p>   阻塞和非阻塞通常用来形容多线程间的相互影响。比如一个线程占用了临界区资源，那么其它所有需要这个资源的线程就必须在这个临界区中进行等待，等待会导致线程挂起。这种情况就是阻塞。</p>
<p>  此时，如果占用资源的线程一直不愿意释放资源，那么其它所有阻塞在这个临界区上的线程都不能工作。阻塞是指线程在操作系统层面被挂起。阻塞一般性能不好，需大约8万个时钟周期来做调度。</p>
<p>  非阻塞则允许多个线程同时进入临界区。</p>
<p>  <strong>死锁</strong></p>
<p>  死锁是进程死锁的简称，是指多个进程循环等待他方占有的资源而无限的僵持下去的局面。</p>
<p>   <img src="/images/threadPool/死锁.jpg" alt="Alt text"></p>
<p><strong>活锁</strong></p>
<p>假设有两个线程1、2，它们都需要资源 A/B，假设1号线程占有了 A 资源，2号线程占有了 B 资源；由于两个线程都需要同时拥有这两个资源才可以工作，为了避免死锁，1号线程释放了 A 资源占有锁，2号线程释放了 B 资源占有锁；此时 AB 空闲，两个线程又同时抢锁，再次出现上述情况，此时发生了活锁。</p>
<p>简单类比，电梯遇到人，一个进的一个出的，对面占路，两个人同时往一个方向让路，来回重复，还是堵着路。</p>
<p>如果线上应用遇到了活锁问题，恭喜你中奖了，这类问题比较难排查。</p>
<p>饥饿</p>
<p>饥饿是指某一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行。</p>
<p>线程的生命周期</p>
<p>在线程的生命周期中，它要经历创建、可运行、不可运行几种状态。</p>
<p><strong>创建状态</strong></p>
<p>当用 new 操作符创建一个新的线程对象时，该线程处于创建状态。</p>
<p>处于创建状态的线程只是一个空的线程对象，系统不为它分配资源。</p>
<p><strong>可运行状态</strong></p>
<p>执行线程的 start() 方法将为线程分配必须的系统资源，安排其运行，并调用线程体——run()方法，这样就使得该线程处于可运行状态（Runnable）。</p>
<p>这一状态并不是运行中状态（Running），因为线程也许实际上并未真正运行。</p>
<p><strong>不可运行状态</strong></p>
<p>当发生下列事件时，处于运行状态的线程会转入到不可运行状态：</p>
<p>调用了 sleep() 方法；<br>线程调用 wait() 方法等待特定条件的满足；<br>线程输入/输出阻塞；<br>返回可运行状态；<br>处于睡眠状态的线程在指定的时间过去后；<br>如果线程在等待某一条件，另一个对象必须通过 notify() 或 notifyAll() 方法通知等待线程条件的改变；<br>如果线程是因为输入输出阻塞，等待输入输出完成。<br>线程的优先级</p>
<p><strong>线程优先级及设置</strong></p>
<p>线程的优先级是为了在多线程环境中便于系统对线程的调度，优先级高的线程将优先执行。一个线程的优先级设置遵从以下原则：</p>
<p>线程创建时，子继承父的优先级；<br>线程创建后，可通过调用 setPriority() 方法改变优先级；<br>线程的优先级是1-10之间的正整数。<br>线程的调度策略</p>
<p>线程调度器选择优先级最高的线程运行。但是，如果发生以下情况，就会终止线程的运行：</p>
<p>线程体中调用了 yield() 方法，让出了对 CPU 的占用权；<br>线程体中调用了 sleep() 方法，使线程进入睡眠状态；<br>线程由于 I/O 操作而受阻塞；<br>另一个更高优先级的线程出现；<br>在支持时间片的系统中，该线程的时间片用完。<br>单线程创建方式</p>
<p>单线程创建方式比较简单，一般只有两种方式：继承 Thread 类和实现 Runnable 接口；这两种方式比较常用就不在 Demo 了，但是对于新手需要注意的问题有：</p>
<p>不管是继承 Thread 类还是实现 Runable 接口，业务逻辑是写在 run 方法里面，线程启动的时候是执行 start() 方法；<br>开启新的线程，不影响主线程的代码执行顺序也不会阻塞主线程的执行；<br>新的线程和主线程的代码执行顺序是不能够保证先后的；<br>对于多线程程序，从微观上来讲某一时刻只有一个线程在工作，多线程目的是让 CPU 忙起来；<br>通过查看 Thread 的源码可以看到，Thread 类是实现了 Runnable 接口的，所以这两种本质上来讲是一个；<br>PS：平时在工作中也可以借鉴这种代码结构，对上层调用来讲提供更多的选择，作为服务提供方核心业务归一维护</p>
<p>为什么要用线程池</p>
<p>通过上面的介绍，完全可以开发一个多线程的程序，为什么还要引入线程池呢。主要是因为上述单线程方式存在以下几个问题：</p>
<p>线程的工作周期：线程创建所需时间为 T1，线程执行任务所需时间为 T2，线程销毁所需时间为 T3，往往是 T1+T3 大于 T2，所有如果频繁创建线程会损耗过多额外的时间；<br>如果有任务来了，再去创建线程的话效率比较低，如果从一个池子中可以直接获取可用的线程，那效率会有所提高。所以线程池省去了任务过来，要先创建线程再去执行的过程，节省了时间，提升了效率；<br>线程池可以管理和控制线程，因为线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控；<br>线程池提供队列，存放缓冲等待执行的任务。<br>大致总结了上述的几个原因，所以可以得出一个结论就是在平时工作中，如果要开发多线程程序，尽量要使用线程池的方式来创建和管理线程。</p>
<p>通过线程池创建线程从调用 API 角度来说分为两种，一种是原生的线程池，另外该一种是通过 Java 提供的并发包来创建，后者比较简单，后者其实是对原生的线程池创建方式做了一次简化包装，让调用者使用起来更方便，但道理都是一样的。所以搞明白原生线程池的原理是非常重要的。</p>
<p>ThreadPoolExecutor</p>
<p>通过 ThreadPoolExecutor 创建线程池，API 如下所示：</p>
<p>/**</p>
<pre><code> * public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,
 *                           TimeUnit unit,BlockingQueue&lt;Runnable&gt; workQueue)
 * corePoolSize用于指定核心线程数量
 * maximumPoolSize指定最大线程数
 * keepAliveTime和TimeUnit指定线程空闲后的最大存活时间
 * workQueue则是线程池的缓冲队列,还未执行的线程会在队列中等待
 * 监控队列长度，确保队列有界
 * 不当的线程池大小会使得处理速度变慢，稳定性下降，并且导致内存泄露。如果配置的线程过少，则队列会持续变大，消耗过多内存。
 * 而过多的线程又会 由于频繁的上下文切换导致整个系统的速度变缓——殊途而同归。队列的长度至关重要，它必须得是有界的，这样如果线程池不堪重负了它可以暂时拒绝掉新的请求。
 * ExecutorService 默认的实现是一个无界的 LinkedBlockingQueue。
 */
private ThreadPoolExecutor executor  = new ThreadPoolExecutor(corePoolSize, corePoolSize+1, 10l, TimeUnit.SECONDS,
        new LinkedBlockingQueue&lt;Runnable&gt;(1000));
</code></pre><p>先来解释下其中的参数含义（如果看的比较模糊可以大致有个印象，后面的图是关键）。</p>
<p>corePoolSize<br>核心池的大小。<br>在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了 prestartAllCoreThreads() 或者 prestartCoreThread() 方法，从这两个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建 corePoolSize 个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到 corePoolSize 后，就会把到达的任务放到缓存队列当中。</p>
<p>maximumPoolSize<br>线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程。</p>
<p>keepAliveTime<br>表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于 corePoolSize 时，keepAliveTime 才会起作用，直到线程池中的线程数不大于 corePoolSize，即当线程池中的线程数大于 corePoolSize 时，如果一个线程空闲的时间达到 keepAliveTime，则会终止，直到线程池中的线程数不超过 corePoolSize。</p>
<p>但是如果调用了 allowCoreThreadTimeOut(boolean) 方法，在线程池中的线程数不大于 corePoolSize 时，keepAliveTime 参数也会起作用，直到线程池中的线程数为0。</p>
<p>unit<br>参数 keepAliveTime 的时间单位。</p>
<p>workQueue<br>一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下这几种选择：</p>
<ul>
<li><p>ArrayBlockingQueue：<br>是一个基于数组结构的有界阻塞队列，此队列安FIFO（先进先出）原则对元素进行排序。</p>
</li>
<li><p>LinkedBlockingQueue、<br>基于链表结构的阻塞队列，次队列按照</p>
</li>
<li>SynchronousQueue。</li>
</ul>
<p>threadFactory<br>线程工厂，主要用来创建线程。</p>
<p>handler<br>表示当拒绝处理任务时的策略，有以下四种取值：</p>
<p>ThreadPoolExecutor.AbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常；<br>ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常；<br>ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）；<br>ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务。<br>上面这些参数是如何配合工作的呢？请看下图：</p>
<p>   <img src="/images/threadPool/线程池参数配置详解.jpg" alt="Alt text"></p>
<p>注意图上面的序号。</p>
<p>简单总结下线程池之间的参数协作分为以下几步：</p>
<p>线程优先向 CorePool 中提交；<br>在 Corepool 满了之后，线程被提交到任务队列，等待线程池空闲；<br>在任务队列满了之后 corePool 还没有空闲，那么任务将被提交到 maxPool 中，如果 MaxPool 满了之后执行 task 拒绝策略。<br>流程图如下：</p>
<p>   <img src="/images/threadPool/线程池执行流程.jpg" alt="Alt text"></p>
<p>以上就是原生线程池创建的核心原理。除了原生线程池之外并发包还提供了简单的创建方式，上面也说了它们是对原生线程池的一种包装，可以让开发者简单快捷的创建所需要的线程池。</p>
<p>Executors</p>
<p>newSingleThreadExecutor</p>
<p>创建一个线程的线程池，在这个线程池中始终只有一个线程存在。如果线程池中的线程因为异常问题退出，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。</p>
<p>newFixedThreadPool</p>
<p>创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。</p>
<p>newCachedThreadPool</p>
<p>可根据实际情况，调整线程数量的线程池，线程池中的线程数量不确定，如果有空闲线程会优先选择空闲线程，如果没有空闲线程并且此时有任务提交会创建新的线程。在正常开发中并不推荐这个线程池，因为在极端情况下，会因为 newCachedThreadPool 创建过多线程而耗尽 CPU 和内存资源。</p>
<p>newScheduledThreadPool</p>
<p>此线程池可以指定固定数量的线程来周期性的去执行。比如通过 scheduleAtFixedRate 或者 scheduleWithFixedDelay 来指定周期时间。</p>
<p>PS：另外在写定时任务时（如果不用 Quartz 框架），最好采用这种线程池来做，因为它可以保证里面始终是存在活的线程的。</p>
<p>推荐使用 ThreadPoolExecutor 方式</p>
<p>在阿里的 Java 开发手册时有一条是不推荐使用 Executors 去创建，而是推荐去使用 ThreadPoolExecutor 来创建线程池。</p>
<p>这样做的目的主要原因是：使用 Executors 创建线程池不会传入核心参数，而是采用的默认值，这样的话我们往往会忽略掉里面参数的含义，如果业务场景要求比较苛刻的话，存在资源耗尽的风险；另外采用 ThreadPoolExecutor 的方式可以让我们更加清楚地了解线程池的运行规则，不管是面试还是对技术成长都有莫大的好处。</p>
<p><strong>线程池有5种状态：</strong><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">volatile int runState;</span><br><span class="line">// runState is stored in the high-order bits</span><br><span class="line">private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;</span><br><span class="line">private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;</span><br><span class="line">private static final int STOP       =  1 &lt;&lt; COUNT_BITS;</span><br><span class="line">private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;</span><br><span class="line">private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;</span><br></pre></td></tr></table></figure></p>
<p>runState表示当前线程池的状态，它是一个 volatile 变量用来保证线程之间的可见性。<br>下面的几个static final变量表示runState可能的几个取值，有以下几个状态：</p>
<ul>
<li>RUNNING：能接受新提交的任务，并且也能处理阻塞队列中的任务。(线程池初始时，线程池处于RUNNING状态；)</li>
<li>SHUTDOWN：关闭状态，不接受新提交的任务，但可以处理阻塞队列中已保存的任务。在线程池处于 RUNNING 状态时，调用 shutdown() 方法会使线程池进入到该状态。（finalize() 方法在执行过程中也会调用 shutdown() 方法进入该状态）</li>
<li>STOP：不能接受新任务，也不处理阻塞队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态。</li>
<li>TIDYING：如果所有的任务都已终止了，workerCount (有效线程数) 为0，线程池进入该状态后会调用 terminated() 方法进入 TERMINATED 状态。</li>
<li>TERMINATED：在 terminated() 方法执行完后进入该状态，默认 terminated() 方法中什么也没有做。</li>
</ul>
<p>改了变量，其他线程可以立即知道。保证可见性的方法有以下几种：</p>
<p>volatile<br>加入 volatile 关键字的变量在进行汇编时会多出一个 lock 前缀指令，这个前缀指令相当于一个内存屏障，内存屏障可以保证内存操作的顺序。当声明为 volatile 的变量进行写操作时，那么这个变量需要将数据写到主内存中。</p>
<p>由于处理器会实现缓存一致性协议，所以写到主内存后会导致其他处理器的缓存无效，也就是线程工作内存无效，需要从主内存中重新刷新数据。</p>
]]></content>
      <categories>
        <category>多线程</category>
      </categories>
      <tags>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql索引数据结构</title>
    <url>/2018/05/19/%E6%A0%91%E5%BD%A2%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<p><strong>树结构</strong>：</p>
<blockquote>
<p>前中后序遍历、二叉树、二叉搜索树、平衡二叉树，更高级点的有红黑树、B树、B+树、字典树..</p>
</blockquote>
<blockquote>
<p>红黑树（为什么这样设计）设计理念、原理、解决问题的方法比技术本身重要</p>
</blockquote>
<p><strong>二叉排序树</strong></p>
<p><img src="/images/b_tree/001.jpg" alt="Alt text"></p>
<blockquote>
<p>左边比根节点小，右边比根节点大。并且左右子树都是二叉排序树。但是在一些极端情况下，比如插入序列是有序的，就会出现退化的情况。</p>
</blockquote>
<p><img src="/images/b_tree/002.jpg" alt="Alt text"></p>
<blockquote>
<p>有序序列，二叉排序树会退化成链表。</p>
</blockquote>
<p><strong>平衡树</strong></p>
<blockquote>
<p>插入数据的时候同时调整这棵树，让它的节点尽可能均匀分布。</p>
<p>红黑树就是平衡树的一种，它的复杂的定义和规则，都是为了保证树的平衡性。</p>
</blockquote>
<p><img src="/images/b_tree/003.jpg" alt="Alt text"></p>
<p><strong>保证树的平衡性原因</strong></p>
<blockquote>
<p>因为树的查找性能取决于树的高度，让树尽可能平衡。为了降低树的高度。</p>
<p>java中的TreeSet数据结构底层就是红黑树。</p>
</blockquote>
<p><strong>B树</strong></p>
<blockquote>
<p>一种多路搜索树，它的每个节点可以拥有多余两个孩子的节点（它的每个节点可以拥有多个孩子节点（多余两个））。M路的B树最多能拥有M个孩子节点。</p>
</blockquote>
<p><img src="/images/b_tree/004.jpg" alt="Alt text"></p>
<blockquote>
<p>这是一个3路的B数，每个节点最多可以拥有3个孩子，同样是搜索树。</p>
<p>多路搜索树设计成多路，是为了进一步降低树的高度。路数越多，树的高度月底。</p>
<p>如果设计成无限多路时，会退化成有序数组。</p>
<p>25 25 30 40 43 45 50 59 65 77 85 </p>
</blockquote>
<p><img src="/images/b_tree/005.jpg" alt="Alt text"></p>
<p><strong>使用场景：</strong></p>
<p>B树一般做文件系统的索引比较多</p>
<p>为什么文件系统的索引喜欢用B树而不是红黑树、有序数组？</p>
<p>文件系统和数据库的索引都是存在硬盘上的，并且如果数据量大，不一定能一次性加载到内存中。（考虑运行时内存情况）</p>
<p>如果一棵树都无法一次性加载进内存，要怎样查找呢？这时候B树的多路存储作用出来的，可以每次加载B树的一个节点，然后一步步往下去找。</p>
<p>25 25 30 40 43 45 50 59 65 77 85 </p>
<p><img src="/images/b_tree/005.jpg" alt="Alt text"></p>
<p>假设内存一次性只能加载2个数，这么长的有序数据是无法一次性进内存的。</p>
<p><img src="/images/b_tree/006.jpg" alt="Alt text"></p>
<p>我们把它组织成一颗三路的B树，这样每个节点最多能有2个数。</p>
<p><img src="/images/b_tree/007.jpg" alt="Alt text"></p>
<p>查找的时候，每次载入一个节点进内存就行。</p>
<p>如果在内存中，红黑树比B树效率更高，但是设计到磁盘操作，B树就更优了。</p>
<p><strong>B+树</strong></p>
<p>B+树是在B树的基础上改造的，它的数据都在叶子节点，同时叶子节点之间还加了指针形成链表。</p>
<p><img src="/images/b_tree/008.jpg" alt="Alt text"></p>
<p>这是一个4路B+树，它的数据都在叶子结点并且有链表相连。</p>
<p><strong>为什么要这样设计</strong></p>
<p>B+树在数据库的索引中用得比较多。数据库中select数据，不一定只选一条，很多时候选多条，B树需要做局部的中序遍历，可能要跨层访问。而B+树由于所有数据都在叶子节点，不用跨层，同时由于有链表结构，只需要找到首尾，通过链表就能把所有数据取出来了。</p>
<p><img src="/images/b_tree/009.jpg" alt="Alt text"></p>
<p>比如选出7到19，只需要在叶子节点中就能找到。</p>
<p><strong>为什么hash比B+树更快，为啥mysql还用B+树来存索引？</strong></p>
<p>这和业务场景有关，如果只选一条数据，那确实是hash更快。但是数据库中经常会选择多条，这时候由于B+树索引有序，并且又有链表相连，它的查询效率比hash就快很多了。而且数据库中的索引一般都是在磁盘上的，数据量大的情况可能无法一次装入内存，B+树的设计可以允许数据分批加载，同时树的高度降低，提高查找效率。</p>
<p>B+树查询时间  log(n)</p>
<p>hash查询时间 O(1)</p>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>B+tree</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Boot中解决跨域问题</title>
    <url>/2017/06/25/%E8%B7%A8%E8%B6%8A%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<h2 id="跨域问题"><a href="#跨域问题" class="headerlink" title="跨域问题"></a>跨域问题</h2><ul>
<li>什么情况下会出现跨域问题</li>
</ul>
<p>通常，在前端工程师的开发过程中，往往在本地机器启动前端服务， 而调用的后端接口服务是在另外一台机器运行，这时就会出现跨域问题，让接口无法调通。<br>而到了测试环境和生产环境，可以使用Nginx去解决这个问题。<br>这里我们仅考虑开发环境，在不借助Nginx的情况下，解决跨域。</p>
<ul>
<li>解决方案</li>
</ul>
<p>在SpringBoot工程中，增加跨域配置即可。</p>
<ul>
<li>实现</li>
</ul>
<p>新增一个跨域配置类 CrossDomainConfig，在其中配置允许跨域访问的url、请求方式、Header等。代码如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">import org.springframework.context.annotation.Bean;</span><br><span class="line">import org.springframework.context.annotation.Configuration;</span><br><span class="line">import org.springframework.web.cors.CorsConfiguration;</span><br><span class="line">import org.springframework.web.cors.UrlBasedCorsConfigurationSource;</span><br><span class="line">import org.springframework.web.filter.CorsFilter;</span><br><span class="line"></span><br><span class="line">@Configuration</span><br><span class="line">public class CrossDomainConfig&#123;</span><br><span class="line"></span><br><span class="line">    public CrossDomainConfig() &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">　　private CorsConfiguration buildConfig() &#123;</span><br><span class="line">　　　　</span><br><span class="line">　　　　 // 添加cors配置信息</span><br><span class="line">    　　CorsConfiguration corsConfiguration = new CorsConfiguration();</span><br><span class="line">　　　　 corsConfiguration.addAllowedOrigin(&quot;http://localhost:8080&quot;);</span><br><span class="line">    　　// * 代表所有url</span><br><span class="line">        corsConfiguration.addAllowedOrigin(&quot;*&quot;);</span><br><span class="line"></span><br><span class="line">        // 设置允许请求的方式</span><br><span class="line">        corsConfiguration.addAllowedMethod(&quot;*&quot;);</span><br><span class="line"></span><br><span class="line">        // 设置允许的header</span><br><span class="line">        corsConfiguration.addAllowedHeader(&quot;*&quot;);</span><br><span class="line">        </span><br><span class="line">        // 设置是否发送cookie信息</span><br><span class="line">        corsConfiguration.setAllowCredentials(true);</span><br><span class="line"></span><br><span class="line">    　　return corsConfiguration;</span><br><span class="line">　　&#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    public CorsFilter corsFilter() &#123;</span><br><span class="line">        　</span><br><span class="line">        // 为url添加映射路径</span><br><span class="line">        UrlBasedCorsConfigurationSource crossDomainSource = new UrlBasedCorsConfigurationSource();</span><br><span class="line">        crossDomainSource.registerCorsConfiguration(&quot;/**&quot;, buildConfig()); </span><br><span class="line">        </span><br><span class="line">        // 返回重新定义好的配置</span><br><span class="line">        return new CorsFilter(crossDomainSource); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>重启后台工程，会发现，跨域问题被如此简单的解决了。</p>
]]></content>
      <categories>
        <category>跨域</category>
      </categories>
      <tags>
        <tag>跨域，spring boot</tag>
      </tags>
  </entry>
  <entry>
    <title>阻塞队列BlockingQueue</title>
    <url>/2016/07/12/%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97BlockingQueue/</url>
    <content><![CDATA[<pre><code>阻塞队列（BlockingQueue)是java.util.concurrent包下重要的数据结构，BlockingQueue提
</code></pre><p>供了线程安全的队列访问方式:当向阻塞队列插入数据时，如果队列已满，线程将会阻塞等待直到<br>队列非满从阻塞队列取数据时，如果队列已空，线程将会阻塞等待直到队列非空。并发包下很多<br>高级同步类的实现都是基于BlockingQueue实现的。</p>
<p>  1.BlockingQueue的操作方法<br>  BlockingQueue具有4组不通的方法用于插入，移除以及对队列中的元素进行检查。如果请求的<br>操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下：</p>
<p><img src="/images/queue/blockingQueue.jpg" alt="Alt text"></p>
<p>四组不通的行为方式解释为：</p>
<ul>
<li>抛异常：如果试图的操作无法立即执行，抛出一个异常。</li>
<li>特定值：如果试图的操作无法立即执行，返回一个特定的值(常常为：true/false)</li>
<li>阻塞： 如果试图的操作无法立即执行，该方法调用将会发生阻塞，知道能够执行。</li>
<li>超时： 如果试图的操作无法立即执行，该方法调用将会发生阻塞，知道能够执行，但等待<br>事件不会超过给定值。返回一个特定值后告知该操作是否成功(典型为：true/false)。</li>
</ul>
<p>无法向BlockingQueue中插入null。试图插入null,BlockingQueue会抛出一个nullPointerException。</p>
<p>可以访问到BlockingQueue中的所有元素，而不仅仅是开始和结束的元素。如：你将一个对象放入<br>队列之中等待处理，但你的应用想要将其取消掉，那么你可以调用诸如remove(o)方法来将队列中的<br>特定对象进行移除。但是这么干效率并不高(基于队列的数据结构，获取开始或结束位置的其他<br>对象的效率不会太高)，因此尽量不要使用这类方法，除非不得这样做。</p>
<p>  BlockingQueue的实现类</p>
<p>  BlockingQueue：是一个接口，需要使用它的实现之一来使用BlockingQueue，java.util.<br>  concurrent包下具有以下BlockingQueue接口的实现类：</p>
<ul>
<li><p>ArrayBlockingQueue:ArrayBlockingQueue是一个有界的阻塞队列，内部实现是将对象放到一个<br>数组里。所以它不能存储无限数量的元素。有一个同一时间能够存储元素数量的上限。可以再队列<br>初始化的时候设定这个上限，但之后无法对这个上限进行修改。(因为它是基于数组实现的，<br>也就具有数组的特性：一旦初始化，大小就无法修改)。</p>
</li>
<li><p>DelayQueue:DealyQueue对元素进行持有知道一个特定的延迟到期。注入其中的元素必须实现<br>java.util.concurrent.Delayed接口。</p>
</li>
<li><p>LinkedBlockingQueue:LinkedBlockingQueue内部以一个链式结构(链接节点)对其元素进行储存。<br>如果需要的话，这一链式结构可以选择一个上限。如果没有定义上限，将使用Integer.MAX_VALUE<br>作为上限。</p>
</li>
<li><p>PriorityBlockingQueue:PriorityBlockingQueue是一个无界的并发队列，它使用了和类<br>java.util.PriorityQueue一样的排序规则。你无法向这个队列中插入null值。所有插入到<br>PriorityBlockingQueue的元素必须实现java.lang.Comparable接口。因为该队列中元素的排序<br>就取决于你自己的Comparable实现。</p>
</li>
<li><p>SynchronousQueue:SynchronousQueue是一个特殊的队列，它的内部同时只能容纳单个元素。<br>如果该队列已有一个元素，试图向队列插入一个新元素的线程将会阻塞，知道另一个线程将<br>该元素从队列中抽走。同样如果该队列为空，试图从队列中抽取一个元素的线程将会阻塞，直到<br>另一个线程从队列中插入了一条新的元素。也可将此队列成为汇合点。</p>
<p>范例：</p>
<p>阻塞队列的最长使用的范例就是生产者消费者模式，也是各种实现生产者消费者模式中首选方式。<br>无需关心阻塞生产、消费的时候，使用方便，代码如下：</p>
<p>/**</p>
<ul>
<li>Copyright (C), 2015-2018, XXX有限公司</li>
<li>FileName: BlockingQueueTest</li>
<li>Author:   Administrator</li>
<li>Date:     2018/8/30 23:30</li>
<li>Description:</li>
<li>History:</li>
<li><author>          <time>          <version>          <desc></desc></version></time></author></li>
<li>作者姓名           修改时间           版本号              描述<br>*/<br>package org.apache;</li>
</ul>
</li>
</ul>
<p>import java.util.Random;<br>import java.util.concurrent.BlockingQueue;<br>import java.util.concurrent.LinkedBlockingQueue;</p>
<p>/**</p>
<ul>
<li>〈一句话功能简述〉<br> </li>
<li>〈〉<br>*</li>
<li>@author Administrator</li>
<li>@create 2018/8/30</li>
<li><p>@since 1.0.0<br>*/<br>public class BlockingQueueTest {<br> //生产者<br> static class Producer implements Runnable {</p>
<pre><code>private final BlockingQueue&lt;Integer&gt; blockingQueue;
private volatile boolean flag;
private Random random;
Producer(BlockingQueue&lt;Integer&gt; blockingQueue) {
    this.blockingQueue = blockingQueue;
    flag = false;
    random = new Random();
}
@Override
public void run() {
    while (!flag) {
        int info = random.nextInt(100);
        try {
            blockingQueue.put(info);
            System.out.println(Thread.currentThread().getName() + &quot;produce&quot; + info);
            Thread.sleep(50);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
public void shutDown() {
        flag = true;
}
</code></pre><p> }<br> static class Consumer implements Runnable {</p>
<pre><code>private final BlockingQueue&lt;Integer&gt; blockingQueue;
private volatile boolean flag;
Consumer(BlockingQueue blockingQueue) {
    this.blockingQueue = blockingQueue;
}
@Override
public void run() {
    while (!flag) {
        int info ;
            try {
                info = blockingQueue.take();
                System.out.println(Thread.currentThread().getName() + &quot;consumer&quot; + info);
                Thread.sleep(50);

            } catch (InterruptedException e) {
                e.printStackTrace();
            }
    }
}

public void shutDown() {
    flag = true;
}
</code></pre><p> }</p>
<p> public static void main(String[] args) {</p>
<pre><code>BlockingQueue&lt;Integer&gt; blockingQueue = new LinkedBlockingQueue&lt;Integer&gt;(10);
Producer producer = new Producer(blockingQueue);
Consumer consumer = new Consumer(blockingQueue);
for (int i = 0; i &lt; 10; i++) {
    if (i &lt; 5) {
        new Thread(producer, &quot;producer&quot; + i).start();
    } else {
        new Thread(consumer, &quot;consumer&quot; + i).start();
    }
}
try {
    Thread.sleep(1000);
} catch (InterruptedException e) {
    e.printStackTrace();
}
producer.shutDown();
consumer.shutDown();
</code></pre><p> }<br>}</p>
</li>
</ul>
<p>其实阻塞队列实现阻塞同步的方式很简单，使用的就是是lock锁的多条件（condition）阻塞控制。使用BlockingQueue封装了根据条件阻塞线程的过程，而我们就不用关心繁琐的await/signal操作了。<br>下面是Jdk 1.7中ArrayBlockingQueue部分代码：<br>    public ArrayBlockingQueue(int capacity, boolean fair) {</p>
<pre><code>    if (capacity &lt;= 0)
        throw new IllegalArgumentException();
    //创建数组   
    this.items = new Object[capacity];
    //创建锁和阻塞条件
    lock = new ReentrantLock(fair);   
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
    }
//添加元素的方法public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == items.length)
        notFull.await();
        //如果队列不满就入队
        enqueue(e);
    } finally {
        lock.unlock();
    }
    }
 //入队的方法
 private void enqueue(E x) {
    final Object[] items = this.items;
    items[putIndex] = x;
    if (++putIndex == items.length)
        putIndex = 0;
    count++;
    notEmpty.signal();
    }
 //移除元素的方法
 public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == 0)
        notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
    }
 //出队的方法
 private E dequeue() {
    final Object[] items = this.items;
    @SuppressWarnings(&quot;unchecked&quot;)
    E x = (E) items[takeIndex];
    items[takeIndex] = null;
    if (++takeIndex == items.length)
        takeIndex = 0;
    count--;
    if (itrs != null)
        itrs.elementDequeued();
    notFull.signal();
    return
    }
</code></pre><p>双端阻塞队列(BlockingDequeue)<br>  concurrent包下还提供双端阻塞队列（BlockingDeque），和BlockingQueue是类似的，只不过BlockingDeque提供从任意一端插入<br>  或者抽取元素的队列。</p>
]]></content>
      <categories>
        <category>队列</category>
      </categories>
      <tags>
        <tag>queue</tag>
      </tags>
  </entry>
</search>
